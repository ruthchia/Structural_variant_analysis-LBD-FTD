{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75323a7",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Structural-variants-in-Lewy-body-dementias-and-frontotemporal-dementia/amyotrophic-lateral-sclerosis\" data-toc-modified-id=\"Structural-variants-in-Lewy-body-dementias-and-frontotemporal-dementia/amyotrophic-lateral-sclerosis-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Structural variants in Lewy body dementias and frontotemporal dementia/amyotrophic lateral sclerosis</a></span></li><li><span><a href=\"#Make-vcf-file-of-the-high-quality-subset-of-structural-variants-(clean-samples-and-filtered-structural-variants)\" data-toc-modified-id=\"Make-vcf-file-of-the-high-quality-subset-of-structural-variants-(clean-samples-and-filtered-structural-variants)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Make vcf file of the high-quality subset of structural variants (clean samples and filtered structural variants)</a></span></li><li><span><a href=\"#Descriptive-statistics-of-filtered-high-quality-subset-data\" data-toc-modified-id=\"Descriptive-statistics-of-filtered-high-quality-subset-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Descriptive statistics of filtered high quality subset data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mean-number-of-structural-variants-per-sample-(autosomes-only)\" data-toc-modified-id=\"Mean-number-of-structural-variants-per-sample-(autosomes-only)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Mean number of structural variants per sample (autosomes only)</a></span></li><li><span><a href=\"#Structural-variant-descriptives-(allele-frequency,-length,-type)\" data-toc-modified-id=\"Structural-variant-descriptives-(allele-frequency,-length,-type)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Structural variant descriptives (allele frequency, length, type)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-wrangling\" data-toc-modified-id=\"Data-wrangling-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Data wrangling</a></span></li><li><span><a href=\"#Build-R-data-frame-and-make-Figure-2-subplots\" data-toc-modified-id=\"Build-R-data-frame-and-make-Figure-2-subplots-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Build R data frame and make Figure 2 subplots</a></span></li><li><span><a href=\"#Get-descriptives\" data-toc-modified-id=\"Get-descriptives-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Get descriptives</a></span></li><li><span><a href=\"#Get-descriptives-by-case-control-status\" data-toc-modified-id=\"Get-descriptives-by-case-control-status-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Get descriptives by case-control status</a></span></li></ul></li></ul></li><li><span><a href=\"#Structural-variant-validation-vs.-Nanopore\" data-toc-modified-id=\"Structural-variant-validation-vs.-Nanopore-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Structural variant validation vs. Nanopore</a></span><ul class=\"toc-item\"><li><span><a href=\"#Unfiltered-data\" data-toc-modified-id=\"Unfiltered-data-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Unfiltered data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lewy-body-dementia-case/control-samples\" data-toc-modified-id=\"Lewy-body-dementia-case/control-samples-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Lewy body dementia case/control samples</a></span></li><li><span><a href=\"#Frontotemporal-dementia/amyotrophic-lateral-sclerosis-samples\" data-toc-modified-id=\"Frontotemporal-dementia/amyotrophic-lateral-sclerosis-samples-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Frontotemporal dementia/amyotrophic lateral sclerosis samples</a></span></li><li><span><a href=\"#Summary-of-results\" data-toc-modified-id=\"Summary-of-results-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Summary of results</a></span></li></ul></li><li><span><a href=\"#Filtered-structural-variants\" data-toc-modified-id=\"Filtered-structural-variants-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Filtered structural variants</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lewy-body-dementia-and-frontotemporal-dementia/amyotrophic-lateral-sclerosis-samples\" data-toc-modified-id=\"Lewy-body-dementia-and-frontotemporal-dementia/amyotrophic-lateral-sclerosis-samples-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Lewy body dementia and frontotemporal dementia/amyotrophic lateral sclerosis samples</a></span></li><li><span><a href=\"#Summary-of-results\" data-toc-modified-id=\"Summary-of-results-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Summary of results</a></span></li></ul></li><li><span><a href=\"#Filtered-structural-variants---allele-frequency-<1-%-vs->=1-%\" data-toc-modified-id=\"Filtered-structural-variants---allele-frequency-<1-%-vs->=1-%-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Filtered structural variants - allele frequency &lt;1 % vs &gt;=1 %</a></span></li></ul></li><li><span><a href=\"#TPCN1-replication-in-BBseq/DementiaSeq2\" data-toc-modified-id=\"TPCN1-replication-in-BBseq/DementiaSeq2-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>TPCN1 replication in BBseq/DementiaSeq2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generate-principal-components\" data-toc-modified-id=\"Generate-principal-components-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Generate principal components</a></span></li><li><span><a href=\"#Run-manta-to-genotype-TPCN1-deletion\" data-toc-modified-id=\"Run-manta-to-genotype-TPCN1-deletion-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Run manta to genotype TPCN1 deletion</a></span><ul class=\"toc-item\"><li><span><a href=\"#Run-samplot-to-visually-check-SV-calls\" data-toc-modified-id=\"Run-samplot-to-visually-check-SV-calls-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Run samplot to visually check SV calls</a></span></li></ul></li><li><span><a href=\"#Lewy-body-dementias-clinical-and-pathological\" data-toc-modified-id=\"Lewy-body-dementias-clinical-and-pathological-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Lewy body dementias clinical and pathological</a></span><ul class=\"toc-item\"><li><span><a href=\"#Make-phenotype-file-of-all-Lewy-body-dementia-samples\" data-toc-modified-id=\"Make-phenotype-file-of-all-Lewy-body-dementia-samples-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Make phenotype file of all Lewy body dementia samples</a></span></li><li><span><a href=\"#Make-covariate-file-and-select-covariate-with-step()\" data-toc-modified-id=\"Make-covariate-file-and-select-covariate-with-step()-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;</span>Make covariate file and select covariate with step()</a></span></li><li><span><a href=\"#Run-association-analysis-on-SNPs/Indels-of-TPCN1-block\" data-toc-modified-id=\"Run-association-analysis-on-SNPs/Indels-of-TPCN1-block-5.3.3\"><span class=\"toc-item-num\">5.3.3&nbsp;&nbsp;</span>Run association analysis on SNPs/Indels of TPCN1 block</a></span></li><li><span><a href=\"#Run-association-analysis-with-structural-variant-calls\" data-toc-modified-id=\"Run-association-analysis-with-structural-variant-calls-5.3.4\"><span class=\"toc-item-num\">5.3.4&nbsp;&nbsp;</span>Run association analysis with structural variant calls</a></span></li><li><span><a href=\"#Meta-analysis-of-structural-variant-results\" data-toc-modified-id=\"Meta-analysis-of-structural-variant-results-5.3.5\"><span class=\"toc-item-num\">5.3.5&nbsp;&nbsp;</span>Meta-analysis of structural variant results</a></span></li></ul></li></ul></li><li><span><a href=\"#50-neurodegenerative-disease-genes-gene-set-analyses\" data-toc-modified-id=\"50-neurodegenerative-disease-genes-gene-set-analyses-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>50 neurodegenerative disease genes gene-set analyses</a></span><ul class=\"toc-item\"><li><span><a href=\"#File-preparations\" data-toc-modified-id=\"File-preparations-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>File preparations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Subset-50-neurodegenerative-disease-gene-regions\" data-toc-modified-id=\"Subset-50-neurodegenerative-disease-gene-regions-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Subset 50 neurodegenerative disease gene regions</a></span></li><li><span><a href=\"#Create-vcfs\" data-toc-modified-id=\"Create-vcfs-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Create vcfs</a></span></li><li><span><a href=\"#Case-control-allele-frequencies\" data-toc-modified-id=\"Case-control-allele-frequencies-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>Case-control allele frequencies</a></span></li><li><span><a href=\"#CADD-SV-scores\" data-toc-modified-id=\"CADD-SV-scores-6.1.4\"><span class=\"toc-item-num\">6.1.4&nbsp;&nbsp;</span>CADD-SV scores</a></span></li><li><span><a href=\"#GeneHancer-regulatory-elements\" data-toc-modified-id=\"GeneHancer-regulatory-elements-6.1.5\"><span class=\"toc-item-num\">6.1.5&nbsp;&nbsp;</span>GeneHancer regulatory elements</a></span></li></ul></li><li><span><a href=\"#Lewy-body-dementias\" data-toc-modified-id=\"Lewy-body-dementias-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Lewy body dementias</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-vcfs-into-pandas-as-the-main-data-frame\" data-toc-modified-id=\"Import-vcfs-into-pandas-as-the-main-data-frame-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Import vcfs into pandas as the main data frame</a></span></li><li><span><a href=\"#Import-case-control-allele-frequencies-and-add-them-to-data-frame\" data-toc-modified-id=\"Import-case-control-allele-frequencies-and-add-them-to-data-frame-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Import case-control allele frequencies and add them to data frame</a></span></li><li><span><a href=\"#List-only-sample-IDs-that-have-minor-(mostly-alternative)-allele\" data-toc-modified-id=\"List-only-sample-IDs-that-have-minor-(mostly-alternative)-allele-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>List only sample IDs that have minor (mostly alternative) allele</a></span></li><li><span><a href=\"#Gene-region,-promoter,-exon,-non-coding,-GeneHancer-and-CADD-SV-overlap\" data-toc-modified-id=\"Gene-region,-promoter,-exon,-non-coding,-GeneHancer-and-CADD-SV-overlap-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>Gene region, promoter, exon, non-coding, GeneHancer and CADD-SV overlap</a></span></li><li><span><a href=\"#Tidy-main-data-frame\" data-toc-modified-id=\"Tidy-main-data-frame-6.2.5\"><span class=\"toc-item-num\">6.2.5&nbsp;&nbsp;</span>Tidy main data frame</a></span></li></ul></li><li><span><a href=\"#Frontotemporal-dementia/amyotrophic-lateral-sclerosis\" data-toc-modified-id=\"Frontotemporal-dementia/amyotrophic-lateral-sclerosis-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Frontotemporal dementia/amyotrophic lateral sclerosis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-vcfs-into-pandas-as-the-main-data-frame\" data-toc-modified-id=\"Import-vcfs-into-pandas-as-the-main-data-frame-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Import vcfs into pandas as the main data frame</a></span></li><li><span><a href=\"#Import-case-control-allele-frequencies-and-add-them-to-data-frame\" data-toc-modified-id=\"Import-case-control-allele-frequencies-and-add-them-to-data-frame-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Import case-control allele frequencies and add them to data frame</a></span></li><li><span><a href=\"#List-only-sample-IDs-that-have-minor-(mostly-alternative)-allele\" data-toc-modified-id=\"List-only-sample-IDs-that-have-minor-(mostly-alternative)-allele-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>List only sample IDs that have minor (mostly alternative) allele</a></span></li><li><span><a href=\"#Gene-region,-promoter,-exon,-non-coding,-GeneHancer-and-CADD-SV-overlap\" data-toc-modified-id=\"Gene-region,-promoter,-exon,-non-coding,-GeneHancer-and-CADD-SV-overlap-6.3.4\"><span class=\"toc-item-num\">6.3.4&nbsp;&nbsp;</span>Gene region, promoter, exon, non-coding, GeneHancer and CADD-SV overlap</a></span></li><li><span><a href=\"#Tidy-main-data-frame\" data-toc-modified-id=\"Tidy-main-data-frame-6.3.5\"><span class=\"toc-item-num\">6.3.5&nbsp;&nbsp;</span>Tidy main data frame</a></span></li></ul></li></ul></li><li><span><a href=\"#Shiny-app\" data-toc-modified-id=\"Shiny-app-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Shiny app</a></span><ul class=\"toc-item\"><li><span><a href=\"#50-Neurodegenerative-disease-gene-images\" data-toc-modified-id=\"50-Neurodegenerative-disease-gene-images-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>50 Neurodegenerative disease gene images</a></span></li><li><span><a href=\"#Data-preparation\" data-toc-modified-id=\"Data-preparation-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Data preparation</a></span></li><li><span><a href=\"#Shiny-app-code\" data-toc-modified-id=\"Shiny-app-code-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Shiny app code</a></span></li></ul></li><li><span><a href=\"#Miscellaneous\" data-toc-modified-id=\"Miscellaneous-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Miscellaneous</a></span><ul class=\"toc-item\"><li><span><a href=\"#Manhattan-plots\" data-toc-modified-id=\"Manhattan-plots-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Manhattan plots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lewy-body-dementias-plot\" data-toc-modified-id=\"Lewy-body-dementias-plot-8.1.1\"><span class=\"toc-item-num\">8.1.1&nbsp;&nbsp;</span>Lewy body dementias plot</a></span></li><li><span><a href=\"#Frontotemporal-dementia/amyotrophic-lateral-sclerosis-plot\" data-toc-modified-id=\"Frontotemporal-dementia/amyotrophic-lateral-sclerosis-plot-8.1.2\"><span class=\"toc-item-num\">8.1.2&nbsp;&nbsp;</span>Frontotemporal dementia/amyotrophic lateral sclerosis plot</a></span></li></ul></li><li><span><a href=\"#95-%-condifence-intervals-for-genome-wide-association-study-hits\" data-toc-modified-id=\"95-%-condifence-intervals-for-genome-wide-association-study-hits-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>95 % condifence intervals for genome-wide association study hits</a></span></li><li><span><a href=\"#TPCN1-plots\" data-toc-modified-id=\"TPCN1-plots-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>TPCN1 plots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Locus-zoom\" data-toc-modified-id=\"Locus-zoom-8.3.1\"><span class=\"toc-item-num\">8.3.1&nbsp;&nbsp;</span>Locus zoom</a></span></li></ul></li><li><span><a href=\"#Beta-beta-plots\" data-toc-modified-id=\"Beta-beta-plots-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>Beta-beta plots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Beta-beta-plot-of-Belenguez-Alzheimer's-disease-TPCN1-and-our-TPCN1-loci\" data-toc-modified-id=\"Beta-beta-plot-of-Belenguez-Alzheimer's-disease-TPCN1-and-our-TPCN1-loci-8.4.1\"><span class=\"toc-item-num\">8.4.1&nbsp;&nbsp;</span>Beta-beta plot of Belenguez Alzheimer's disease TPCN1 and our TPCN1 loci</a></span></li><li><span><a href=\"#Beta-beta-plot-of-Lewy-body-dementias-and-Parkinsons'-disease\" data-toc-modified-id=\"Beta-beta-plot-of-Lewy-body-dementias-and-Parkinsons'-disease-8.4.2\"><span class=\"toc-item-num\">8.4.2&nbsp;&nbsp;</span>Beta-beta plot of Lewy body dementias and Parkinsons' disease</a></span></li></ul></li><li><span><a href=\"#Cohort-demographics\" data-toc-modified-id=\"Cohort-demographics-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>Cohort demographics</a></span></li><li><span><a href=\"#Bigbed-files-for-UCSC/Ensembl\" data-toc-modified-id=\"Bigbed-files-for-UCSC/Ensembl-8.6\"><span class=\"toc-item-num\">8.6&nbsp;&nbsp;</span>Bigbed files for UCSC/Ensembl</a></span></li><li><span><a href=\"#Number-of-tested-filtered-clean-minor-allele-frequecy-<1%-and->=1%-structural-variants-tested-against-Nanopore\" data-toc-modified-id=\"Number-of-tested-filtered-clean-minor-allele-frequecy-<1%-and->=1%-structural-variants-tested-against-Nanopore-8.7\"><span class=\"toc-item-num\">8.7&nbsp;&nbsp;</span>Number of tested filtered clean minor allele frequecy &lt;1% and &gt;=1% structural variants tested against Nanopore</a></span></li><li><span><a href=\"#Generate-spreadsheets-for-high-quality-structural-variants\" data-toc-modified-id=\"Generate-spreadsheets-for-high-quality-structural-variants-8.8\"><span class=\"toc-item-num\">8.8&nbsp;&nbsp;</span>Generate spreadsheets for high-quality structural variants</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd20337-6a0f-48cc-ac42-01881c5b03b9",
   "metadata": {},
   "source": [
    "# Structural variants in Lewy body dementias and frontotemporal dementia/amyotrophic lateral sclerosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a236f-ca93-4bc1-8616-fc1be8fbe328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working directory\n",
    "WD=\"$PATH2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c71599",
   "metadata": {},
   "source": [
    "Common abbreviations in notebook:\n",
    "1. LBD = Lewy body dementias\n",
    "2. FTD = Frontotemporal dementia (/amyotrophic lateral sclerosis)\n",
    "3. SV = Structural variant\n",
    "4. AF = allele frequency\n",
    "5. df = data frame\n",
    "6. SVLEN = structural variant lenght\n",
    "7. SVTYPE = structural variant type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767c0b3-0a77-4cea-a0be-71624cc01d8b",
   "metadata": {},
   "source": [
    "# Make vcf file of the high-quality subset of structural variants (clean samples and filtered structural variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86494fcd-d113-4945-8eea-740578f5e5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load plink/2.3-alpha\n",
    "\n",
    "#Make a list of clean, analyzed samples (i.e. all covariates known)\n",
    "##List all samples\n",
    "for PHENO in LBD FTD; do \n",
    "    awk '(($8 !=\"NA\") && NR >1) {print $1}' $PATH5/COVARIATES.SNVindels.SV.freeze9.${PHENO}.controls.UNRELATED_minGQ300.txt > tmp_${PHENO}_analyzed_samples.txt\n",
    "done\n",
    "##List cases and controls separately\n",
    "for PHENO in LBD FTD; do \n",
    "    awk '($8 !=\"NA\" && NR >1 && $4==1 ) {print $1}' $PATH5/COVARIATES.SNVindels.SV.freeze9.${PHENO}.controls.UNRELATED_minGQ300.txt > tmp_${PHENO}_analyzed_controls.txt\n",
    "    awk '($8 !=\"NA\" && NR >1 && $4==2 ) {print $1}' $PATH5/COVARIATES.SNVindels.SV.freeze9.${PHENO}.controls.UNRELATED_minGQ300.txt > tmp_${PHENO}_analyzed_cases.txt\n",
    "done\n",
    "\n",
    "#Make a list of clean SVs\n",
    "##Calculate AFs of SVs so that AF=0 SVs that filtering has created can be excluded (N.B.! in these AF calculations are included samples that will be excluded! Need to recalculate AFs later!)\n",
    "for PHENO in LBD FTD; do\n",
    "    plink2 \\\n",
    "    --pfile $PATH5/${PHENO}_minGQ300/SV.${PHENO}.forMerging \\\n",
    "    --freq \\\n",
    "    --out tmp_${PHENO}_SV_afreq\n",
    "done\n",
    "\n",
    "##Make a list of SVs with AF > 0 (exclude 0 and nan AFs)\n",
    "for PHENO in LBD FTD; do\n",
    "    awk '(NR !=1 && $5 != 0 && $5 !=\"nan\") {print $2}' tmp_${PHENO}_SV_afreq.afreq > tmp_${PHENO}_SVS_AF_over0.txt\n",
    "done\n",
    "\n",
    "##Extract all filtered SVs\n",
    "for PHENO in LBD FTD; do\n",
    "    awk '{print $3}' $PATH5/${PHENO}_minGQ300/SV.${PHENO}.forMerging.pvar | grep \"${PHENO}\" > tmp_${PHENO}_SVs.txt\n",
    "done\n",
    "\n",
    "##Get union of all filtered SVs and filtered SVs with AF > 0\n",
    "for PHENO in LBD FTD; do\n",
    "    grep -wFf tmp_${PHENO}_SVS_AF_over0.txt tmp_${PHENO}_SVs.txt > ${PHENO}_clean_SVs_AF_over_0.txt\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518a770-d205-4fd4-b0c2-77123d0a355a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "#Get SV numbers and sample counts (SV numbers will drop after excluding new AF=0 SVs)\n",
    "for PHENO in LBD FTD; do\n",
    "    echo \"${PHENO} number of clean SVs:\"\n",
    "    wc -l ${PHENO}_clean_SVs_AF_over_0.txt\n",
    "    echo \"${PHENO} number of samples:\"\n",
    "    wc -l tmp_${PHENO}_analyzed_samples.txt\n",
    "    echo \"${PHENO} number of cases:\"\n",
    "    wc -l tmp_${PHENO}_analyzed_cases.txt\n",
    "    echo \"${PHENO} number of controls:\"\n",
    "    wc -l tmp_${PHENO}_analyzed_controls.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774391d3-f25e-4f1b-9848-7aeffe698386",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load bcftools\n",
    "\n",
    "#Make clean vcfs by filtering clean samples and SVs from 1% FDR GATK-SV output vcf\n",
    "#Set GQ<300 to missing and index\n",
    "for PHENO in LBD FTD; do\n",
    "    bcftools view -S tmp_${PHENO}_analyzed_samples.txt -i \"ID=@${PHENO}_clean_SVs_AF_over_0.txt\" -Oz -o tmp_${PHENO}.vcf.gz /${PHENO}_gatksv_1perc_fdr_cleaned_filters_qual_recalibrated/${PHENO}_1perc_fdr.cleaned_filters_qual_recalibrated.LNGsampleID.vcf.gz\n",
    "    bcftools +setGT -Oz -o ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz tmp_${PHENO}.vcf.gz -- -t q -i 'GQ<300' -n .\n",
    "    tabix -f -p vcf ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68363da-6939-4598-8cff-486980311437",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load bcftools\n",
    "\n",
    "#Split vcfs by case-control status\n",
    "for PHENO in LBD FTD; do\n",
    "    for STATUS in cases controls; do\n",
    "        bcftools view -S tmp_${PHENO}_analyzed_${STATUS}.txt -Oz -o rm_${PHENO}_${STATUS}.vcf.gz ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz\n",
    "    done\n",
    "done\n",
    "\n",
    "#Add AF tags to all vcfs\n",
    "for PHENO in LBD FTD; do\n",
    "   bcftools +fill-tags -Oz -o rename_${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz -- -t AF,AC,AN\n",
    "done\n",
    "\n",
    "for PHENO in LBD FTD; do\n",
    "    for STATUS in cases controls; do\n",
    "        bcftools +fill-tags -Oz -o ${PHENO}_${STATUS}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz rm_${PHENO}_${STATUS}.vcf.gz -- -t AF,AC,AN\n",
    "    done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e1f4d-5cae-4a7d-b686-a55a7d538295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load samtools\n",
    "\n",
    "#Remove rm files and rename rename files to overwrite older version\n",
    "for PHENO in LBD FTD; do\n",
    "    mv rename_${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz\n",
    "done\n",
    "\n",
    "rm rm_*\n",
    "\n",
    "#Redo tabix indexing on all vcfs\n",
    "parallel -j1 tabix -f -p vcf {} ::: *.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b2bca4-5a5f-407a-b99b-b601664d6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load samtools\n",
    "#Exclude SVs with AF = 0 from all vcfs (after exclusion of samples, new AF=0 SVs have been created) and rename to overwrite old file\n",
    "\n",
    "for PHENO in LBD FTD; do\n",
    "    bcftools view -i 'AF > 0' -Oz -o temp_${PHENO}.vcf.gz ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz\n",
    "    mv temp_${PHENO}.vcf.gz ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz\n",
    "done\n",
    "\n",
    "for PHENO in LBD FTD; do\n",
    "    for STATUS in cases controls; do\n",
    "        bcftools view -i 'AF > 0' -Oz -o temp_${PHENO}_${STATUS}.vcf.gz ${PHENO}_${STATUS}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz\n",
    "        mv temp_${PHENO}_${STATUS}.vcf.gz ${PHENO}_${STATUS}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d26f8d-16e9-421a-9b18-30ad367bd79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load samtools\n",
    "\n",
    "#Redo tabix indexing on all vcfs\n",
    "parallel -j1 tabix -f -p vcf {} ::: *.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24908421-875f-47b1-9f24-1200a252a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load samtools\n",
    "\n",
    "#Make autosome only vcfs, recalculate AF, AN and AC, filter out AF=0 SVs\n",
    "for PHENO in LBD FTD; do\n",
    "    bcftools view -r chr1,chr2,chr3,chr4,chr5,chr6,chr7,chr8,chr9,chr10,chr11,chr12,chr13,chr14,chr15,chr16,chr17,chr18,chr19,chr20,chr21,chr22 -Oz -o rm_${PHENO}_autosomes.vcf.gz ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz\n",
    "    bcftools +fill-tags -Oz -o rm2_${PHENO}_autosomes.vcf.gz rm_${PHENO}_autosomes.vcf.gz -- -t AF,AC,AN\n",
    "    bcftools view -i 'AF > 0' -Oz -o ${PHENO}_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz rm2_${PHENO}_autosomes.vcf.gz \n",
    "    rm rm*_${PHENO}_autosomes.vcf.gz\n",
    "done\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddfe37-ab8c-4a1c-8392-4d72be1c7c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load samtools\n",
    "\n",
    "#Redo tabix indexing on all vcfs\n",
    "parallel -j $SLURM_CPUS_PER_TASK tabix -f -p vcf {} ::: *.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf2bcf-d69a-40d2-9f04-fcb43f3ef172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load samtools\n",
    "#Get variant counts\n",
    "echo \"LBD all clean SVs:\"\n",
    "bcftools query -f '%ID\\n' LBD_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz | wc -l\n",
    "echo \"LBD cases all clean SVs:\"\n",
    "bcftools query -f '%ID\\n' LBD_cases_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz | wc -l\n",
    "echo \"LBD controls all clean SVs:\"\n",
    "bcftools query -f '%ID\\n' LBD_controls_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz | wc -l\n",
    "echo \"FTD all clean all SVs:\"\n",
    "bcftools query -f '%ID\\n' FTD_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz | wc -l\n",
    "echo \"FTD cases clean all SVs:\"\n",
    "bcftools query -f '%ID\\n' FTD_cases_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz | wc -l\n",
    "echo \"FTD controls clean all SVs:\"\n",
    "bcftools query -f '%ID\\n' FTD_controls_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz | wc -l\n",
    "\n",
    "echo -e \"\\n\"\n",
    "echo \"LBD autosomal clean SVs:\"\n",
    "bcftools query -f '%ID\\n' LBD_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz | wc -l\n",
    "echo \"FTD autosomal clean SVs:\"\n",
    "bcftools query -f '%ID\\n' FTD_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz | wc -l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17527eb4-10c7-4f09-863a-22d25da8c140",
   "metadata": {},
   "source": [
    "# Descriptive statistics of filtered high quality subset data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d9d93-72ea-4ec4-abfa-ce5a74a316cc",
   "metadata": {},
   "source": [
    "## Mean number of structural variants per sample (autosomes only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619aa011-df35-483f-8b38-f5c70cc60c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load bcftools\n",
    "\n",
    "#Run bcftools stats to get SV counts per sample (autosomes, high quality subset SVs). Do separately for all, cases and controls\n",
    "for PHENO in LBD FTD; do\n",
    "    bcftools stats -S tmp_${PHENO}_analyzed_samples.txt ${PHENO}_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz > $PATH2/descriptive_stats_and_fig2/${PHENO}_high_quality_subset_clean_GQ300missing_autosomes_stats.txt\n",
    "    bcftools stats -S tmp_${PHENO}_analyzed_cases.txt ${PHENO}_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz > $PATH2/descriptive_stats_and_fig2/${PHENO}_cases_high_quality_subset_clean_GQ300missing_autosomes_stats.txt\n",
    "    bcftools stats -S tmp_${PHENO}_analyzed_controls.txt ${PHENO}_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz > $PATH2/descriptive_stats_and_fig2/${PHENO}_controls_high_quality_subset_clean_GQ300missing_autosomes_stats.txt\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a7a59-ed4e-4c5d-93c6-9cfbcdf3f6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/descriptive_stats_and_fig2\n",
    "#Calculate average number of SVs in autosome per sample across filtered samples: at rows starting PCS, is number of reference hom variants and number of variants with missing genotype\n",
    "#Total number of SVs with alt = total number of SVs in data set - nRefHom-nMissing\n",
    "N_LBD=146027\n",
    "N_FTD=153678\n",
    "for PHENO in LBD; do\n",
    "    echo \"Mean number of SVs in autosomes per sample in filtered FDR1% ${PHENO} run, all samples\"\n",
    "    grep 'PSC' ${PHENO}_high_quality_subset_clean_GQ300missing_autosomes_stats.txt | awk -v N=$N_LBD '(NR>2){print N-$4-$14}' | awk '{ total += $1; count++ } END { print total/count }'\n",
    "    echo \"Mean number of SVs in autosomes per cases in filtered FDR1% ${PHENO} run, all samples\"\n",
    "    grep 'PSC' ${PHENO}_cases_high_quality_subset_clean_GQ300missing_autosomes_stats.txt | awk -v N=$N_LBD '(NR>2){print N-$4-$14}' | awk '{ total += $1; count++ } END { print total/count }'\n",
    "    echo \"Mean number of SVs in autosomes per controls in filtered FDR1% ${PHENO} run, all samples\"\n",
    "    grep 'PSC' ${PHENO}_controls_high_quality_subset_clean_GQ300missing_autosomes_stats.txt | awk -v N=$N_LBD '(NR>2){print N-$4-$14}' | awk '{ total += $1; count++ } END { print total/count }'\n",
    "done\n",
    "\n",
    "for PHENO in FTD; do\n",
    "    echo \"Mean number of SVs in autosomes per sample in filtered FDR1% ${PHENO} run, all samples\"\n",
    "    grep 'PSC' ${PHENO}_high_quality_subset_clean_GQ300missing_autosomes_stats.txt | awk -v N=$N_FTD '(NR>2){print N-$4-$14}' | awk '{ total += $1; count++ } END { print total/count }'\n",
    "    echo \"Mean number of SVs in autosomes per cases in filtered FDR1% ${PHENO} run, all samples\"\n",
    "    grep 'PSC' ${PHENO}_cases_high_quality_subset_clean_GQ300missing_autosomes_stats.txt | awk -v N=$N_FTD '(NR>2){print N-$4-$14}' | awk '{ total += $1; count++ } END { print total/count }'\n",
    "    echo \"Mean number of SVs in autosomes per controls in filtered FDR1% ${PHENO} run, all samples\"\n",
    "    grep 'PSC' ${PHENO}_controls_high_quality_subset_clean_GQ300missing_autosomes_stats.txt | awk -v N=$N_FTD '(NR>2){print N-$4-$14}' | awk '{ total += $1; count++ } END { print total/count }'\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ec090-78ba-410f-aa1f-6b6bceecc5ca",
   "metadata": {},
   "source": [
    "## Structural variant descriptives (allele frequency, length, type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0dc1da-02cb-4a21-8e63-0b4238f8c1d2",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48434f7-dee3-4d4a-bcfe-1ac30cb652d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/descriptive_stats_and_fig2\n",
    "module load bcftools\n",
    "\n",
    "#Extract AF,AC,SVLEN,SVTYPE,CHROM info per variant for LBD and FTD\n",
    "for PHENO in LBD FTD; do\n",
    "    bcftools query -f '%ID %SVTYPE %SVLEN %AF %AC %CHROM\\n' ../clean_high_quality_vcfs/${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz > ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr_INFO.txt\n",
    "done\n",
    "\n",
    "#Extract AF,AC,SVLEN,SVTYPE,CHROM info per variant for LBD and FTD cases and controls separately\n",
    "#N.B.! Case and control vcfs include AF=0 variants!\n",
    "for PHENO in LBD FTD; do\n",
    "    for STATUS in cases controls; do\n",
    "        bcftools query -f '%ID %SVTYPE %SVLEN %AF %AC %CHROM\\n' ../clean_high_quality_vcfs/${PHENO}_${STATUS}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz > ${PHENO}_${STATUS}_high_quality_subset_clean_GQ300missing_all_chr_INFO.txt\n",
    "    done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e743b1-c735-4644-8560-6fec95aa5345",
   "metadata": {},
   "source": [
    "### Build R data frame and make Figure 2 subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66b91e-613f-4a1c-8d1e-0c131b897ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f773ce-6c19-4c90-bd2a-1806b9550a9e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "####Filtered SVs GATK-SV style bar plots: LBD\n",
    "\n",
    "#Set wd\n",
    "setwd(\"$PATH2/descriptive_stats_and_fig2\")\n",
    "\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(scales)\n",
    "\n",
    "#Import files\n",
    "\n",
    "df <- fread(\"LBD_high_quality_subset_clean_GQ300missing_all_chr_INFO.txt\")\n",
    "colnames(df) <- c(\"ID\",\"SVTYPE\",\"SVLEN\",\"AF\",\"AC\",\"CHROM\")\n",
    "\n",
    "#Rename BND and CTX to OTH\n",
    "df$SVTYPE[df$SVTYPE %in% c(\"BND\",\"CTX\")] <- \"OTH\"\n",
    "\n",
    "#Make SVTYPEs into factors\n",
    "df$SVTYPE <- factor(df$SVTYPE , levels=c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"), labels = c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"))\n",
    "\n",
    "\n",
    "#Add SVLEN and AF groups, add AC=1 separately since threshold varies accordig to number of samples\n",
    "df$SVLEN_group <- cut(df$SVLEN, breaks = c(-2,0,100,500,2500,10000,50000,10^10), labels=c(\"unresolved\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "df$AF_group <- cut(as.numeric(df$AF), breaks = c(0,0.01,0.10,0.50,1), labels=c(\"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "levels(df$AF_group)[5] <- \"AC=1\"\n",
    "df$AF_group[df$AC == 1] <- \"AC=1\"\n",
    "\n",
    "#Make grouped data frames. N.B.! Exclude \"Other\" category from plots as per GATK-SV model image since SVLEN is more of a guess for them\n",
    "df_grouped_AF_SVTYPE <- df %>%\n",
    "  group_by(SVTYPE, AF_group) %>%\n",
    "  summarize(count = n())\n",
    "\n",
    "tmp <- df_grouped_AF_SVTYPE\n",
    "tmp$AF_group <- \"ALL\"\n",
    "df_grouped_AF_SVTYPE <- rbind(df_grouped_AF_SVTYPE,tmp)\n",
    "df_grouped_AF_SVTYPE$AF_group <- factor(df_grouped_AF_SVTYPE$AF_group, ordered = TRUE, levels = c(\"ALL\", \"AC=1\", \"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "\n",
    "df_grouped_SVLEN_SVTYPE <- df %>%\n",
    "  filter(SVTYPE != \"OTH\") %>%\n",
    "  group_by(SVTYPE, SVLEN_group) %>%\n",
    "  summarize(count = n())\n",
    "\n",
    "tmp <- df_grouped_SVLEN_SVTYPE\n",
    "tmp$SVLEN_group <- \"ALL\"\n",
    "df_grouped_SVLEN_SVTYPE <- rbind(df_grouped_SVLEN_SVTYPE,tmp)\n",
    "df_grouped_SVLEN_SVTYPE$SVLEN_group <- factor(df_grouped_SVLEN_SVTYPE$SVLEN_group, ordered = TRUE, levels = c(\"ALL\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "\n",
    "#Make a second data frame for scaled plots to include ALL group\n",
    "df2 <- df\n",
    "df2$AF_group <- \"ALL\"\n",
    "df2$SVLEN_group <- \"ALL\"\n",
    "df2 <- rbind(df,df2)\n",
    "df2$SVLEN_group <- factor(df2$SVLEN_group, ordered = TRUE, levels = c(\"ALL\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "df2$AF_group <- factor(df2$AF_group, ordered = TRUE, levels = c(\"ALL\", \"AC=1\", \"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "\n",
    "\n",
    "#Plots\n",
    "##Variant count by SVTYPE\n",
    "print(ggplot(df, aes(SVTYPE, fill=SVTYPE)) +\n",
    "        geom_bar(width=0.8) +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        geom_text(stat='count', aes(label = format(..count.., big.mark = \",\", scientific = FALSE)), size = 5, color = c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\"), vjust=-1) +\n",
    "        ylab(\"SV Count\") +\n",
    "        xlab(\"\") +\n",
    "        scale_y_continuous(labels = comma, expand = c(-0.001,0), limits = c(0,nrow(df[df$SVTYPE == \"DEL\"]) + 5000)) +\n",
    "        guides(fill=\"none\") +\n",
    "        theme(axis.title.y=element_text(size=16), axis.ticks.x = element_blank(), axis.text.y=element_text(size=12), axis.text.x=element_text(size=14, angle=90, color = c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"LBD_filtered_SV_variant_count_plot.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "##SV count by AF\n",
    "print(ggplot(df_grouped_AF_SVTYPE, aes(fill=SVTYPE, x=AF_group, y = count)) +\n",
    "        geom_bar(width = 0.8, position=position_stack(reverse = TRUE), stat=\"identity\") +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        xlab(\"\") +\n",
    "        ylab(\"\") +\n",
    "        scale_y_continuous(labels = comma, expand = c(-0.0001,0)) +\n",
    "        guides(fill=\"none\") +\n",
    "        ggtitle(\"SV Count by AF LBD\") +\n",
    "        theme(axis.title.y=element_text(size=20), axis.ticks.x = element_blank(), axis.text.y=element_text(size=20), axis.text.x=element_text(size=20, angle=90), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"LBD_filtered_SV_count_by_AF_plot.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "##SV count by AF scaled\n",
    "print(ggplot(df2, aes(fill=SVTYPE, x=AF_group)) +\n",
    "        geom_bar(width = 0.8, position = position_fill(reverse = TRUE)) +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        xlab(\"\") +\n",
    "        ylab(\"\") +\n",
    "        scale_y_continuous(breaks = c(0,0.20,0.40,0.60,0.8,1), labels = c(\"0%\", \"20%\", \"40%\", \"60%\", '80%', \"100%\"), expand = c(-0.001,0.001)) +\n",
    "        guides(fill=\"none\") +\n",
    "        ggtitle(\"SV Count by AF LBD scaled\") +\n",
    "        theme(axis.title.y=element_text(size=20), axis.ticks.x = element_blank(), axis.text.y=element_text(size=20), axis.text.x=element_text(size=20, angle=90), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"LBD_filtered_SV_count_by_AF_plot_scaled.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "##SV count by SVLEN\n",
    "print(ggplot(df_grouped_SVLEN_SVTYPE, aes(fill=SVTYPE, x=SVLEN_group, y = count)) +\n",
    "        geom_bar(width = 0.8, position=position_stack(reverse = TRUE), stat=\"identity\") +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        xlab(\"\") +\n",
    "        ylab(\"\") +\n",
    "        scale_y_continuous(labels = comma, expand = c(-0.001,0)) +\n",
    "        guides(fill=\"none\") +\n",
    "        ggtitle(\"SV Count by SVLEN LBD\") +\n",
    "        theme(axis.title.y=element_text(size=20), axis.ticks.x = element_blank(), axis.text.y=element_text(size=20), axis.text.x=element_text(size=20, angle=90), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"LBD_filtered_SV_count_by_SVLEN_plot.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "##SV count by SVLEN scaled\n",
    "print(ggplot(subset(df2, SVTYPE != \"OTH\"), aes(fill=SVTYPE, x=SVLEN_group)) +\n",
    "        geom_bar(width = 0.8,, position = position_fill(reverse = TRUE)) +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        xlab(\"\") +\n",
    "        ylab(\"\") +\n",
    "        scale_y_continuous(breaks = c(0,0.20,0.40,0.60,0.8,1), labels = c(\"0%\", \"20%\", \"40%\", \"60%\", '80%', \"100%\"), expand = c(-0.001,0.001)) +\n",
    "        guides(fill=\"none\") +\n",
    "        ggtitle(\"SV Count by SVLEN LBD scaled\") +\n",
    "        theme(axis.title.y=element_text(size=20), axis.ticks.x = element_blank(), axis.text.y=element_text(size=20), axis.text.x=element_text(size=20, angle=90), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"LBD_filtered_SV_count_by_SVLEN_plot_scaled.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "\n",
    "#Save df\n",
    "write.table(df, \"LBD_descriptives_df.txt\", quote=FALSE, sep=\"\\t\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e52ec-86ca-45bd-af29-85dfaab53d58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "####Filtered SVs GATK-SV style bar plots: FTD\n",
    "\n",
    "#Set wd\n",
    "setwd(\"$PATH2/descriptive_stats_and_fig2\")\n",
    "\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(scales)\n",
    "\n",
    "#Import files\n",
    "\n",
    "df <- fread(\"FTD_high_quality_subset_clean_GQ300missing_all_chr_INFO.txt\")\n",
    "colnames(df) <- c(\"ID\",\"SVTYPE\",\"SVLEN\",\"AF\",\"AC\",\"CHROM\")\n",
    "\n",
    "#Rename BND and CTX to OTH\n",
    "df$SVTYPE[df$SVTYPE %in% c(\"BND\",\"CTX\")] <- \"OTH\"\n",
    "\n",
    "#Make SVTYPEs into factors\n",
    "df$SVTYPE <- factor(df$SVTYPE , levels=c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"), labels = c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"))\n",
    "\n",
    "\n",
    "#Add SVLEN and AF groups, add AC=1 separately since threshold varies accordig to number of samples\n",
    "df$SVLEN_group <- cut(df$SVLEN, breaks = c(-2,0,100,500,2500,10000,50000,10^10), labels=c(\"unresolved\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "df$AF_group <- cut(as.numeric(df$AF), breaks = c(0,0.01,0.10,0.50,1), labels=c(\"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "levels(df$AF_group)[5] <- \"AC=1\"\n",
    "df$AF_group[df$AC == 1] <- \"AC=1\"\n",
    "\n",
    "#Make grouped data frames. N.B.! Exclude \"Other\" category from plots as per GATK-SV model image since SVLEN is more of a guess for them\n",
    "df_grouped_AF_SVTYPE <- df %>%\n",
    "  group_by(SVTYPE, AF_group) %>%\n",
    "  summarize(count = n())\n",
    "\n",
    "tmp <- df_grouped_AF_SVTYPE\n",
    "tmp$AF_group <- \"ALL\"\n",
    "df_grouped_AF_SVTYPE <- rbind(df_grouped_AF_SVTYPE,tmp)\n",
    "df_grouped_AF_SVTYPE$AF_group <- factor(df_grouped_AF_SVTYPE$AF_group, ordered = TRUE, levels = c(\"ALL\", \"AC=1\", \"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "\n",
    "df_grouped_SVLEN_SVTYPE <- df %>%\n",
    "  filter(SVTYPE != \"OTH\") %>%\n",
    "  group_by(SVTYPE, SVLEN_group) %>%\n",
    "  summarize(count = n())\n",
    "\n",
    "tmp <- df_grouped_SVLEN_SVTYPE\n",
    "tmp$SVLEN_group <- \"ALL\"\n",
    "df_grouped_SVLEN_SVTYPE <- rbind(df_grouped_SVLEN_SVTYPE,tmp)\n",
    "df_grouped_SVLEN_SVTYPE$SVLEN_group <- factor(df_grouped_SVLEN_SVTYPE$SVLEN_group, ordered = TRUE, levels = c(\"ALL\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "\n",
    "#Make a second data frame for scaled plots to include ALL group\n",
    "df2 <- df\n",
    "df2$AF_group <- \"ALL\"\n",
    "df2$SVLEN_group <- \"ALL\"\n",
    "df2 <- rbind(df,df2)\n",
    "df2$SVLEN_group <- factor(df2$SVLEN_group, ordered = TRUE, levels = c(\"ALL\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "df2$AF_group <- factor(df2$AF_group, ordered = TRUE, levels = c(\"ALL\", \"AC=1\", \"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "\n",
    "\n",
    "#Plots\n",
    "##Variant count by SVTYPE\n",
    "print(ggplot(df, aes(SVTYPE, fill=SVTYPE)) +\n",
    "        geom_bar(width=0.8) +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        geom_text(stat='count', aes(label = format(..count.., big.mark = \",\", scientific = FALSE)), size = 5, color = c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\"), vjust=-1) +\n",
    "        ylab(\"SV Count\") +\n",
    "        xlab(\"\") +\n",
    "        scale_y_continuous(labels = comma, expand = c(-0.001,0), limits = c(0,nrow(df[df$SVTYPE == \"DEL\"]) + 5000)) +\n",
    "        guides(fill=\"none\") +\n",
    "        theme(axis.title.y=element_text(size=16), axis.ticks.x = element_blank(), axis.text.y=element_text(size=12), axis.text.x=element_text(size=14, angle=90, color = c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"FTD_filtered_SV_variant_count_plot.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "##SV count by AF\n",
    "print(ggplot(df_grouped_AF_SVTYPE, aes(fill=SVTYPE, x=AF_group, y = count)) +\n",
    "        geom_bar(width = 0.8, position=position_stack(reverse = TRUE), stat=\"identity\") +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        xlab(\"\") +\n",
    "        ylab(\"\") +\n",
    "        scale_y_continuous(labels = comma, expand = c(-0.0001,0)) +\n",
    "        guides(fill=\"none\") +\n",
    "        ggtitle(\"SV Count by AF FTD\") +\n",
    "        theme(axis.title.y=element_text(size=20), axis.ticks.x = element_blank(), axis.text.y=element_text(size=20), axis.text.x=element_text(size=20, angle=90), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"FTD_filtered_SV_count_by_AF_plot.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "##SV count by AF scaled\n",
    "print(ggplot(df2, aes(fill=SVTYPE, x=AF_group)) +\n",
    "        geom_bar(width = 0.8, position = position_fill(reverse = TRUE)) +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        xlab(\"\") +\n",
    "        ylab(\"\") +\n",
    "        scale_y_continuous(breaks = c(0,0.20,0.40,0.60,0.8,1), labels = c(\"0%\", \"20%\", \"40%\", \"60%\", '80%', \"100%\"), expand = c(-0.001,0.001)) +\n",
    "        guides(fill=\"none\") +\n",
    "        ggtitle(\"SV Count by AF FTD scaled\") +\n",
    "        theme(axis.title.y=element_text(size=20), axis.ticks.x = element_blank(), axis.text.y=element_text(size=20), axis.text.x=element_text(size=20, angle=90), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"FTD_filtered_SV_count_by_AF_plot_scaled.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "##SV count by SVLEN\n",
    "print(ggplot(df_grouped_SVLEN_SVTYPE, aes(fill=SVTYPE, x=SVLEN_group, y = count)) +\n",
    "        geom_bar(width = 0.8, position=position_stack(reverse = TRUE), stat=\"identity\") +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        xlab(\"\") +\n",
    "        ylab(\"\") +\n",
    "        scale_y_continuous(labels = comma, expand = c(-0.001,0)) +\n",
    "        guides(fill=\"none\") +\n",
    "        ggtitle(\"SV Count by SVLEN FTD\") +\n",
    "        theme(axis.title.y=element_text(size=20), axis.ticks.x = element_blank(), axis.text.y=element_text(size=20), axis.text.x=element_text(size=20, angle=90), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"FTD_filtered_SV_count_by_SVLEN_plot.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "##SV count by SVLEN scaled\n",
    "print(ggplot(subset(df2, SVTYPE != \"OTH\"), aes(fill=SVTYPE, x=SVLEN_group)) +\n",
    "        geom_bar(width = 0.8,, position = position_fill(reverse = TRUE)) +\n",
    "        scale_fill_manual(values=c(\"#D6402D\", \"#5282AF\", \"#D579E1\", \"#F69A57\", \"#86E496\", \"#395946\")) +\n",
    "        xlab(\"\") +\n",
    "        ylab(\"\") +\n",
    "        scale_y_continuous(breaks = c(0,0.20,0.40,0.60,0.8,1), labels = c(\"0%\", \"20%\", \"40%\", \"60%\", '80%', \"100%\"), expand = c(-0.001,0.001)) +\n",
    "        guides(fill=\"none\") +\n",
    "        ggtitle(\"SV Count by SVLEN FTD scaled\") +\n",
    "        theme(axis.title.y=element_text(size=20), axis.ticks.x = element_blank(), axis.text.y=element_text(size=20), axis.text.x=element_text(size=20, angle=90), panel.background = element_rect(fill = \"white\"), axis.line.y = element_line(size = 0.5, colour = \"black\")))\n",
    "ggsave(filename = \"FTD_filtered_SV_count_by_SVLEN_plot_scaled.png\", plot = last_plot(), device = \"png\", dpi = 300, width = 5, height=7, units = \"in\" )\n",
    "\n",
    "#Save df\n",
    "write.table(df, \"FTD_descriptives_df.txt\", quote=FALSE, sep=\"\\t\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a777c9-9f20-4879-885c-933c74b25db8",
   "metadata": {},
   "source": [
    "### Get descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05451a6-481e-4e99-99fe-15c6ea4f27f7",
   "metadata": {},
   "source": [
    "Get\n",
    "1. Median structural variant lenght of filtered data (BND, CTX excluded)\n",
    "2. Structural variant type frequencies\n",
    "3. Proportion of SVs with allele frequency <1 (including AC=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db209c-aed9-46c5-943b-78cc1ed621db",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#Use dfs from GATK-SV style barplot section \n",
    "\n",
    "#Set wd\n",
    "setwd(\"$PATH2/descriptive_stats_and_fig2\")\n",
    "\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(gmodels)\n",
    "\n",
    "#Import dfs\n",
    "df_LBD <- fread(\"LBD_descriptives_df.txt\")\n",
    "df_FTD <- fread(\"FTD_descriptives_df.txt\")\n",
    "\n",
    "#Get median SVLENs\n",
    "tmp_SVLEN_LBD <- df_LBD %>%\n",
    "  filter(SVTYPE !=\"OTH\") %>%\n",
    "  select(SVLEN)\n",
    "print(paste0(\"LBD median: \",median(tmp_SVLEN_LBD$SVLEN)))\n",
    "\n",
    "tmp_SVLEN_FTD <- df_FTD %>%\n",
    "  filter(SVTYPE !=\"OTH\") %>%\n",
    "  select(SVLEN)\n",
    "print(paste0(\"FTD median: \",median(tmp_SVLEN_FTD$SVLEN)))\n",
    "\n",
    "\n",
    "#Get SVTYPE frequencies\n",
    "###Get SVTTYPE frequencies\n",
    "print(\"LBD SVTYPES\")\n",
    "print(CrossTable(df_LBD$SVTYPE))\n",
    "\n",
    "print(\"FTD SVTYPES\")\n",
    "print(CrossTable(df_FTD$SVTYPE))\n",
    "\n",
    "#Get proportion of MAF<1 % SVs\n",
    "print(\"LBD AF groups\")\n",
    "CrossTable(df_LBD$AF_group)\n",
    "print(\"FTD AF groups\")\n",
    "CrossTable(df_FTD$AF_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9152f-5945-4fe9-a6f9-f897b016f7f1",
   "metadata": {},
   "source": [
    "### Get descriptives by case-control status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05ffdf-cf73-4841-9b4d-a8ca71bca547",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f424bbe-d0cd-4328-a3ec-c3858a576f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#Make R dfs for LBD and FTD case-control status\n",
    "\n",
    "#Set wd\n",
    "setwd(\"$PATH2/descriptive_stats_and_fig2\")\n",
    "\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(scales)\n",
    "\n",
    "########LBD cases\n",
    "\n",
    "df <- fread(\"LBD_cases_high_quality_subset_clean_GQ300missing_all_chr_INFO.txt\")\n",
    "colnames(df) <- c(\"ID\",\"SVTYPE\",\"SVLEN\",\"AF\",\"AC\",\"CHROM\")\n",
    "\n",
    "#Exclude AF=0 SVs\n",
    "df <- df %>%\n",
    "    filter(df$AF > 0)\n",
    "\n",
    "#Rename BND and CTX to OTH\n",
    "df$SVTYPE[df$SVTYPE %in% c(\"BND\",\"CTX\")] <- \"OTH\"\n",
    "\n",
    "#Make SVTYPEs into factors\n",
    "df$SVTYPE <- factor(df$SVTYPE , levels=c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"), labels = c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"))\n",
    "\n",
    "\n",
    "#Add SVLEN and AF groups, add AC=1 separately since threshold varies accordig to number of samples\n",
    "df$SVLEN_group <- cut(df$SVLEN, breaks = c(-2,0,100,500,2500,10000,50000,10^10), labels=c(\"unresolved\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "df$AF_group <- cut(as.numeric(df$AF), breaks = c(0,0.01,0.10,0.50,1), labels=c(\"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "levels(df$AF_group)[5] <- \"AC=1\"\n",
    "df$AF_group[df$AC == 1] <- \"AC=1\"\n",
    "\n",
    "#Save\n",
    "write.table(df, \"LBD_cases_descriptives_df.txt\", quote=FALSE, sep=\"\\t\", row.names = FALSE)\n",
    "\n",
    "rm(df)\n",
    "\n",
    "########LBD controls\n",
    "\n",
    "df <- fread(\"LBD_controls_high_quality_subset_clean_GQ300missing_all_chr_INFO.txt\")\n",
    "colnames(df) <- c(\"ID\",\"SVTYPE\",\"SVLEN\",\"AF\",\"AC\",\"CHROM\")\n",
    "\n",
    "#Exclude AF=0 SVs\n",
    "df <- df %>%\n",
    "    filter(df$AF > 0)\n",
    "\n",
    "#Rename BND and CTX to OTH\n",
    "df$SVTYPE[df$SVTYPE %in% c(\"BND\",\"CTX\")] <- \"OTH\"\n",
    "\n",
    "#Make SVTYPEs into factors\n",
    "df$SVTYPE <- factor(df$SVTYPE , levels=c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"), labels = c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"))\n",
    "\n",
    "\n",
    "#Add SVLEN and AF groups, add AC=1 separately since threshold varies accordig to number of samples\n",
    "df$SVLEN_group <- cut(df$SVLEN, breaks = c(-2,0,100,500,2500,10000,50000,10^10), labels=c(\"unresolved\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "df$AF_group <- cut(as.numeric(df$AF), breaks = c(0,0.01,0.10,0.50,1), labels=c(\"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "levels(df$AF_group)[5] <- \"AC=1\"\n",
    "df$AF_group[df$AC == 1] <- \"AC=1\"\n",
    "\n",
    "#Save\n",
    "write.table(df, \"LBD_controls_descriptives_df.txt\", quote=FALSE, sep=\"\\t\", row.names = FALSE)\n",
    "\n",
    "rm(df)\n",
    "\n",
    "########FTD cases\n",
    "\n",
    "df <- fread(\"FTD_cases_high_quality_subset_clean_GQ300missing_all_chr_INFO.txt\")\n",
    "colnames(df) <- c(\"ID\",\"SVTYPE\",\"SVLEN\",\"AF\",\"AC\",\"CHROM\")\n",
    "\n",
    "#Exclude AF=0 SVs\n",
    "df <- df %>%\n",
    "    filter(df$AF > 0)\n",
    "\n",
    "#Rename BND and CTX to OTH\n",
    "df$SVTYPE[df$SVTYPE %in% c(\"BND\",\"CTX\")] <- \"OTH\"\n",
    "\n",
    "#Make SVTYPEs into factors\n",
    "df$SVTYPE <- factor(df$SVTYPE , levels=c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"), labels = c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"))\n",
    "\n",
    "\n",
    "#Add SVLEN and AF groups, add AC=1 separately since threshold varies accordig to number of samples\n",
    "df$SVLEN_group <- cut(df$SVLEN, breaks = c(-2,0,100,500,2500,10000,50000,10^10), labels=c(\"unresolved\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "df$AF_group <- cut(as.numeric(df$AF), breaks = c(0,0.01,0.10,0.50,1), labels=c(\"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "levels(df$AF_group)[5] <- \"AC=1\"\n",
    "df$AF_group[df$AC == 1] <- \"AC=1\"\n",
    "\n",
    "#Save\n",
    "write.table(df, \"FTD_cases_descriptives_df.txt\", quote=FALSE, sep=\"\\t\", row.names = FALSE)\n",
    "\n",
    "rm(df)\n",
    "\n",
    "########FTD controls\n",
    "\n",
    "df <- fread(\"FTD_controls_high_quality_subset_clean_GQ300missing_all_chr_INFO.txt\")\n",
    "colnames(df) <- c(\"ID\",\"SVTYPE\",\"SVLEN\",\"AF\",\"AC\",\"CHROM\")\n",
    "\n",
    "#Exclude AF=0 SVs\n",
    "df <- df %>%\n",
    "    filter(df$AF > 0)\n",
    "\n",
    "#Rename BND and CTX to OTH\n",
    "df$SVTYPE[df$SVTYPE %in% c(\"BND\",\"CTX\")] <- \"OTH\"\n",
    "\n",
    "#Make SVTYPEs into factors\n",
    "df$SVTYPE <- factor(df$SVTYPE , levels=c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"), labels = c(\"DEL\", \"DUP\", \"CNV\", \"INS\", \"INV\", \"CPX\", \"OTH\"))\n",
    "\n",
    "\n",
    "#Add SVLEN and AF groups, add AC=1 separately since threshold varies accordig to number of samples\n",
    "df$SVLEN_group <- cut(df$SVLEN, breaks = c(-2,0,100,500,2500,10000,50000,10^10), labels=c(\"unresolved\", \"<100bp\", \"100bp-500bp\", \"500bp-2.5kb\", \"2.5kb-10kb\", \"10kb-50kb\", \">50kb\"))\n",
    "df$AF_group <- cut(as.numeric(df$AF), breaks = c(0,0.01,0.10,0.50,1), labels=c(\"AF<1%\", \"1-10%\", \"10-50%\", \">50%\"))\n",
    "levels(df$AF_group)[5] <- \"AC=1\"\n",
    "df$AF_group[df$AC == 1] <- \"AC=1\"\n",
    "\n",
    "#Save\n",
    "write.table(df, \"FTD_controls_descriptives_df.txt\", quote=FALSE, sep=\"\\t\", row.names = FALSE)\n",
    "\n",
    "rm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40e652-0525-429c-bd01-7d1ddf5da370",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#####LBD case and control descriptives\n",
    "#Set wd\n",
    "setwd(\"$PATH2/descriptive_stats_and_fig2\")\n",
    "\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(gmodels)\n",
    "\n",
    "#Import dfs\n",
    "df_LBD_cases <- fread(\"LBD_cases_descriptives_df.txt\")\n",
    "df_LBD_controls <- fread(\"LBD_controls_descriptives_df.txt\")\n",
    "\n",
    "#Add group info\n",
    "df_LBD_controls$V5 <- \"Control\"\n",
    "df_LBD_cases$V5 <- \"Case\"\n",
    "\n",
    "#Merge\n",
    "df <- rbind(df_LBD_cases, df_LBD_controls)\n",
    "colnames(df)[9] <- \"GROUP\"\n",
    "\n",
    "#Get median SVLENs\n",
    "tmp_SVLEN_LBD_cases <- df_LBD_cases %>%\n",
    "  filter(SVTYPE !=\"OTH\") %>%\n",
    "  select(SVLEN)\n",
    "print(paste0(\"LBD_cases median: \",median(tmp_SVLEN_LBD_cases$SVLEN)))\n",
    "\n",
    "tmp_SVLEN_LBD_controls <- df_LBD_controls %>%\n",
    "  filter(SVTYPE !=\"OTH\") %>%\n",
    "  select(SVLEN)\n",
    "print(paste0(\"LBD_controls median: \",median(tmp_SVLEN_LBD_controls$SVLEN)))\n",
    "\n",
    "\n",
    "#Get SVTYPE frequencies\n",
    "###Get SVTTYPE frequencies\n",
    "print(\"LBD_cases SVTYPES\")\n",
    "print(CrossTable(df_LBD_cases$SVTYPE))\n",
    "\n",
    "print(\"LBD_controls SVTYPES\")\n",
    "print(CrossTable(df_LBD_controls$SVTYPE))\n",
    "\n",
    "###Statistical test: compare case-control SVTYPES per SVTYPE\n",
    "m <- as.matrix(table(df$GROUP, df$SVTYPE))\n",
    "print(m)\n",
    "\n",
    "for (i in 1:6) {\n",
    "    m_tmp <- matrix(c(m[1,i],rowSums(m)[1]-m[1,i],m[2,i],rowSums(m)[2]-m[2,i]), ncol = 2, byrow = FALSE)\n",
    "    print(m_tmp)\n",
    "    print(fisher.test(m_tmp))\n",
    "}\n",
    "\n",
    "#Get SVLEn group frequencies\n",
    "print(\"LBD cases SVLENs\")\n",
    "print(CrossTable(df_LBD_cases$SVLEN_group))\n",
    "print(\"LBD controls SVLENs\")\n",
    "print(CrossTable(df_LBD_controls$SVLEN_group))\n",
    "\n",
    "m <- as.matrix(table(df$GROUP, df$SVLEN_group))\n",
    "print(m)\n",
    "\n",
    "for (i in 1:7) {\n",
    "    m_tmp <- matrix(c(m[1,i],rowSums(m)[1]-m[1,i],m[2,i],rowSums(m)[2]-m[2,i]), ncol = 2, byrow = FALSE)\n",
    "    print(m_tmp)\n",
    "    print(fisher.test(m_tmp))\n",
    "}\n",
    "\n",
    "#Get proportion of MAF<1 % SVs\n",
    "print(\"LBD_cases AF groups\")\n",
    "CrossTable(df_LBD_cases$AF_group)\n",
    "print(\"LBD_controls AF groups\")\n",
    "CrossTable(df_LBD_controls$AF_group)\n",
    "\n",
    "m <- as.matrix(table(df$GROUP, df$AF_group))\n",
    "print(m)\n",
    "\n",
    "for (i in 1:5) {\n",
    "    m_tmp <- matrix(c(m[1,i],rowSums(m)[1]-m[1,i],m[2,i],rowSums(m)[2]-m[2,i]), ncol = 2, byrow = FALSE)\n",
    "    print(m_tmp)\n",
    "    print(fisher.test(m_tmp))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec8fa1-794b-4acb-b035-ac0611120d9b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#####FTD case and control descriptives\n",
    "#Set wd\n",
    "setwd(\"$PATH2/descriptive_stats_and_fig2\")\n",
    "\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(gmodels)\n",
    "\n",
    "#Import dfs\n",
    "df_FTD_cases <- fread(\"FTD_cases_descriptives_df.txt\")\n",
    "df_FTD_controls <- fread(\"FTD_controls_descriptives_df.txt\")\n",
    "\n",
    "#Add group info\n",
    "df_FTD_controls$V5 <- \"Control\"\n",
    "df_FTD_cases$V5 <- \"Case\"\n",
    "\n",
    "#Merge\n",
    "df <- rbind(df_FTD_cases, df_FTD_controls)\n",
    "colnames(df)[9] <- \"GROUP\"\n",
    "\n",
    "#Get median SVLENs\n",
    "tmp_SVLEN_FTD_cases <- df_FTD_cases %>%\n",
    "  filter(SVTYPE !=\"OTH\") %>%\n",
    "  select(SVLEN)\n",
    "print(paste0(\"FTD_cases median: \",median(tmp_SVLEN_FTD_cases$SVLEN)))\n",
    "\n",
    "tmp_SVLEN_FTD_controls <- df_FTD_controls %>%\n",
    "  filter(SVTYPE !=\"OTH\") %>%\n",
    "  select(SVLEN)\n",
    "print(paste0(\"FTD_controls median: \",median(tmp_SVLEN_FTD_controls$SVLEN)))\n",
    "\n",
    "\n",
    "#Get SVTYPE frequencies\n",
    "###Get SVTTYPE frequencies\n",
    "print(\"FTD_cases SVTYPES\")\n",
    "print(CrossTable(df_FTD_cases$SVTYPE))\n",
    "\n",
    "print(\"FTD_controls SVTYPES\")\n",
    "print(CrossTable(df_FTD_controls$SVTYPE))\n",
    "\n",
    "m <- as.matrix(table(df$GROUP, df$SVTYPE))\n",
    "print(m)\n",
    "\n",
    "for (i in 1:6) {\n",
    "    m_tmp <- matrix(c(m[1,i],rowSums(m)[1]-m[1,i],m[2,i],rowSums(m)[2]-m[2,i]), ncol = 2, byrow = FALSE)\n",
    "    print(m_tmp)\n",
    "    print(fisher.test(m_tmp))\n",
    "}\n",
    "\n",
    "#Get SVLEn group frequencies\n",
    "print(\"FTD cases SVLENs\")\n",
    "print(CrossTable(df_FTD_cases$SVLEN_group))\n",
    "print(\"FTD controls SVLENs\")\n",
    "print(CrossTable(df_FTD_controls$SVLEN_group))\n",
    "\n",
    "m <- as.matrix(table(df$GROUP, df$SVLEN_group))\n",
    "print(m)\n",
    "\n",
    "for (i in 1:7) {\n",
    "    m_tmp <- matrix(c(m[1,i],rowSums(m)[1]-m[1,i],m[2,i],rowSums(m)[2]-m[2,i]), ncol = 2, byrow = FALSE)\n",
    "    print(m_tmp)\n",
    "    print(fisher.test(m_tmp))\n",
    "}\n",
    "\n",
    "#Get proportion of MAF<1 % SVs\n",
    "print(\"FTD_cases AF groups\")\n",
    "CrossTable(df_FTD_cases$AF_group)\n",
    "print(\"FTD_controls AF groups\")\n",
    "CrossTable(df_FTD_controls$AF_group)\n",
    "\n",
    "m <- as.matrix(table(df$GROUP, df$AF_group))\n",
    "print(m)\n",
    "\n",
    "for (i in 1:5) {\n",
    "    m_tmp <- matrix(c(m[1,i],rowSums(m)[1]-m[1,i],m[2,i],rowSums(m)[2]-m[2,i]), ncol = 2, byrow = FALSE)\n",
    "    print(m_tmp)\n",
    "    print(fisher.test(m_tmp))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a909c-5cd8-4824-a832-06633ef15b37",
   "metadata": {},
   "source": [
    "# Structural variant validation vs. Nanopore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6aca49-c801-4565-a563-e10ac1da8b2f",
   "metadata": {},
   "source": [
    "We have 20 samples that have been also run on Nanopore and SV called with Sniffles2.  \n",
    "\n",
    "Samples:  \n",
    "UMARY634 = RES08390   \n",
    "UMARY1544 = RES08094   \n",
    "UMARY4542 = RES08098   \n",
    "UMARY5077 = RES08391  \n",
    "UMARY1571 = RES08095  \n",
    "UMIC1205 = RES00064   \n",
    "UMIC1527 = RES00275  \n",
    "UMIC1601 = RES00071   \n",
    "UMIC959 = RES08227      \n",
    "BARCS1192 = RES01897  \n",
    "BARCS1429 = RES01877  \n",
    "BARCS1720 = RES01827  \n",
    "BARCS1777 = RES01859  \n",
    "INDU20004038 = RES02284    \n",
    "OREG2142 = RES00032  \n",
    "OREG2595 = RES00048  \n",
    "\n",
    "X4904 = RES05724   \n",
    "X4948 = RES05722   \n",
    "X4980 = RES05720   \n",
    "X5324 = RES05717  \n",
    "\n",
    "Goals:  \n",
    "1. Structural variant validation per-sample per structural variant type\n",
    "2. Genotype concordance of top GWAS hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a1582-6826-4eb2-b557-161c74e16047",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unfiltered data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9debb-b559-4ad2-9f90-05d8721d2223",
   "metadata": {},
   "source": [
    "### Lewy body dementia case/control samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5aa64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Extract each LBD sample of interest separately from 1% GATK-SV (all variants on autosomes), include only SVs with an alternative allele (=exclude 0/0s)\n",
    "module load samtools\n",
    "cd $PATH3/nanopore_vs_sr_validation\n",
    "mkdir SR_vcfs\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs\n",
    "\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    bcftools view \\\n",
    "    -r chr1,chr2,chr3,chr4,chr5,chr6,chr7,chr8,chr9,chr10,chr11,chr12,chr13,chr14,chr15,chr16,chr17,chr18,chr19,chr20,chr21,chr22 \\\n",
    "    --threads $SLURM_CPUS_PER_TASK \\\n",
    "    -s $SAMPLE \\\n",
    "    -Ou \\\n",
    "    /LBD_gatksv_1perc_fdr_cleaned_filters_qual_recalibrated/LBD_1perc_fdr.cleaned_filters_qual_recalibrated.LNGsampleID.vcf.gz \\\n",
    "    | \\\n",
    "    bcftools view -i 'GT[*]=\"alt\"' \\\n",
    "    --threads $SLURM_CPUS_PER_TASK \\\n",
    "    -Oz \\\n",
    "    -o ${SAMPLE}_altgtonly_LBD_1perc_fdr.cleaned_filters_qual_recalibrated.LNGsampleID.vcf.gz \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Index vcfs\n",
    "cd $PATH3//nanopore_vs_sr_validation/SR_vcfs\n",
    "parallel -j1 tabix -p vcf {} ::: *_altgtonly_LBD_1perc_fdr.cleaned_filters_qual_recalibrated.LNGsampleID.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e4189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Split by SV type into separate vcfs\n",
    "module load samtools\n",
    "\n",
    "cd $PATH3//nanopore_vs_sr_validation/SR_vcfs\n",
    "mkdir split_SR_vcfs\n",
    "\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    for svtype in \"DEL\" \"INS\" \"DUP\" \"INV\" \"CPX\"; do \n",
    "        filt=\"SVTYPE=\\\"$svtype\\\"\"\n",
    "        bcftools view -i $filt \\\n",
    "        --threads $SLURM_CPUS_PER_TASK \\\n",
    "        -O z \\\n",
    "        -o split_SR_vcfs/${SAMPLE}_${svtype}_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        ${SAMPLE}_altgtonly_LBD_1perc_fdr.cleaned_filters_qual_recalibrated.LNGsampleID.vcf.gz \n",
    "    done\n",
    "done\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Rename DUP SVtype to INS since that is what sniffles2 for Nanopore (mostly) uses. But keep DUP file separate from INS to be able to differ DUP from INS\n",
    "module load samtools\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs/split_SR_vcfs\n",
    "\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    zcat ${SAMPLE}_DUP_1percfdr_pass_multialleic_alt_SVs.vcf.gz | \\\n",
    "    sed 's/SVTYPE=DUP/SVTYPE=INS/g' > ${SAMPLE}_DUP_as_INS_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "    bgzip ${SAMPLE}_DUP_as_INS_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64c876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Index vcfs \n",
    "module load samtools\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs/split_SR_vcfs\n",
    "\n",
    "parallel -j $SLURM_CPUS_PER_TASK tabix -f -p vcf {} ::: *vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#To match Nanopore format, for INS SR vcfs, make %END = %POS\n",
    "module load bcftools\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs/split_SR_vcfs\n",
    "\n",
    "##Extract needed info\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    bcftools query -f '%CHROM\\t%POS\\t%END\\t%POS\\n' ${SAMPLE}_INS_1percfdr_pass_multialleic_alt_SVs.vcf.gz >  ${SAMPLE}_end_annotation.txt\n",
    "    bgzip -f ${SAMPLE}_end_annotation.txt\n",
    "    tabix -f -s1 -b2 -e3 ${SAMPLE}_end_annotation.txt.gz\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "##Update END flag: but make it STOP named since END cannot be directly altered.\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs/split_SR_vcfs\n",
    "module load bcftools\n",
    "\n",
    "echo \"##INFO=<ID=STOP,Number=1,Type=Integer,Description=\"\"End position of the structural variant\"\">\"  > tmp_stop_header.txt\n",
    "\n",
    "##Add STOP flag and remove END flag, then rename STOP to END\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    bcftools annotate -a ${SAMPLE}_end_annotation.txt.gz -c CHROM,FROM,TO,STOP -x INFO/END -h tmp_stop_header.txt -Oz -o ${SAMPLE}_tmp.vcf.gz ${SAMPLE}_INS_1percfdr_pass_multialleic_alt_SVs.vcf.gz\n",
    "    zcat ${SAMPLE}_tmp.vcf.gz | sed 's/STOP/END/g' > ${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "    bgzip ${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "    tabix -p vcf ${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf.gz\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Split LBD Nanopore vcfs by SV type\n",
    "module load bcftools\n",
    "cd $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2\n",
    "mkdir split_vcfs\n",
    "\n",
    "#Split by SV type into separate vcfs\n",
    "module load samtools\n",
    "\n",
    "SAMPLES_NANOPORE=\"UMARY634 UMARY1544 UMARY4542 UMARY5077 UMARY1571 UMIC1205 UMIC1527 UMIC1601 UMIC959 BARCS1192 BARCS1429 BARCS1720 BARCS1777 INDU2004038 OREG2142 OREG2595\"\n",
    "\n",
    "for SAMPLE in $SAMPLES_NANOPORE; do\n",
    "    for svtype in \"DEL\" \"INS\" \"DUP\" \"INV\"; do \n",
    "        filt=\"SVTYPE=\\\"$svtype\\\"\"\n",
    "        bcftools view -i $filt \\\n",
    "        --threads $SLURM_CPUS_PER_TASK \\\n",
    "        -O z \\\n",
    "        -o split_vcfs/${SAMPLE}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        ${SAMPLE}_fastq_pass.wf_sv.vcf.gz \n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa078b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Index split Nanopore vcfs by SV type\n",
    "cd $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs\n",
    "\n",
    "module load samtools\n",
    "\n",
    "parallel -j $SLURM_CPUS_PER_TASK tabix -p vcf {} ::: *vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Run truvari bench per SV type per sample\n",
    "##Validation criterion are: refdist:200bp, pctsize=0.70, pctsim=0,typeignore=FALSE\n",
    "##So differences in start and ends sites max 200bp (default 500), 70% size overlap (default), no sequence identity since not resolved (default 0.7), SV type must match (default)\n",
    "cd $PATH3/nanopore_vs_sr_validation\n",
    "mkdir truvari_bench\n",
    "\n",
    "source /data/$USER/conda/etc/profile.d/conda.sh && source /data/$USER/conda/etc/profile.d/mamba.sh\n",
    "conda activate truvari\n",
    "\n",
    "###Nanopore samples in same order now than short read samples\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048\"\n",
    "SAMPLES_NANOPORE=\"BARCS1720 BARCS1192 INDU2004038 UMARY5077 UMIC959 UMARY1571 UMARY634 BARCS1777 BARCS1429 UMARY1544 OREG2142 UMIC1205 UMIC1527 UMARY4542 UMIC1601 OREG2595\"\n",
    "\n",
    "\n",
    "##DEL,INV\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=(BARCS1720 BARCS1192 INDU2004038 UMARY5077 UMIC959 UMARY1571 UMARY634 BARCS1777 BARCS1429 UMARY1544 OREG2142 UMIC1205 UMIC1527 UMARY4542 UMIC1601 OREG2595)\n",
    "    for svtype in DEL INV; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c SR_vcfs/split_SR_vcfs/${SAMPLE}_${svtype}_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype} \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "##INS, separately since SR path name is different\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in INS; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c SR_vcfs/split_SR_vcfs/${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype} \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "\n",
    "##Run SR DUPs as INS\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in DUP; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b vcfs_sniffles2/split_vcfs/${array[${i}]}_INS_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c SR_vcfs/split_SR_vcfs/${SAMPLE}_DUP_as_INS_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype} \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43150353-eaa6-4bd7-997e-51dea2ac7dac",
   "metadata": {},
   "source": [
    "### Frontotemporal dementia/amyotrophic lateral sclerosis samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Extract each FTD sample of interest separately, include only SVs with an alternative allele (=exclude 0/0s) \n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs\n",
    "module load samtools\n",
    "\n",
    "FTD_SAMPLES=\"RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $FTD_SAMPLES; do\n",
    "    bcftools view \\\n",
    "    -r chr1,chr2,chr3,chr4,chr5,chr6,chr7,chr8,chr9,chr10,chr11,chr12,chr13,chr14,chr15,chr16,chr17,chr18,chr19,chr20,chr21,chr22 \\\n",
    "    -s $SAMPLE \\\n",
    "    -Ou \\\n",
    "    /FTD_gatksv_1perc_fdr_cleaned_filters_qual_recalibrated/FTD_1perc_fdr.cleaned_filters_qual_recalibrated.LNGsampleID.vcf.gz \\\n",
    "    | \\\n",
    "    bcftools view -i 'GT[*]=\"alt\"' \\\n",
    "    -Oz \\\n",
    "    -o ${SAMPLE}_altgtonly_FTD_1perc_fdr.cleaned_filters_qual_recalibrated.LNGsampleID.vcf.gz \n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Split by SV type into separate vcfs\n",
    "module load samtools\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs\n",
    "\n",
    "FTD_SAMPLES=\"RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $FTD_SAMPLES; do\n",
    "    for svtype in \"DEL\" \"INS\" \"DUP\" \"INV\"; do \n",
    "        filt=\"SVTYPE=\\\"$svtype\\\"\"\n",
    "        bcftools view -i $filt \\\n",
    "        -O z \\\n",
    "        -o split_SR_vcfs/${SAMPLE}_${svtype}_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        ${SAMPLE}_altgtonly_FTD_1perc_fdr.cleaned_filters_qual_recalibrated.LNGsampleID.vcf.gz \n",
    "    done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010194c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Rename DUP SVtype to INS since that is what cuteSV for Nanopore (mostly) uses. But keep DUP file separate from INS to be able to differ DUP from INS\n",
    "module load samtools\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs/split_SR_vcfs\n",
    "\n",
    "FTD_SAMPLES=\"RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $FTD_SAMPLES; do\n",
    "    zcat ${SAMPLE}_DUP_1percfdr_pass_multialleic_alt_SVs.vcf.gz | \\\n",
    "    sed 's/SVTYPE=DUP/SVTYPE=INS/g' > ${SAMPLE}_DUP_as_INS_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "    bgzip ${SAMPLE}_DUP_as_INS_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "done\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ce168",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#To match Nanopore format, for INS SR vcfs, make %END = %POS\n",
    "module load bcftools\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs/split_SR_vcfs\n",
    "\n",
    "##Extract needed info\n",
    "FTD_SAMPLES=\"RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $FTD_SAMPLES; do\n",
    "    bcftools query -f '%CHROM\\t%POS\\t%END\\t%POS\\n' ${SAMPLE}_INS_1percfdr_pass_multialleic_alt_SVs.vcf.gz >  ${SAMPLE}_end_annotation.txt\n",
    "    bgzip -f ${SAMPLE}_end_annotation.txt\n",
    "    tabix -f -s1 -b2 -e3 ${SAMPLE}_end_annotation.txt.gz\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92d8da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "##Update END flag for INS: but make it STOP named since END cannot be directly altered, then rename to END.\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs/split_SR_vcfs\n",
    "module load bcftools\n",
    "\n",
    "echo \"##INFO=<ID=STOP,Number=1,Type=Integer,Description=\"\"End position of the structural variant\"\">\"  > tmp_stop_header.txt\n",
    "\n",
    "##Add STOP flag and remove END flag\n",
    "FTD_SAMPLES=\"RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $FTD_SAMPLES; do\n",
    "    bcftools annotate -a ${SAMPLE}_end_annotation.txt.gz -c CHROM,FROM,TO,STOP -x INFO/END -h tmp_stop_header.txt -Oz -o ${SAMPLE}_tmp.vcf.gz ${SAMPLE}_INS_1percfdr_pass_multialleic_alt_SVs.vcf.gz\n",
    "    zcat ${SAMPLE}_tmp.vcf.gz | sed 's/STOP/END/g' > ${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "    bgzip ${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea604f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Index vcfs \n",
    "module load samtools\n",
    "cd $PATH3/nanopore_vs_sr_validation/SR_vcfs/split_SR_vcfs\n",
    "\n",
    "\n",
    "ls -1 *vcf.gz | parallel -j $SLURM_CPUS_PER_TASK tabix -f -p vcf {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eacfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Split FTD Nanopore vcfs by SV type\n",
    "module load bcftools\n",
    "cd $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2\n",
    "\n",
    "SAMPLES_NANOPORE=\"X5324 X4980 X4948 X4904\"\n",
    "\n",
    "for SAMPLE in $SAMPLES_NANOPORE; do\n",
    "    for svtype in \"DEL\" \"INS\" \"DUP\" \"INV\"; do \n",
    "        filt=\"SVTYPE=\\\"$svtype\\\"\"\n",
    "        bcftools view -i $filt \\\n",
    "        --threads $SLURM_CPUS_PER_TASK \\\n",
    "        -O z \\\n",
    "        -o split_vcfs/${SAMPLE}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        ${SAMPLE}_fastq_pass.wf_sv.vcf.gz \n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f16098",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Index split Nanopore vcfs by SV type\n",
    "cd $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs\n",
    "module load samtools\n",
    "\n",
    "parallel -j1 tabix -f -p vcf {} ::: *vcf.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38361b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Run truvari bench per SV type per sample\n",
    "##Validation criteria are: refdist:200bp, pctsize=0.70, pctsim=0,typeignore=FALSE\n",
    "##So differences in start and ends sites max 200bp (default 500), 70% size overlap (default), no sequence identity since not resolved (default 0.7), SV type must match (default)\n",
    "cd $PATH3/nanopore_vs_sr_validation\n",
    "\n",
    "source /data/$USER/conda/etc/profile.d/conda.sh && source /data/$USER/conda/etc/profile.d/mamba.sh\n",
    "conda activate truvari\n",
    "\n",
    "###Nanopore samples in same order than short read samples!\n",
    "FTD_SAMPLES=\"RES05717 RES05720 RES05722 RES05724\"\n",
    "SAMPLES_NANOPORE=\"X5324 X4980 X4948 X4904\"\n",
    "\n",
    "\n",
    "##DEL,INV\n",
    "i=0\n",
    "for SAMPLE in $FTD_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in DEL INV; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c SR_vcfs/split_SR_vcfs/${SAMPLE}_${svtype}_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype} \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "##INS, separately since SR path name is different\n",
    "i=0\n",
    "for SAMPLE in $FTD_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in INS; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c SR_vcfs/split_SR_vcfs/${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype} \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "\n",
    "##Run SR DUPs as INS\n",
    "i=0\n",
    "for SAMPLE in $FTD_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in DUP; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b vcfs_sniffles2/split_vcfs/${array[${i}]}_INS_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c SR_vcfs/split_SR_vcfs/${SAMPLE}_DUP_as_INS_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype} \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b11a9-e0e6-48ac-92c8-197fd073e11c",
   "metadata": {},
   "source": [
    "### Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf9c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Output precision and genotype concordance per sample per SVtype and outoput all to same file\n",
    "cd $PATH3/nanopore_vs_sr_validation/truvari_bench\n",
    "\n",
    "ALL_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $ALL_SAMPLES; do\n",
    "    for svtype in DEL INV INS DUP; do\n",
    "        echo $SAMPLE $svtype > tmp.txt\n",
    "        grep -e 'precision' -e 'gt_concordance' truvari_bench_${SAMPLE}_${svtype}/summary.txt >> tmp.txt\n",
    "        tr '\\n' ' ' < tmp.txt | sed '$s/ $/\\n/' >> $PATH3/nanopore_vs_sr_validation/results_unfiltered_SR_vs_nanopore_precision_gt_goncordance.txt\n",
    "    done\n",
    "done\n",
    "\n",
    "cat $PATH3/nanopore_vs_sr_validation/results_unfiltered_SR_vs_nanopore_precision_gt_goncordance.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8467309-b530-41a4-a3b1-ef8d6af5a683",
   "metadata": {},
   "source": [
    "## Filtered structural variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c4d9b-92ea-49be-a7e0-f42dd05fe790",
   "metadata": {},
   "source": [
    "### Lewy body dementia and frontotemporal dementia/amyotrophic lateral sclerosis samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73db383-ec1d-4119-93d2-5f96bc43f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/nanopore_validation\n",
    "mkdir SR_vcfs\n",
    "cd SR_vcfs\n",
    "\n",
    "#Extract each LBD sample of interest separately from clean high-quality subset vcfs (autosomes), include only SVs with an alternative allele (=exclude 0/0s)\n",
    "\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "   echo \"bcftools view \\\n",
    "    -s $SAMPLE \\\n",
    "    -Ou \\\n",
    "    $PATH2/clean_high_quality_vcfs/LBD_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz \\\n",
    "    | \\\n",
    "    bcftools view -i 'GT[*]=\\\"alt\\\"' \\\n",
    "    -Oz \\\n",
    "    -o ${SAMPLE}_altgtonly_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz\" >> swarm_extract_samples.swarm\n",
    "done\n",
    "\n",
    "#Run swarm with swarm -t 8 -g 16 --module samtools swarm_extract_samples.swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44b0cc-8242-4cd4-9a2a-50080af407a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/nanopore_validation/SR_vcfs\n",
    "\n",
    "#Extract each FTD sample of interest separately from clean high-quality subset vcfs (autosomes), include only SVs with an alternative allele (=exclude 0/0s)\n",
    "#Add to swarm file\n",
    "SR_SAMPLES=\"RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "   echo \"bcftools view \\\n",
    "    -s $SAMPLE \\\n",
    "    -Ou \\\n",
    "    $PATH2/clean_high_quality_vcfs/FTD_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz \\\n",
    "    | \\\n",
    "    bcftools view -i 'GT[*]=\\\"alt\\\"' \\\n",
    "    -Oz \\\n",
    "    -o ${SAMPLE}_altgtonly_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz\" >> swarm_extract_samples.swarm\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478ba9e-6855-4314-9d1d-80de043bc9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/nanopore_validation/SR_vcfs\n",
    "#Run swarm of sample extraction\n",
    "swarm --partition quick --logdir swarm_logs --time=02:00:00 -t 8 -g 16 --module bcftools swarm_extract_samples.swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07ee38-3125-40b2-a31a-9a79f43be84f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/nanopore_validation/SR_vcfs\n",
    "module load samtools\n",
    "\n",
    "#Index vcfs\n",
    "parallel -j $SLURM_CPUS_PER_TASK tabix -p vcf {} ::: *_altgtonly_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a7f66-b0fb-4fab-8ce2-18ac4f199d1a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/nanopore_validation/SR_vcfs\n",
    "mkdir split_SR_vcfs/\n",
    "module load samtools\n",
    "\n",
    "#Split by SV type into separate vcfs\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    for svtype in \"DEL\" \"INS\" \"DUP\" \"INV\" \"CPX\"; do \n",
    "        filt=\"SVTYPE=\\\"$svtype\\\"\"\n",
    "        bcftools view -i $filt \\\n",
    "        --threads $SLURM_CPUS_PER_TASK \\\n",
    "        -O z \\\n",
    "        -o split_SR_vcfs/clean_${SAMPLE}_${svtype}_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        ${SAMPLE}_altgtonly_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz \n",
    "    done\n",
    "done\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550160a-0a20-402f-b49e-643eaaa2679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs/\n",
    "module load samtools\n",
    "\n",
    "#Rename DUP SVtype to INS since that is what sniffles2 for Nanopore (mostly) uses. But keep DUP file separate from INS to be able to differ DUP from INS\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    zcat clean_${SAMPLE}_DUP_1percfdr_pass_multialleic_alt_SVs.vcf.gz | \\\n",
    "    sed 's/SVTYPE=DUP/SVTYPE=INS/g' > clean_${SAMPLE}_DUP_as_INS_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "    bgzip clean_${SAMPLE}_DUP_as_INS_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774634e-0d45-4a10-801b-a2070c34c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Index vcfs \n",
    "module load samtools\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs\n",
    "\n",
    "parallel -j $SLURM_CPUS_PER_TASK tabix -f -p vcf {} ::: *vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55259de2-e3c9-4cc0-881b-91eccffcb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#To match Nanopore format, for INS SR vcfs, make %END = %POS\n",
    "module load bcftools\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs\n",
    "\n",
    "##Extract needed info\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    bcftools query -f '%CHROM\\t%POS\\t%END\\t%POS\\n' clean_${SAMPLE}_INS_1percfdr_pass_multialleic_alt_SVs.vcf.gz >  clean_${SAMPLE}_end_annotation.txt\n",
    "    bgzip -f clean_${SAMPLE}_end_annotation.txt\n",
    "    tabix -f -s1 -b2 -e3 clean_${SAMPLE}_end_annotation.txt.gz\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa01c1f-7568-400e-b3db-01837813a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "##Update END flag: but make it STOP named since END cannot be directly altered.\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs\n",
    "module load bcftools\n",
    "\n",
    "echo \"##INFO=<ID=STOP,Number=1,Type=Integer,Description=\"\"End position of the structural variant\"\">\"  > tmp_stop_header.txt\n",
    "\n",
    "##Add STOP flag and remove END flag, then rename STOP to END\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    bcftools annotate -a clean_${SAMPLE}_end_annotation.txt.gz -c CHROM,FROM,TO,STOP -x INFO/END -h tmp_stop_header.txt -Oz -o clean_${SAMPLE}_tmp.vcf.gz clean_${SAMPLE}_INS_1percfdr_pass_multialleic_alt_SVs.vcf.gz\n",
    "    zcat clean_${SAMPLE}_tmp.vcf.gz | sed 's/STOP/END/g' > clean_${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "    bgzip clean_${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf\n",
    "    tabix -f -p vcf clean_${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf.gz\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24b7dc-84ee-423a-a8a0-3a1e33f2d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Run truvari bench per SV type per sample for all samples\n",
    "##Validation criterion are: refdist:200bp, pctsize=0.70, pctsim=0,typeignore=FALSE\n",
    "##So differences in start and ends sites max 200bp (default 500), 70% size overlap (default), no sequence identity since not resolved (default 0.7), SV type must match (default)\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs\n",
    "mkdir truvari_bench\n",
    "\n",
    "source /data/$USER/conda/etc/profile.d/conda.sh && source /data/$USER/conda/etc/profile.d/mamba.sh\n",
    "conda activate truvari\n",
    "\n",
    "###Nanopore samples in same order now than short read samples\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "SAMPLES_NANOPORE=\"BARCS1720 BARCS1192 INDU2004038 UMARY5077 UMIC959 UMARY1571 UMARY634 BARCS1777 BARCS1429 UMARY1544 OREG2142 UMIC1205 UMIC1527 UMARY4542 UMIC1601 OREG2595 X5324 X4980 X4948 X4904\"\n",
    "\n",
    "\n",
    "##DEL,INV\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in DEL INV; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c clean_${SAMPLE}_${svtype}_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype} \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "##INS, separately since SR path name is different\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in INS; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c clean_${SAMPLE}_INS_end_is_pos_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype} \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "\n",
    "##Run SR DUPs as INS\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in DUP; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs/${array[${i}]}_INS_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c clean_${SAMPLE}_DUP_as_INS_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype} \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e23320-ae13-44bd-b544-e206db2bba30",
   "metadata": {},
   "source": [
    "### Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc31aa-9a7c-4cc4-8da4-ae2d9049bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Output precision and genotype concordance per sample per SVtype and outoput all to same file\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs/truvari_bench\n",
    "\n",
    "ALL_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "for SAMPLE in $ALL_SAMPLES; do\n",
    "    for svtype in DEL INV INS DUP; do\n",
    "        echo $SAMPLE $svtype > tmp.txt\n",
    "        grep -e 'precision' -e 'gt_concordance' truvari_bench_${SAMPLE}_${svtype}/summary.txt >> tmp.txt\n",
    "        tr '\\n' ' ' < tmp.txt | sed '$s/ $/\\n/' >> $PATH2/nanopore_validation/results_filtered_SR_vs_nanopore_precision_gt_goncordance.txt\n",
    "    done\n",
    "done\n",
    "\n",
    "cat $PATH2/nanopore_validation/results_filtered_SR_vs_nanopore_precision_gt_goncordance.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9737a0-3de8-45dc-81a7-3e36df100d67",
   "metadata": {},
   "source": [
    "## Filtered structural variants - allele frequency <1 % vs >=1 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5be57-b3d9-466f-9245-bee403c3e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load bcftools\n",
    "\n",
    "#Make a list of MAF <1 % and MAF >=1% SVs in LBD and FTD clean autosomal dataset\n",
    "for PHENO in LBD FTD; do\n",
    "    bcftools query -f '%ID %AF\\n' ${PHENO}_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz | awk '($2<0.01) {print $1}' > ${PHENO}_autosomal_clean_AF_under_0.01.txt\n",
    "    bcftools query -f '%ID %AF\\n' ${PHENO}_high_quality_subset_clean_GQ300missing_autosomes.vcf.gz | awk '($2>=0.01) {print $1}' > ${PHENO}_autosomal_clean_AF_over_0.01.txt\n",
    "done\n",
    "\n",
    "#Cat phenotype LBD and FTD ID files per AF group\n",
    "cat LBD_autosomal_clean_AF_under_0.01.txt FTD_autosomal_clean_AF_under_0.01.txt > LBD_FTD_autosomal_clean_AF_under_0.01.txt\n",
    "cat LBD_autosomal_clean_AF_over_0.01.txt FTD_autosomal_clean_AF_over_0.01.txt > LBD_FTD_autosomal_clean_AF_over_0.01.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec52906-69a4-41ab-8813-0c0a5e716f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs\n",
    "module load bcftools\n",
    "#Use previously made properly split and formatted SVTYPE vcfs to split ny MAF\n",
    "ALL_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "##MAF<1%\n",
    "for SAMPLE in $ALL_SAMPLES; do\n",
    "    for svtype in DEL INS_end_is_pos DUP_as_INS INV; do\n",
    "        bcftools view -i 'ID=@$PATH2/clean_high_quality_vcfs/LBD_FTD_autosomal_clean_AF_under_0.01.txt' -Oz -o ${SAMPLE}_${svtype}_MAF_under_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz clean_${SAMPLE}_${svtype}_1percfdr_pass_multialleic_alt_SVs.vcf.gz\n",
    "        tabix -f -p vcf ${SAMPLE}_${svtype}_MAF_under_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz\n",
    "    done\n",
    "done\n",
    "\n",
    "##MAF>=1%\n",
    "for SAMPLE in $ALL_SAMPLES; do\n",
    "    for svtype in DEL INS_end_is_pos DUP_as_INS INV; do\n",
    "        bcftools view -i 'ID=@$PATH2/clean_high_quality_vcfs/LBD_FTD_autosomal_clean_AF_over_0.01.txt' -Oz -o ${SAMPLE}_${svtype}_MAF_over_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz clean_${SAMPLE}_${svtype}_1percfdr_pass_multialleic_alt_SVs.vcf.gz\n",
    "        tabix -f -p vcf ${SAMPLE}_${svtype}_MAF_over_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9877d2-f027-492b-84da-7b42747a3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Run truvari bench per SV type per sample for all samples\n",
    "##Validation criterion are: refdist:200bp, pctsize=0.70, pctsim=0,typeignore=FALSE\n",
    "##So differences in start and ends sites max 200bp (default 500), 70% size overlap (default), no sequence identity since not resolved (default 0.7), SV type must match (default)\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs\n",
    "\n",
    "source /data/$USER/conda/etc/profile.d/conda.sh && source /data/$USER/conda/etc/profile.d/mamba.sh\n",
    "conda activate truvari\n",
    "\n",
    "###Nanopore samples in same order now than short read samples\n",
    "SR_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "SAMPLES_NANOPORE=\"BARCS1720 BARCS1192 INDU2004038 UMARY5077 UMIC959 UMARY1571 UMARY634 BARCS1777 BARCS1429 UMARY1544 OREG2142 UMIC1205 UMIC1527 UMARY4542 UMIC1601 OREG2595 X5324 X4980 X4948 X4904\"\n",
    "\n",
    "##Under 1% MAF\n",
    "###DEL,INV\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in DEL INV; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c ${SAMPLE}_${svtype}_MAF_under_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype}_under_0.01\n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "###INS, separately since SR path name is different\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in INS; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c ${SAMPLE}_${svtype}_end_is_pos_MAF_under_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype}_under_0.01 \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "\n",
    "###Run SR DUPs as INS\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in DUP; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs/${array[${i}]}_INS_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c ${SAMPLE}_${svtype}_as_INS_MAF_under_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype}_under_0.01\n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "\n",
    "##Over 1% MAF\n",
    "###DEL,INV\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in DEL INV; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c ${SAMPLE}_${svtype}_MAF_over_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype}_over_0.01 \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "###INS, separately since SR path name is different\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in INS; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs/${array[${i}]}_${svtype}_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c ${SAMPLE}_${svtype}_end_is_pos_MAF_over_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype}_over_0.01\n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "\n",
    "###Run SR DUPs as INS\n",
    "i=0\n",
    "for SAMPLE in $SR_SAMPLES; do\n",
    "    array=($SAMPLES_NANOPORE)\n",
    "    for svtype in DUP; do\n",
    "        truvari bench \\\n",
    "        --refdist=200 \\\n",
    "        --pctsize=0.70 \\\n",
    "        --pctsim=0 \\\n",
    "        --sizemax=999999999 \\\n",
    "        -b $PATH3/nanopore_vs_sr_validation/vcfs_sniffles2/split_vcfs/${array[${i}]}_INS_fastq_pass.wf_sv.vcf.gz \\\n",
    "        -c ${SAMPLE}_${svtype}_as_INS_MAF_over_0.01_filtered_1percfdr_pass_multialleic_alt_SVs.vcf.gz \\\n",
    "        -f $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "        -o truvari_bench/truvari_bench_${SAMPLE}_${svtype}_over_0.01 \n",
    "    done\n",
    "    i=${i}+1\n",
    "done\n",
    "\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeefb2a-f004-4627-8923-03a0bd67740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Output precision and genotype concordance per sample per SVtype and outoput all to same file\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs/truvari_bench\n",
    "\n",
    "ALL_SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "#MAF under 1%\n",
    "for SAMPLE in $ALL_SAMPLES; do\n",
    "    for svtype in DEL INV INS DUP; do\n",
    "        echo $SAMPLE $svtype > tmp.txt\n",
    "        grep -e 'precision' -e 'gt_concordance' truvari_bench_${SAMPLE}_${svtype}_under_0.01/summary.txt >> tmp.txt\n",
    "        tr '\\n' ' ' < tmp.txt | sed '$s/ $/\\n/' >> $PATH2/nanopore_validation/results_filtered_maf_under_0.01_SR_vs_nanopore_precision_gt_goncordance.txt\n",
    "    done\n",
    "done\n",
    "\n",
    "echo \"Under 1% MAF\"\n",
    "cat $PATH2/nanopore_validation/results_filtered_maf_under_0.01_SR_vs_nanopore_precision_gt_goncordance.txt\n",
    "\n",
    "\n",
    "#MAF over 1%\n",
    "for SAMPLE in $ALL_SAMPLES; do\n",
    "    for svtype in DEL INV INS DUP; do\n",
    "        echo $SAMPLE $svtype > tmp.txt\n",
    "        grep -e 'precision' -e 'gt_concordance' truvari_bench_${SAMPLE}_${svtype}_over_0.01/summary.txt >> tmp.txt\n",
    "        tr '\\n' ' ' < tmp.txt | sed '$s/ $/\\n/' >> $PATH2/nanopore_validation/results_filtered_maf_over_0.01_SR_vs_nanopore_precision_gt_goncordance.txt\n",
    "    done\n",
    "done\n",
    "\n",
    "echo -e \"\\n\"\n",
    "echo \"Over 1% MAF\"\n",
    "cat $PATH2/nanopore_validation/results_filtered_maf_over_0.01_SR_vs_nanopore_precision_gt_goncordance.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eace41-82cd-4f4b-b14e-aa7f5d7e6303",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs/truvari_bench\n",
    "\n",
    "#Check that MAF<1% and MAF >=1% SV counts match (one sample and one SVTYPE)\n",
    "echo \"all\"\n",
    "cat truvari_bench_UMARY-1571_DEL/summary.txt\n",
    "echo \"under 1%\"\n",
    "cat truvari_bench_UMARY-1571_DEL_under_0.01/summary.txt\n",
    "echo \"over 1%\"\n",
    "cat truvari_bench_UMARY-1571_DEL_over_0.01/summary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b209854-d83a-405d-944e-c08733c2945a",
   "metadata": {},
   "source": [
    "Match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f4454-e2f3-4f0d-85a3-19ec9c3638b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs/truvari_bench\n",
    "#Check if there are INV MAF<1% since all are 0 replication\n",
    "cat truvari_bench_*_INV_under_0.01/summary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de81484-4ecc-47ac-ab04-93ae881aa4e0",
   "metadata": {},
   "source": [
    "For all samples, there is 1 INV MAF<1% to be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abaadd7-6b1e-4d44-8fcd-d92f06b18c19",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TPCN1 replication in BBseq/DementiaSeq2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edc6db0-c30d-4eb1-84a0-67411faa7292",
   "metadata": {},
   "source": [
    "## Generate principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1429c0d1-d702-48f7-a390-b3477e74b7b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Generate PCAs for covariates (method copied from Ruth's notebook)\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2\n",
    "mkdir -p PCAcovs\n",
    "\n",
    "module load plink/2.3-alpha\n",
    "module load flashpca/2.0\n",
    "\n",
    "cohort=\"BBSeq_DemSeq2\"\n",
    "\n",
    "##Prune clean plink files\n",
    "for CHNUM in {1..22}; do\n",
    "    plink2 \\\n",
    "    --pfile $PATH6/FILTERED.BBS_RESv2.controls_chr${CHNUM} \\\n",
    "    --allow-no-sex \\\n",
    "    --maf 0.01 \\\n",
    "    --geno 0.01 \\\n",
    "    --hwe 5e-6 \\\n",
    "    --autosome \\\n",
    "    --exclude range $PATH7/GenomicRangeExlusion.forPCA.txt \\\n",
    "    --make-bed \\\n",
    "    --out PCAcovs/temp_chr${CHNUM} \n",
    "done\n",
    "\n",
    "for CHNUM in {1..22}; do\n",
    "    plink2 \\\n",
    "    --bfile PCAcovs/temp_chr${CHNUM} \\\n",
    "    --remove-nosex \\\n",
    "    --geno 0.01 \\\n",
    "    --maf 0.05 \\\n",
    "    --indep-pairwise 1000 10 0.02 \\\n",
    "    --out PCAcovs/temp_pruning_chr${CHNUM} \n",
    "done\n",
    "\n",
    "for CHNUM in {1..22}; do\n",
    "    plink2 \\\n",
    "    --bfile PCAcovs/temp_chr${CHNUM} \\\n",
    "    --remove-nosex \\\n",
    "    --extract PCAcovs/temp_pruning_chr${CHNUM}.prune.in \\\n",
    "    --keep-allele-order \\\n",
    "    --make-bed \\\n",
    "    --out PCAcovs/pruned.${cohort}.controls.UNRELATED_chr${CHNUM} \n",
    "done\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f5eeb-c61a-48e0-8e86-37a83f042c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2\n",
    "module load flashpca/2.0\n",
    "\n",
    "cohort=\"BBSeq_DemSeq2\"\n",
    "\n",
    "##Merge pruned binaries to single file with chr 1-22\n",
    "cat PCAcovs/pruned.${cohort}.controls.UNRELATED_chr1.fam > PCAcovs/pruned.${cohort}.controls.UNRELATED_ALLchr_forPCA.fam\n",
    "for chr in {1..22}; do cat PCAcovs/pruned.${cohort}.controls.UNRELATED_chr${chr}.bim; done > PCAcovs/pruned.${cohort}.controls.UNRELATED_ALLchr_forPCA.bim\n",
    "(echo -en \"\\x6C\\x1B\\x01\"; for chr in {1..22}; do tail -c +4 PCAcovs/pruned.${cohort}.controls.UNRELATED_chr${chr}.bed; done) > PCAcovs/pruned.${cohort}.controls.UNRELATED_ALLchr_forPCA.bed\n",
    "\n",
    "##Calculate/generate PCs based on pruned data set\n",
    "cd PCAcovs\n",
    "flashpca --bfile pruned.${cohort}.controls.UNRELATED_ALLchr_forPCA --suffix _FILTERED.${cohort}.controls.UNRELATED_ALLchr_forPCA --numthreads 19\n",
    "\n",
    "##Move all log files to a new folder\n",
    "mkdir logFiles\n",
    "mv *.log logFiles\n",
    "\n",
    "##Remove intermediate files\n",
    "rm temp_*\n",
    "rm pruned.${cohort}.controls.UNRELATED_chr*.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956491e-8b39-43b5-bea2-8ab2723eb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b7d5e-862f-495a-8e5d-1423f6b3d9a0",
   "metadata": {},
   "source": [
    "## Run manta to genotype TPCN1 deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b59ef-1d8f-45be-a375-f6120fd3cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Prepare manta swarm command \n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/manta_run/crams\n",
    "\n",
    "##Make rest of command file\n",
    "i=1\n",
    "for FILE in replication_TPCN1_crams/*.cram; do\n",
    "    echo \"configManta.py \\\n",
    "    --bam ${FILE} \\\n",
    "    --referenceFasta=$PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta \\\n",
    "    --region=chr12:113244516-113246325 \\\n",
    "    --runDir ../run/run_${i}\" >> swarm_manta_config.swarm\n",
    "    i=$((i+1))\n",
    "done\n",
    "\n",
    "swarm --time=00:10:00 --partition quick -t 2 -g 4 --maxrunning 50 --logdir swarm_logs -m manta swarm_manta_config.swarm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b41a43-3ac1-41fc-9f3f-e4336ec320e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Make a swarm job out of generated commands\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/manta_run/crams\n",
    "\n",
    "cat swarm_logs/swarm*.o | grep 'runWorkflow.py' > ../run/swarm_run_manta.swarm\n",
    "\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/manta_run/run\n",
    "\n",
    "swarm --partition quick --time=00:10:00 -t 10 -g 10 --maxrunning 50 --logdir swarm_logs -m manta swarm_run_manta.swarm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba635713-f0f6-4334-9ac9-e01494901d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Merge all individual SVs into one\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/manta_run/run\n",
    "module load bcftools\n",
    "\n",
    "##Make a list of all SVs in numerical order\n",
    "for i in {1..2353}; do\n",
    "    echo \"run_${i}/results/variants/diploidSV.vcf.gz\" >> merge_vcf_file_list.txt\n",
    "done\n",
    "\n",
    "##Merge\n",
    "bcftools merge --force-samples --missing-to-ref --file-list merge_vcf_file_list.txt -m none -Oz -o ../replication_TPCN1_BBSeq_Demseq2.vcf.gz \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd5298-8e6d-4cf1-a72b-e6100ce9853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Check SVs on that region, should be just one\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/manta_run/\n",
    "module load bcftools\n",
    "\n",
    "bcftools query -f '%ID %POS %END %SVLEN %QUAL\\n' replication_TPCN1_BBSeq_Demseq2.vcf.gz\n",
    "\n",
    "#Check genotype counts\n",
    "bcftools query -f '[%GT\\n]' replication_TPCN1_BBSeq_Demseq2.vcf.gz | sort | uniq -c\n",
    "\n",
    "#Make genotype file\n",
    "bcftools query -f '[%SAMPLE %GT\\n]' replication_TPCN1_BBSeq_Demseq2.vcf.gz > TPCN1_DEL_BBSeq_Demseq2_genotypes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537509bc-9d8c-4189-9a43-0f29307f9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Check GQ distribution\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/manta_run/\n",
    "module load bcftools\n",
    "\n",
    "bcftools query -f '[%GQ\\n]' replication_TPCN1_BBSeq_Demseq2.vcf.gz | awk '($1>30)' | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580bce9-313e-4da9-a0df-fd0232b09d03",
   "metadata": {},
   "source": [
    "Just one SV found and it is the right one! AF= 7.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afde88a-8695-4ffd-b9f5-f089e0c1a2ce",
   "metadata": {},
   "source": [
    "### Run samplot to visually check SV calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be081f50-0132-4fa9-af4b-5a0d76e00469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Make swarm file\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/manta_run/crams\n",
    "\n",
    "find replication_TPCN1_crams -name *.cram  -printf \"%f\\n\" | parallel -j1 echo \"samplot plot -b replication_TPCN1_crams/{} -o plots/{}_replication_TPCN1_del_samplot.pdf -c chr12 -s 113245316 -e 113245625 -w 500 -t DEL -d 0 -q 20 -r $PATH1/Homo_sapiens_assembly38/Homo_sapiens_assembly38.fasta\" >> swarm_samplot.swarm \n",
    "\n",
    "swarm --maxrunning 100 --logdir swarm_logs --module samplot -c 1 -g 2 --partition quick --time=00:05:00 swarm_samplot.swarm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce0dbf-bb3f-4bad-b323-c1df1e58154a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/manta_run/crams\n",
    "\n",
    "source swarm_samplot.swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9a4c2-6f7a-4e76-8991-99da85c67f96",
   "metadata": {},
   "source": [
    "## Lewy body dementias clinical and pathological"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f235310-83e5-408f-823c-da1a252fd5b6",
   "metadata": {},
   "source": [
    "Pathological diagnoses include also \"Lewy body disease\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1ef693-07d8-4134-ad04-08f49ed2810b",
   "metadata": {},
   "source": [
    "### Make phenotype file of all Lewy body dementia samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09378be-42d0-4099-9fae-ac69d9295a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Make phenotype file: pathological LBD/LRP vs controls\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2\n",
    "\n",
    "##Extract LBD cases with a pathological diagnosis\n",
    "awk '($5==\"LBD\") {print $1,$2}' $PATH10/LBD.FTD/Phenotype.BBS_DementiaSeq_v2_harmonized.txt > tmp_LBD_cases.txt\n",
    "\n",
    "##Add BrainBank Seq path LBD/LRP cases\n",
    "awk '{print $1,$1}' $PATH1/BrainBankSeq2022/LBD_samples.txt >> tmp_LBD_cases.txt\n",
    "sort tmp_LBD_cases.txt | uniq | awk '{if(NR==1) {print \"FID\",\"IID\",\"LBD\"} else{print $1,$2,2}}' > pheno_LBD_cases.txt\n",
    "\n",
    "##Make phenotype file by adding Controls\n",
    "awk '{print $1,$1,1}' $PATH1/BrainBankSeq2022/control_samples.txt >> pheno_LBD_cases.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38db50-2756-4557-a2ba-bd55fbbfb953",
   "metadata": {},
   "source": [
    "### Make covariate file and select covariate with step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e73e30-5ddb-44ad-8628-5ffcc4204ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad4191-0bf2-420b-90a7-5bd2c7a41221",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#Combine age and sex info of BBSeq and DemSeq2 (LBD cases) into one file\n",
    "\n",
    "##Set wd\n",
    "setwd(\"$PATH3/replication_TPCN1_BBSeq_Demseq2/\")\n",
    "\n",
    "##Load libraries\n",
    "library(readxl)\n",
    "library(tidyverse)\n",
    "library(data.table)\n",
    "\n",
    "##Import files\n",
    "Phenotypes_LBD_Resolution_v2_genomes <- read_excel(\"Phenotypes_LBD_Resolution_v2_genomes.xlsx\")\n",
    "\n",
    "HBRC_BBSeq_ages <- read_excel(\"HBRC_BBSeq_ages.xlsx\")\n",
    "BrainBankSeq_study_participants <- read_excel(\"BrainBankSeq_study_participants.xlsx\")\n",
    "Banner_cohort_June232020 <- read_excel(\"Banner_cohort_June232020.xlsx\")\n",
    "\n",
    "sample_key <- read_excel(\"sample_key.xlsx\")\n",
    "\n",
    "##Add BBSEq ID to Banner info\n",
    "Banner_cohort_June232020 <- Banner_cohort_June232020[,c(1,5)]\n",
    "Banner_cohort_June232020 <- merge(Banner_cohort_June232020, sample_key, by.x = \"LNG_ID\", by.y = \"Unique Samples\")\n",
    "\n",
    "##Merge BBSeq age info with sex info\n",
    "df <- merge(BrainBankSeq_study_participants, HBRC_BBSeq_ages, by.x = \"Sample_ID\", by.y = \"LNG_ID\", all = TRUE)\n",
    "df <- merge(df, Banner_cohort_June232020, by.x = \"Sample_ID\", by.y = \"LNG_ID.y\", all = TRUE)\n",
    "\n",
    "##Make data frame neater\n",
    "df$Age[df$LNG_ID %like% \"BANN\"] <- df$expired_age[df$LNG_ID %like% \"BANN\"]\n",
    "df$Age[df$`Unique Samples` %like% \"BRC\"] <- df$Age_Death[df$`Unique Samples` %like% \"BRC\"]\n",
    "\n",
    "df <- df[,c(1,5,6,11)]\n",
    "\n",
    "##Concat BBSeq and Demseq2 LBD data\n",
    "Phenotypes_LBD_Resolution_v2_genomes <- Phenotypes_LBD_Resolution_v2_genomes[,c(2,6,3,5)]\n",
    "colnames(Phenotypes_LBD_Resolution_v2_genomes) <- colnames(df)\n",
    "\n",
    "df <- rbind(df,Phenotypes_LBD_Resolution_v2_genomes)\n",
    "\n",
    "##Drop samples with empty values\n",
    "df <- drop_na(df)\n",
    "\n",
    "##Some samples have age as a range, e.g. 60-69. CHange to middle pointt of range e.g. 65.\n",
    "print(table(df$Age[df$Age %like% \"-\"]))\n",
    "df$Age[df$Age == \"50 - 59\"] <- 55\n",
    "df$Age[df$Age == \"60 - 69\"] <- 65\n",
    "df$Age[df$Age == \"70 - 79\"] <- 75\n",
    "df$Age[df$Age == \"80 - 89\"] <- 85\n",
    "##Save as a covar file\n",
    "write.table(df, file=\"BBSeq_DEMSeq2LBD_age_sex_status.txt\", sep=\"\\t\", quote = FALSE, row.names = FALSE)\n",
    "\n",
    "##N.B! In covar file, 23 titled with \"control\" are marked as cases. They are properly controls in the phenotype file.\n",
    "##Likely due to dicrepancy between BBSeq specification and file from Ruth/Sonja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a5449-2862-4003-812a-dedf651197ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#Make covar file\n",
    "#Visualize PCs/Find outliers: no need to exclude, ethnicity outliers previously excluded\n",
    "#Also find covariates to adjust for\n",
    "\n",
    "##Load libraries\n",
    "library(tidyverse)\n",
    "library(data.table)\n",
    "library(ggplot2) \n",
    "\n",
    "##Set wd\n",
    "setwd(\"$PATH3/replication_TPCN1_BBSeq_Demseq2/PCAcovs\")\n",
    "\n",
    "##Import file PC and phenotype file\n",
    "pcs <- fread(\"pcs_FILTERED.BBSeq_DemSeq2.controls.UNRELATED_ALLchr_forPCA\")\n",
    "pheno <- fread(\"$PATH10/LBD.FTD/Phenotype.BBS_DementiaSeq_v2_harmonized.txt\")\n",
    "age <- fread(\"../BBSeq_DEMSeq2LBD_age_sex_status.txt\")\n",
    "age <- age[,c(1,4)]\n",
    "\n",
    "##Merge\n",
    "df <- merge(pcs,pheno, by= c(\"FID\",\"IID\"))\n",
    "df <- merge(df, age, by.x = \"IID\", by.y = \"Sample_ID\" )\n",
    "\n",
    "\n",
    "##Plot\n",
    "print(ggplot(df, aes(x=PC1, y=PC2, color = as.factor(AFFECTION_STATUS))) +\n",
    "    geom_point())\n",
    "print(ggplot(df, aes(x=PC1, y=PC2, color = as.factor(SEX))) +\n",
    "    geom_point())\n",
    "print(ggplot(df, aes(x=PC1, y=PC2, color = COHORT)) +\n",
    "    geom_point())\n",
    "\n",
    "##Neatify df\n",
    "df <- df[,c(2,1,3:14,24,15)]\n",
    "df <- drop_na(df)\n",
    "\n",
    "##Save df as a covariate file\n",
    "write.table(df, file=\"../BBSeq_Demseq2_covariates.txt\", sep=\"\\t\", quote = FALSE, row.names = FALSE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131584cb-b785-481a-a466-33512e96f99d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#Find covariates to adjust for\n",
    "\n",
    "##Set wd\n",
    "setwd(\"$PATH3/replication_TPCN1_BBSeq_Demseq2/\")\n",
    "\n",
    "##Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "\n",
    "##Import files and make pheno 0-1 not 1-2\n",
    "pheno <- fread(\"pheno_LBD_cases.txt\")\n",
    "pheno$LBD <- pheno$LBD - 1\n",
    "\n",
    "covars <- fread(\"BBSeq_Demseq2_covariates.txt\")\n",
    "\n",
    "##Merge\n",
    "COVS <- merge(covars, pheno, by = c(\"FID\",\"IID\"))\n",
    "COVS$Age <- as.numeric(COVS$Age)\n",
    "print(head(COVS))\n",
    "print(table(COVS$path_LBD))\n",
    "\n",
    "## Run step() to determine which covariate is most important\n",
    "## model using glm() and then use step() to determine the model that has the lowest AIC\n",
    "## this tell us which covariates you included in the model are important to use/for adjustment in your analysis\n",
    "model <- glm(LBD ~ SEX + Age + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 , data = COVS, family = \"binomial\"(link = \"logit\"))\n",
    "print(summary(model))\n",
    "step(model)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619cf1c9-124a-4455-8715-9ba19ef1a749",
   "metadata": {},
   "source": [
    "### Run association analysis on SNPs/Indels of TPCN1 block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88d25d-b2a8-4445-85cf-7a01a4da085a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Run glm on the TPCN1 LD block, use only clean variants from Ruth's analysis\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2\n",
    "module load plink/2.3-alpha\n",
    "\n",
    "##Clean variants from Ruth's files\n",
    "awk '($4 > 113150000 && $4<113350000){print $2}' $PATH5/LBD_minGQ300/SNVindels.LBD.UNRELATED.forMerging.chr12.bim > clean_TPCN1_LD_block_SNV_indels.txt\n",
    "\n",
    "plink2 \\\n",
    "--pfile $PATH6/FILTERED.BBS_RESv2.controls_chr12 \\\n",
    "--glm cols=+a1freqcc hide-covar \\\n",
    "--ci 0.95 \\\n",
    "--remove $PATH6/FILTERED.BBS_RESv2.to.remove.relatedSamples_FID_IID.txt \\\n",
    "--pheno pheno_LBD_cases.txt \\\n",
    "--pheno-name LBD \\\n",
    "--extract clean_TPCN1_LD_block_SNV_indels.txt \\\n",
    "--maf 0.01 \\\n",
    "--covar BBSeq_Demseq2_covariates.txt \\\n",
    "--covar-name Age,PC1,PC2,PC3,PC4,PC5 \\\n",
    "--covar-variance-standardize \\\n",
    "--out LBD_vs_controls \\\n",
    "--write-samples\n",
    "\n",
    "#Grep rs6489896 from the results\n",
    "grep -e 'CHROM' -e '113281983' LBD_vs_controls.LBD.glm.logistic.hybrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f4f7a-e047-4ea9-ad71-bda006b7196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/\n",
    "#Extract number of analyzed samples per case-control status\n",
    "#Files contained 567 cases and 274 controls (=862), but plink has used data from 829\n",
    "\n",
    "##Print samples with covariates\n",
    "awk '(NR>1) {print $1}' BBSeq_Demseq2_covariates.txt > tmp.txt\n",
    "\n",
    "##Union of samples with covariates and pheno after exclusions\n",
    "grep -wFf tmp.txt pheno_LBD_cases.txt | awk '{print $1}' > tmp2.txt\n",
    "\n",
    "\n",
    "##union of samples after exclusion etc and with covar and pheno data\n",
    "grep -wFf tmp2.txt LBD_vs_controls.id | awk '{print $1}' > tmp_analyzed_samples.txt\n",
    "wc -l tmp_analyzed_samples.txt\n",
    "\n",
    "#Get number of cases and controls\n",
    "grep -wFf tmp_analyzed_samples.txt pheno_LBD_cases.txt | awk '{print $3}' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64282b-4dd1-4ee8-ac30-53dfc5853d30",
   "metadata": {},
   "source": [
    "### Run association analysis with structural variant calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f83885-a24a-4dde-b8aa-9dd4bce46ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Run PLINK2 glm\n",
    "##To get same samples as in SNP analysis, include samples in SNP analysis\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/\n",
    "module load plink/2.3-alpha\n",
    "\n",
    "##Samples in SNP data\n",
    "awk '{print $1,$2}' $PATH6/FILTERED.BBS_RESv2.controls_chr12.psam > FILTERED.BBS_RESv2.controls_IDs.txt\n",
    "plink2 \\\n",
    "--vcf $PATH3/replication_TPCN1_BBSeq_Demseq2/manta_run/replication_TPCN1_BBSeq_Demseq2.vcf.gz \\\n",
    "--double-id \\\n",
    "--glm cols=+a1freqcc hide-covar \\\n",
    "--ci 0.95 \\\n",
    "--keep FILTERED.BBS_RESv2.controls_IDs.txt \\\n",
    "--remove $PATH6/FILTERED.BBS_RESv2.to.remove.relatedSamples_FID_IID.txt \\\n",
    "--pheno pheno_LBD_cases.txt \\\n",
    "--pheno-name LBD \\\n",
    "--maf 0.01 \\\n",
    "--covar BBSeq_Demseq2_covariates.txt \\\n",
    "--covar-name Age,PC1,PC2,PC3,PC4,PC5 \\\n",
    "--covar-variance-standardize \\\n",
    "--out LBD_vs_controls_manta_SV_calls\n",
    "\n",
    "cat LBD_vs_controls_manta_SV_calls.LBD.glm.logistic.hybrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4623ff3-c56b-4afc-94a6-65067e5c119a",
   "metadata": {},
   "source": [
    "### Meta-analysis of structural variant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b95131-deaa-4024-9d2a-16f40e0d1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/\n",
    "#Format files\n",
    "\n",
    "##Replication data\n",
    "###Change SV ID so it matches GATK-SV\n",
    "awk '{if(NR >1) {$3=\"LBD_DEL_chr12_9172\"} print}' LBD_vs_controls_manta_SV_calls.LBD.glm.logistic.hybrid > tmp_all_LBD_SV_replication_to_metal.txt\n",
    "\n",
    "###Add beta column, chnage REF to N and ALT to <DEL>\n",
    "awk '{if(NR==1) {$17=\"BETA\"} else{$17 = log($12)} print}' tmp_all_LBD_SV_replication_to_metal.txt > tmp2_all_LBD_SV_replication_to_metal.txt\n",
    "awk '{if(NR>1) {$4 = \"N\"} print}' tmp2_all_LBD_SV_replication_to_metal.txt > tmp3_all_LBD_SV_replication_to_metal.txt\n",
    "awk '{if(NR>1) {$5 = \"<DEL>\"} print}' tmp3_all_LBD_SV_replication_to_metal.txt > all_LBD_SV_replication_to_metal.txt\n",
    "\n",
    "rm tmp*_LBD_SV_replication_to_metal.txt\n",
    "\n",
    "##GATK-SV joint LBD data\n",
    "###Extract SV of interest\n",
    "grep -e 'CHROM' -e 'LBD_DEL_chr12_9172' $PATH5/Analysis.GLM.hg38_minGQ300/LBD/LBD.controls.UNRELATED.SNVindels.SV.glm.hwe1e-6.maf005.ALLchr.txt > tmp_LBD_SV_GATKSV_joint_to_metal.txt\n",
    "\n",
    "###Add BETA column\n",
    "awk '{if(NR==1) {$24=\"BETA\"} else{$24 = log($19)} print}' tmp_LBD_SV_GATKSV_joint_to_metal.txt > LBD_SV_GATKSV_joint_to_metal.txt\n",
    "rm tmp_LBD_SV_GATKSV_joint_to_metal.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710875b5-27f7-4ce9-a1f6-ee62ca100b7b",
   "metadata": {},
   "source": [
    "#Commands to run METAL\n",
    "module load metal\n",
    "metal  \n",
    "MARKER ID  \n",
    "ALLELE ALT REF  \n",
    "PVALUE P  \n",
    "EFFECT BETA \n",
    "WEIGHTLABEL OBS_CT  \n",
    "STDERRLABEL LOG(OR)_SE    \n",
    "SCHEME STDERR  \n",
    "OUTFILE TPCN1_DEL_LBDjoint_all_LBD_replication .TBL  \n",
    "PROCESS all_LBD_SV_replication_to_metal.txt  \n",
    "PROCESS LBD_SV_GATKSV_joint_to_metal.txt  \n",
    "ANALYZE  \n",
    "QUIT  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d28f42-c4cc-474a-8627-22dcf947567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2/\n",
    "#Check meta result\n",
    "cat TPCN1_DEL_LBDjoint_all_LBD_replication1.TBL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7a74f-7669-40d6-bcfa-686a1449025c",
   "metadata": {},
   "source": [
    "# 50 neurodegenerative disease genes gene-set analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0016d9-ae94-4752-b464-8d7b8a092ff4",
   "metadata": {},
   "source": [
    "## File preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e51e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe8cb8-10f2-4479-9827-df94fcd6fc16",
   "metadata": {},
   "source": [
    "### Subset 50 neurodegenerative disease gene regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f6b94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Create candidate-gene files from 1%FDR GQ300 clean files, code from Ruth's notebook\n",
    "\n",
    "cd $PATH8/DataSubset.50NDD\n",
    "\n",
    "module load plink/2.3-alpha\n",
    "\n",
    "DATA=\"$PATH2/clean_high_quality_vcfs\"\n",
    "OUT=\"$PATH1/NIH_FALL_2021_SVs_1percFDR\"\n",
    "\n",
    "mkdir $OUT/LBD_NDD_plink_files/\n",
    "mkdir $OUT/FTD_NDD_plink_files/\n",
    "\n",
    "## Extract regions specific to each gene from clean vcfs\n",
    "\n",
    "### LBD\n",
    "cohort=\"LBD\"\n",
    "for FILE in CLEAN.knownGenes.plink/Gene_Locs/*.txt;\n",
    "do\n",
    "GENE=`awk 'NR==1{print $4}' $FILE`\n",
    "GENE=$(echo \"$GENE\" | tr -d '\\r')\n",
    "\n",
    "plink2 \\\n",
    "--vcf $DATA/${cohort}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz \\\n",
    "--extract range $FILE \\\n",
    "--keep $DATA/tmp_${cohort}_analyzed_samples.txt \\\n",
    "--allow-no-sex \\\n",
    "--keep-allele-order \\\n",
    "--make-pgen \\\n",
    "--out $OUT/LBD_NDD_plink_files/SV.${cohort}.keepRelated.subsetKnownGenes.flank1Mb.$GENE\n",
    "done\n",
    "\n",
    "### FTD\n",
    "cohort=\"FTD\"\n",
    "for FILE in CLEAN.knownGenes.plink/Gene_Locs/*.txt;\n",
    "do\n",
    "GENE=`awk 'NR==1{print $4}' $FILE`\n",
    "GENE=$(echo \"$GENE\" | tr -d '\\r')\n",
    "\n",
    "plink2 \\\n",
    "--vcf $DATA/${cohort}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz \\\n",
    "--extract range $FILE \\\n",
    "--keep $DATA/tmp_${cohort}_analyzed_samples.txt \\\n",
    "--allow-no-sex \\\n",
    "--keep-allele-order \\\n",
    "--make-pgen \\\n",
    "--out $OUT/FTD_NDD_plink_files/SV.${cohort}.keepRelated.subsetKnownGenes.flank1Mb.$GENE\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306ff9b3-5973-403c-a677-5cc2d49cd5e8",
   "metadata": {},
   "source": [
    "### Create vcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa475762",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Make one vcf file per gene (create output folders first), for loop over gene names\n",
    "HOME=\"$PATH1/NIH_FALL_2021_SVs_1percFDR\"\n",
    "cd $HOME\n",
    "\n",
    "mkdir vcfs_LBD/\n",
    "mkdir vcfs_FTD/\n",
    "\n",
    "module load plink/2.3-alpha\n",
    "\n",
    "for pheno in LBD FTD; do\n",
    "    for gene in $(ls -1 $PATH1/NIH_FALL_2021_SVs/NIH_files/CLEAN.knownGenes.plink/Gene_Locs/ | awk -F\".\" '{print $1}'); do\n",
    "        plink2 \\\n",
    "        --pfile ${pheno}_NDD_plink_files/SV.${pheno}.keepRelated.subsetKnownGenes.flank1Mb.${gene} \\\n",
    "        --export vcf id-paste=iid \\\n",
    "        --out vcfs_${pheno}/SV.${pheno}.keepRelated.subsetKnownGenes.flank1Mb.${gene}\n",
    "    done\n",
    "done\n",
    "\n",
    "#Bgzip and index vcfs. Concatenate all vcfs into one master vcf for all SV case-control frequency calculations\n",
    "module load samtools\n",
    "\n",
    "for pheno in LBD FTD; do\n",
    "    cd $HOME/vcfs_${pheno}/\n",
    "    ls *vcf -1  | parallel -j 20 bgzip {}\n",
    "    ls *vcf.gz -1 | parallel -j 20 tabix -f -p vcf {}\n",
    "\n",
    "    ls *vcf.gz -1 > ${pheno}_vcfs.txt\n",
    "    bcftools concat -a -f ${pheno}_vcfs.txt -O v -o NDD_all_vcfs.vcf\n",
    "    bcftools sort NDD_all_vcfs.vcf -O v -o NDD_all_vcfs_sorted.vcf\n",
    "    bgzip NDD_all_vcfs_sorted.vcf\n",
    "    tabix -f -p vcf NDD_all_vcfs_sorted.vcf.gz\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2aa6d-bea2-43a2-9d54-cd425378b71a",
   "metadata": {},
   "source": [
    "### Case-control allele frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3e93b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "HOME=\"$PATH1/NIH_FALL_2021_SVs_1percFDR\"\n",
    "cd $HOME\n",
    "\n",
    "#Make plink2 files from master vcf (N.B. some variants are duplicates because overlap multiple genes)\n",
    "module load plink/2.3-alpha\n",
    "\n",
    "for pheno in LBD FTD;do\n",
    "    plink2 \\\n",
    "    --vcf vcfs_${pheno}/NDD_all_vcfs_sorted.vcf.gz \\\n",
    "    --double-id \\\n",
    "    --make-pgen \\\n",
    "    --out vcfs_${pheno}/NDD_all_${pheno}\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee20fe2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "HOME=\"$PATH1/NIH_FALL_2021_SVs_1percFDR\"\n",
    "cd $HOME\n",
    "\n",
    "#Calculate case and control allele frequencies, first subset use any original psam that includes phenotype data based on samples to keep as new psam file\n",
    "module load plink/2.3-alpha\n",
    "\n",
    "mkdir freqs_LBD/\n",
    "mkdir freqs_FTD/\n",
    "\n",
    "##Create covar files for subsetting\n",
    "\n",
    "cut -f1,2,3,4,5,8,13,14,15,16,17,18,19,20,21,22,23,24 $PATH5/COVARIATES.SNVindels.SV.freeze9.LBD.controls.UNRELATED_minGQ300.txt > $HOME/COVARIATES.SNVindels.SV.freeze9.LBD.controls.UNRELATED_minGQ300_relevant_columns.txt\n",
    "cut -f1,2,3,4,5,8,13,14,15,16,17,18,19,20,21,22,23,24 $PATH5/COVARIATES.SNVindels.SV.freeze9.FTD.controls.UNRELATED_minGQ300.txt > $HOME/COVARIATES.SNVindels.SV.freeze9.FTD.controls.UNRELATED_minGQ300_relevant_columns.txt\n",
    "\n",
    "##Calculate AFs\n",
    "for pheno in LBD FTD; do\n",
    "    plink2 \\\n",
    "    --pfile vcfs_${pheno}/NDD_all_${pheno} \\\n",
    "    --freq \\\n",
    "    --covar COVARIATES.SNVindels.SV.freeze9.${pheno}.controls.UNRELATED_minGQ300_relevant_columns.txt \\\n",
    "    --keep-if AFFECTION_STATUS=2 \\\n",
    "    --out freqs_${pheno}/freqs_${pheno}_cases \n",
    "    \n",
    "    plink2 \\\n",
    "    --pfile vcfs_${pheno}/NDD_all_${pheno} \\\n",
    "    --freq \\\n",
    "    --covar COVARIATES.SNVindels.SV.freeze9.${pheno}.controls.UNRELATED_minGQ300_relevant_columns.txt \\\n",
    "    --keep-if AFFECTION_STATUS=1 \\\n",
    "    --out freqs_${pheno}/freqs_${pheno}_controls\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e417a-7db7-4c27-903c-aa024565cbfa",
   "metadata": {},
   "source": [
    "### CADD-SV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Prepare input file: make bed from vcf, add chr prefix and sort\n",
    "source /data/$USER/conda/etc/profile.d/conda.sh\n",
    "conda activate prepBED\n",
    "\n",
    "for pheno in LBD FTD; do\n",
    "    SURVIVOR vcftobed $PATH1/NIH_FALL_2021_SVs_1percFDR/vcfs_${pheno}/NDD_all_vcfs.vcf 0 -1 $PATH1/CADD-SV-1.1/beds/output_${pheno}_1percFDR.bed\n",
    "    awk 'OFS=\"\\t\"{print \"chr\"$1,$2,$6,$11,$7}' $PATH1/CADD-SV-1.1/beds/output_${pheno}_1percFDR.bed > $PATH1/CADD-SV-1.1/beds/tmp_${pheno}_1percFDR.bed\n",
    "    sort -k1,1 -k2,2n $PATH1/CADD-SV-1.1/beds/tmp_${pheno}_1percFDR.bed > $PATH1/CADD-SV-1.1/input/id_${pheno}_1percFDR_NDD_all_vcfs_sorted.bed\n",
    "done\n",
    "\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751e451-f125-45b3-b057-1dca718444f7",
   "metadata": {},
   "source": [
    "**N.B.! Manually enter set id to config file (wirhout id_ prefix and bed suffix)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac87a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $PATH1/CADD-SV-1.1/config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa17328",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Initialize conda environment to run CADD-SV for LBD. Needs enough memory, otherwise process will be killed.\n",
    "source /data/$USER/conda/etc/profile.d/conda.sh\n",
    "conda activate run.caddsv\n",
    "\n",
    "cd $PATH1/CADD-SV-1.1\n",
    "module load R\n",
    "snakemake  --use-conda --configfile config.yml -j $SLURM_CPUS_PER_TASK \n",
    "\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1208a09-af59-43ce-b80f-eb0be96ad83d",
   "metadata": {},
   "source": [
    "**N.B.! Manually enter set id to config file (wirhout id_ prefix and bed suffix)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $PATH1/CADD-SV-1.1/config_FTD.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ce545",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Initialize conda environment to run CADD-SV for FTD. \n",
    "source /data/$USER/conda/etc/profile.d/conda.sh\n",
    "conda activate run.caddsv\n",
    "\n",
    "cd $PATH1/CADD-SV-1.1\n",
    "module load R\n",
    "snakemake  --use-conda --configfile config_FTD.yml -j $SLURM_CPUS_PER_TASK\n",
    "\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f347a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Check number of scored SVs (not all SV types are scoreable by CADD)\n",
    "\n",
    "wc -l $PATH1/CADD-SV-1.1/output/LBD_1percFDR_NDD_all_vcfs_sorted_score.bed\n",
    "wc -l $PATH1/CADD-SV-1.1/output/FTD_1percFDR_NDD_all_vcfs_sorted_score.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f7b84-08be-4809-9cdb-2457a8635134",
   "metadata": {},
   "source": [
    "### GeneHancer regulatory elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a17ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import to python\n",
    "genehancer = pd.read_csv(\"$PATH1/NIH_FALL_2021_SVs/genhancer_candidate_gene_regions_genecards.txt\", sep=\"\\t\")\n",
    "genehancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e96fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select only relevant columns, i.e. geneHancerStart, geneHancerEnd, geneHancerIdentifier and geneName\n",
    "genehancer = genehancer[[\"Start\", \"End\", \"GHIDs\", \"Symbol\"]]\n",
    "\n",
    "#Rename columns like they were in previous versions to ensure all works\n",
    "genehancer.rename(columns={\"Start\":\"geneHancerStart\", \"End\":\"geneHancerEnd\", \"GHIDs\":\"geneHancerIdentifier\", \"Symbol\":\"geneName\"}, inplace=True)\n",
    "genehancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9121936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test if all geneHancerEnd > genehancerStart\n",
    "genehancer[(genehancer[\"geneHancerEnd\"] < genehancer[\"geneHancerStart\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa578aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prior to checking overlaps, change in genehancer data frame PRKN to PARK2\n",
    "genehancer = genehancer.replace(to_replace=\"PRKN\", value=\"PARK2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5221f4-691f-4179-b05e-44fb633700d7",
   "metadata": {},
   "source": [
    "## Lewy body dementias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae976a6e-672c-4629-b6d7-5ae0ccc57e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"$PATH1/NIH_FALL_2021_SVs_1percFDR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6395974-97b8-4c24-8fe7-026b88979c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c297a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#For each vcf (one per gene), print only columns of interest with gene name added as one of the columns.\n",
    "#All columns are separated by tab, sample names with alt allele are separated with single space and their genotype with \":\"\n",
    "\n",
    "cd $PATH1/NIH_FALL_2021_SVs_1percFDR\n",
    "mkdir SV_text_files_LBD\n",
    "\n",
    "module load bcftools\n",
    "\n",
    "for gene in $(ls -1 $PATH1/NIH_FALL_2021_SVs/NIH_files/CLEAN.knownGenes.plink/Gene_Locs/ | awk -F\".\" '{print $1}'); do\n",
    "    bcftools query -f \"%CHROM\\t%POS\\t%END\\t%ID\\t%REF\\t%ALT\\t%QUAL\\t${gene}\\t%FILTER\\t%SVLEN\\t%ALGORITHMS\\t%EVIDENCE\\t[%SAMPLE:%GT ]\\n\" vcfs_LBD/SV.LBD.keepRelated.subsetKnownGenes.flank1Mb.${gene}.vcf.gz > SV_text_files_LBD/LBD_${gene}_to_pandas.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8060ced9-62b5-4b95-968e-c0396df0ed50",
   "metadata": {},
   "source": [
    "### Import vcfs into pandas as the main data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cced10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of files to be concatenated\n",
    "csv_file_list = glob.glob(\"$PATH1/NIH_FALL_2021_SVs_1percFDR/SV_text_files_LBD/*to_pandas.txt\")\n",
    "\n",
    "#Make a list of data frames\n",
    "list_of_dataframes = []\n",
    "\n",
    "for filename in csv_file_list:\n",
    "    list_of_dataframes.append(pd.read_csv(filename, sep=\"\\t\", header=None))\n",
    "  \n",
    "\n",
    "#Merge individual data frames into one\n",
    "NDD_all_LBD = pd.concat(list_of_dataframes, axis=0, join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b853234b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add column names, columns are in the same order as vcf was queried with bcftools\n",
    "NDD_all_LBD.columns = [\"CHROM\",\"POS\",\"END\",\"ID\",\"REF\",\"ALT\",\"QUAL\", \"GENE\", \"FILTER\",\"SVLEN\",\"ALGORITHMS\",\"EVIDENCE\",\"SAMPLES\"]\n",
    "NDD_all_LBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f193178-c6ec-46b3-ab79-920d4bef2174",
   "metadata": {},
   "source": [
    "### Import case-control allele frequencies and add them to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9600e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import case and control allele frequencies, rename columns and select only relevant columns. Drop duplicates before merging\n",
    "\n",
    "LBD_freqs = pd.read_csv(\"$PATH1/NIH_FALL_2021_SVs_1percFDR/freqs_LBD/freqs_LBD_cases.afreq\", sep=\"\\s+\")\n",
    "LBD_freqs.rename(columns={'ALT_FREQS': 'LBD_ALT_FREQS'}, inplace=True)\n",
    "LBD_freqs = LBD_freqs.iloc[:,[1,4]]\n",
    "LBD_freqs.drop_duplicates(inplace=True)\n",
    "\n",
    "LBD_controls_freqs = pd.read_csv(\"$PATH1/NIH_FALL_2021_SVs_1percFDR/freqs_LBD/freqs_LBD_controls.afreq\", sep=\"\\s+\")\n",
    "LBD_controls_freqs.rename(columns={'ALT_FREQS': 'controls_ALT_FREQS'}, inplace=True)\n",
    "LBD_controls_freqs = LBD_controls_freqs.iloc[:,[1,4]]\n",
    "LBD_controls_freqs.drop_duplicates(inplace=True)\n",
    "\n",
    "LBD_freqs = LBD_freqs.merge(LBD_controls_freqs, on = \"ID\", how=\"outer\")\n",
    "LBD_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7300db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add case-control frequencies to data frame (some SVs are >1 times because they overlap >1 genes of interest)\n",
    "NDD_all_LBD = NDD_all_LBD.merge(LBD_freqs, on=\"ID\")\n",
    "NDD_all_LBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea292510-41d5-44df-a519-6cd2e2d7161d",
   "metadata": {},
   "source": [
    "### List only sample IDs that have minor (mostly alternative) allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc3d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split sample id strings (separated by single space) into a list. List items are strings of format ID:Genotype\n",
    "#If frequncy in controls < 0.5, alt allele is minor allele and keep only sample names that contain /1 (0/1 or 1/1)\n",
    "#If frequncy in controls > 0.5, ref allele is minor allele and keep only sample names that contain 0/ (0/0 or 0/1)\n",
    "\n",
    "geno_df = pd.DataFrame()\n",
    "for i in range(0, len(NDD_all_LBD)):\n",
    "    if NDD_all_LBD[\"controls_ALT_FREQS\"][i] < 0.5:\n",
    "        sample_list = NDD_all_LBD[\"SAMPLES\"][i].split(\" \")\n",
    "        minor_allele_samples = [x for x in sample_list if '/1' in x]\n",
    "        b = pd.DataFrame({\"ID\":NDD_all_LBD.iloc[i,3], \"minor_allele_samples\":[minor_allele_samples]})\n",
    "        geno_df = pd.concat([geno_df,b])\n",
    "    else:\n",
    "        sample_list = NDD_all_LBD[\"SAMPLES\"][i].split(\" \")\n",
    "        minor_allele_samples = [x for x in sample_list if '0/' in x]\n",
    "        b = pd.DataFrame({\"ID\":NDD_all_LBD.iloc[i,3], \"minor_allele_samples\":[minor_allele_samples]})\n",
    "        geno_df = pd.concat([geno_df,b])\n",
    "\n",
    "\n",
    "#Drop duplicate values\n",
    "geno_df.drop_duplicates(inplace=True, subset=[\"ID\"])\n",
    "geno_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d88f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add non-ref sample IDs to main data frame and reset indeces\n",
    "\n",
    "NDD_all_LBD = NDD_all_LBD.merge(geno_df, on=\"ID\")\n",
    "NDD_all_LBD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_LBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f2bca-6fc2-4a64-b635-c03acfafe8e2",
   "metadata": {},
   "source": [
    "### Gene region, promoter, exon, non-coding, GeneHancer and CADD-SV overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f4952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import information on starting files section\n",
    "#N.B! biomart doesn't recognize PARK2 but PRKN, that name was substituted manually to biomart and from biomart back to PARK2\n",
    "\n",
    "chr_strand = pd.read_csv(\"$PATH1/NIH_FALL_2021_SVs/NDD_ensembl_104_canonical_gene_regions.txt\", sep=\"\\s+\")\n",
    "chr_strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804e2e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To include promoter regions, substract 1000bp (gnomAD SV pipeline uses this value) from transcription start site if gene is \n",
    "#on plus strand or add 1000bp to transcrip end if gene is on minus strand.\n",
    "\n",
    "chr_strand.loc[chr_strand['Strand'] == \"+\", 'start'] = chr_strand[\"txStart\"] - 1000\n",
    "chr_strand.loc[chr_strand['Strand'] == \"+\", 'stop'] = chr_strand[\"txEnd\"]\n",
    "\n",
    "chr_strand.loc[chr_strand['Strand'] == \"-\", 'start'] = chr_strand[\"txStart\"]\n",
    "chr_strand.loc[chr_strand['Strand'] == \"-\", 'stop'] = chr_strand[\"txEnd\"] + 1000\n",
    "\n",
    "chr_strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae51776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add start and stop sites to main data frame and reset indeces\n",
    "\n",
    "NDD_all_LBD = NDD_all_LBD.merge(chr_strand, left_on=\"GENE\", right_on=\"Gene\")\n",
    "NDD_all_LBD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_LBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d6b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import exon range information\n",
    "#N.B.biomart doens't recognize PARK2 but PRKN, that name was substituted manually\n",
    "\n",
    "exons = pd.read_csv(\"$PATH1/NIH_FALL_2021_SVs/NDD_ensembl_104_canonical_exon_ranges.txt\", sep=\"\\s+\")\n",
    "\n",
    "# Make exonStarts and Stops into lists\n",
    "\n",
    "exons[\"exonStarts\"] = exons[\"exonStarts\"].str.split(\",\")\n",
    "exons[\"exonEnds\"] = exons[\"exonEnds\"].str.split(\",\")\n",
    "\n",
    "# Remove empty value at the end of each list introduced by splitting\n",
    "\n",
    "for i in range (0, len(exons)):\n",
    "    exons[\"exonStarts\"][i] = [x for x in exons[\"exonStarts\"][i] if x !='']\n",
    "    exons[\"exonEnds\"][i] = [x for x in exons[\"exonEnds\"][i] if x !='']\n",
    "    \n",
    "#Convert list of strings into list of numbers so they can be used as interval ranges\n",
    "\n",
    "for i in range (0, len(exons)):\n",
    "    exons[\"exonStarts\"][i] = [int(val) for val in exons[\"exonStarts\"][i]]\n",
    "    exons[\"exonEnds\"][i] = [int(val) for val in exons[\"exonEnds\"][i]]\n",
    "\n",
    "# Make exon interval arrays\n",
    "exons[\"exon_intervals\"] = \"\"\n",
    "for i in range(0, len(exons)):\n",
    "     exons[\"exon_intervals\"][i] =  pd.IntervalIndex.from_arrays(exons[\"exonStarts\"][i], exons[\"exonEnds\"][i], closed='both')\n",
    "\n",
    "exons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83b1d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge exon range information per gene ID\n",
    "\n",
    "NDD_all_LBD = NDD_all_LBD.merge(exons, right_on=\"Gene\", left_on=\"GENE\")\n",
    "NDD_all_LBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list from information on exon overlap. Exon start and stop positions are given for every row (otherwise would be need to check exon overlap chromsome-wise)\n",
    "#pandas intervals need to be start < stop so if loop to test if SV POS < END: interval = pos-end, if not: interval=end-pos\n",
    "\n",
    "exon_overlaps = []\n",
    "for i in range(0, len(NDD_all_LBD)):\n",
    "        if NDD_all_LBD[\"POS\"][i] < NDD_all_LBD[\"END\"][i]:\n",
    "            overlap_truefalse = NDD_all_LBD[\"exon_intervals\"][i].overlaps(pd.Interval(NDD_all_LBD[\"POS\"][i], NDD_all_LBD[\"END\"][i]))\n",
    "            if True in overlap_truefalse:\n",
    "                exon_overlaps.append(\"Exonic\")\n",
    "            else:\n",
    "                exon_overlaps.append(\"Not_exonic\")\n",
    "        else:\n",
    "            overlap_truefalse = NDD_all_LBD[\"exon_intervals\"][i].overlaps(pd.Interval(NDD_all_LBD[\"END\"][i], NDD_all_LBD[\"POS\"][i]))\n",
    "            if True in overlap_truefalse:\n",
    "                exon_overlaps.append(\"Exonic\")\n",
    "            else:\n",
    "                exon_overlaps.append(\"Not_exonic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b31ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add exon overlap information to data frame and reset indeces\n",
    "print(len(exon_overlaps) == len(NDD_all_LBD))\n",
    "\n",
    "NDD_all_LBD = NDD_all_LBD.assign(candidate_gene_exon_overlap = exon_overlaps)\n",
    "NDD_all_LBD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_LBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list from information on gene overlap, i.e. if variant pos-end interval overlaps with start-stop interval\n",
    "# take into account that END can be smaller than POS like above\n",
    "\n",
    "gene_overlap_LBD = []\n",
    "for i in range (0,len(NDD_all_LBD)):\n",
    "    if NDD_all_LBD[\"POS\"][i] <= NDD_all_LBD[\"END\"][i]:\n",
    "        i1 = pd.Interval(NDD_all_LBD[\"POS\"][i], NDD_all_LBD[\"END\"][i], closed=\"both\")\n",
    "        i2 = pd.Interval(NDD_all_LBD[\"start\"][i], NDD_all_LBD[\"stop\"][i], closed=\"both\")\n",
    "        if i1.overlaps(i2):\n",
    "            gene_overlap_LBD.append(\"Candidate_gene_overlap\")\n",
    "        else:\n",
    "            gene_overlap_LBD.append(\"No_candidate_gene_overlap\")\n",
    "    else:\n",
    "        i1 = pd.Interval(NDD_all_LBD[\"END\"][i], NDD_all_LBD[\"POS\"][i], closed=\"both\")\n",
    "        i2 = pd.Interval(NDD_all_LBD[\"start\"][i], NDD_all_LBD[\"stop\"][i], closed=\"both\")\n",
    "        if i1.overlaps(i2):\n",
    "            gene_overlap_LBD.append(\"Candidate_gene_overlap\")\n",
    "        else:\n",
    "            gene_overlap_LBD.append(\"No_candidate_gene_overlap\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f902bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add overlap gene information on main data frame and reset indeces\n",
    "NDD_all_LBD = NDD_all_LBD.assign(Candidate_gene_overlap = gene_overlap_LBD)\n",
    "NDD_all_LBD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_LBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list from information on promoter overlap, i.e. if gene on +: start-transcription start site ; gene on -: transcription end-stop\n",
    "# Also need take into account that END can be smaller than POS.\n",
    "# Therefore two main loops: one tests if POS < END other one tests if Strand is + or -\n",
    "\n",
    "promoter_overlap_LBD = []\n",
    "for i in range (0,len(NDD_all_LBD)):\n",
    "    if NDD_all_LBD[\"Strand\"][i] == \"+\":\n",
    "        if NDD_all_LBD[\"POS\"][i] <= NDD_all_LBD[\"END\"][i]:\n",
    "            i1 = pd.Interval(NDD_all_LBD[\"POS\"][i], NDD_all_LBD[\"END\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(NDD_all_LBD[\"start\"][i], NDD_all_LBD[\"txStart\"][i], closed=\"both\")\n",
    "            if i1.overlaps(i2):\n",
    "                promoter_overlap_LBD.append(\"Promoter_overlap\")\n",
    "            else:\n",
    "                promoter_overlap_LBD.append(\"No_promoter_overlap\")\n",
    "        else:\n",
    "            i1 = pd.Interval(NDD_all_LBD[\"END\"][i], NDD_all_LBD[\"POS\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(NDD_all_LBD[\"start\"][i], NDD_all_LBD[\"txStart\"][i], closed=\"both\")\n",
    "            if i1.overlaps(i2):\n",
    "                promoter_overlap_LBD.append(\"Promoter_overlap\")\n",
    "            else:\n",
    "                promoter_overlap_LBD.append(\"No_promoter_overlap\") \n",
    "    else:\n",
    "        if NDD_all_LBD[\"POS\"][i] <= NDD_all_LBD[\"END\"][i]:\n",
    "            i1 = pd.Interval(NDD_all_LBD[\"POS\"][i], NDD_all_LBD[\"END\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(NDD_all_LBD[\"txEnd\"][i], NDD_all_LBD[\"stop\"][i], closed=\"both\")\n",
    "            if i1.overlaps(i2):\n",
    "                promoter_overlap_LBD.append(\"Promoter_overlap\")\n",
    "            else:\n",
    "                promoter_overlap_LBD.append(\"No_promoter_overlap\")\n",
    "        else:\n",
    "            i1 = pd.Interval(NDD_all_LBD[\"END\"][i], NDD_all_LBD[\"POS\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(NDD_all_LBD[\"txEnd\"][i], NDD_all_LBD[\"stop\"][i], closed=\"both\")\n",
    "            if i1.overlaps(i2):\n",
    "                promoter_overlap_LBD.append(\"Promoter_overlap\")\n",
    "            else:\n",
    "                promoter_overlap_LBD.append(\"No_promoter_overlap\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673efb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add promoter overlap information on main data frame and reset indeces\n",
    "NDD_all_LBD = NDD_all_LBD.assign(Candidate_gene_promoter_overlap = promoter_overlap_LBD)\n",
    "NDD_all_LBD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_LBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aed32b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add information on non-coding variants. Variant overlaps non-coding regions of candidate-gene if it overlaps the gene but is not exonic.\n",
    "NDD_all_LBD['Candidate_gene_non_coding_overlap'] = 'No_non_coding_overlap'\n",
    "NDD_all_LBD2 = NDD_all_LBD\n",
    "NDD_all_LBD2.loc[(NDD_all_LBD['candidate_gene_exon_overlap'] == 'Not_exonic') & (NDD_all_LBD['Candidate_gene_overlap'] == \"Candidate_gene_overlap\" ), ['Candidate_gene_non_coding_overlap']] = \"Non-coding_overlap\"\n",
    "NDD_all_LBD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query GeneHancer overlaps based on gene information and create data frame out of overlaps\n",
    "LBD = NDD_all_LBD2\n",
    "genehancer_overlap_LBD = pd.DataFrame({\"ID\":[],\"geneHancerIdentifier\":[]})\n",
    "\n",
    "for i in LBD.index:\n",
    "    for j in genehancer.index:\n",
    "        if LBD[\"POS\"][i] <= LBD[\"END\"][i]:\n",
    "            i1 = pd.Interval(LBD[\"POS\"][i], LBD[\"END\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(genehancer[\"geneHancerStart\"][j], genehancer[\"geneHancerEnd\"][j], closed=\"both\")\n",
    "            if ((i1.overlaps(i2)) and (LBD[\"GENE\"][i] == genehancer[\"geneName\"][j])):\n",
    "                df = pd.DataFrame({\"ID\":LBD[\"ID\"][i], \"geneHancerIdentifier\":genehancer[\"geneHancerIdentifier\"][j]}, index=[0])\n",
    "                genehancer_overlap_LBD = genehancer_overlap_LBD.append(df)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            i1 = pd.Interval(LBD[\"END\"][i], LBD[\"POS\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(genehancer[\"geneHancerStart\"][j], genehancer[\"geneHancerEnd\"][j], closed=\"both\")\n",
    "            if ((i1.overlaps(i2)) and (LBD[\"GENE\"][i] == genehancer[\"geneName\"][j])):\n",
    "                df = pd.DataFrame({\"ID\":LBD[\"ID\"][i], \"geneHancerIdentifier\":genehancer[\"geneHancerIdentifier\"][j]}, index=[0])\n",
    "                genehancer_overlap_LBD = genehancer_overlap_LBD.append(df)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e22f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check overlap df and save it\n",
    "genehancer_overlap_LBD\n",
    "genehancer_overlap_LBD.to_csv(\"genehancer_overlap_LBD_1percFDR.txt\", sep=\"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59867eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format GeneHancer df for merging\n",
    "genehancer_overlap_LBD = pd.read_csv(\"genehancer_overlap_LBD.txt\", sep=\"\\t\")\n",
    "df = genehancer_overlap_LBD.groupby(\"ID\")[\"geneHancerIdentifier\"].apply(list).reset_index(name=\"genehancer\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f54fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge genehancer info to main data frame\n",
    "LBD = LBD.merge(df, on=\"ID\", how = \"left\")\n",
    "\n",
    "#Add info of no GeneHancer overlap for SVs that did not overlap\n",
    "LBD[\"genehancer\"].fillna(\"No_genehancer_overlap\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import unique CADD-SV scores\n",
    "##CADD-SV output has mixed separators of tabs and spaces, so first create a tsv with wanted columns tab separated and unique SVs only (128 shared SVs between overlapping 1Mb gene regions)\n",
    "!awk 'OFS=\"\\t\" {print $1,$2,$3,$4,$5,$6,$7,$8}' $PATH1/CADD-SV-1.1/output/LBD_1percFDR_NDD_all_vcfs_sorted_score.bed > $PATH1/CADD-SV-1.1/output/LBD_1percFDR_NDD_all_vcfs_sorted_score.txt\n",
    "!head -n1 $PATH1/CADD-SV-1.1/output/LBD_1percFDR_NDD_all_vcfs_sorted_score.txt > $PATH1/CADD-SV-1.1/output/LBD_1percFDR_NDD_all_vcfs_sorted_unique_score.txt\n",
    "!sort $PATH1/CADD-SV-1.1/output/LBD_1percFDR_NDD_all_vcfs_sorted_score.txt | uniq >> $PATH1/CADD-SV-1.1/output/LBD_1percFDR_NDD_all_vcfs_sorted_unique_score.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46330f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import CADD-SV scores\n",
    "caddsv_LBD = pd.read_csv(\"$PATH1/CADD-SV-1.1/output/LBD_1percFDR_NDD_all_vcfs_sorted_unique_score.txt\", sep='\\t')\n",
    "caddsv_LBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc0f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge CADD-SV info to main LBD data frame\n",
    "LBD2 = LBD.merge(caddsv_LBD.iloc[:,[4,5,6,7]], left_on=\"ID\", right_on=\"name\", how=\"left\")\n",
    "LBD2.reset_index(drop=True, inplace=True)                                  \n",
    "LBD2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364f377-03c9-4216-ae39-faeddd1b3dbc",
   "metadata": {},
   "source": [
    "### Tidy main data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f459d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tidy data frame by excluding redundant name column and minor allele sample column as last (array ends are noninclusive so +1 to range end).\n",
    "for i in range (0, len(LBD2.columns)):\n",
    "    print(i, LBD2.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa3210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LBD2 = LBD2.iloc[:, np.r_[0:12,13:15,26:31,32:35,15]]\n",
    "LBD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c4b75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tidy by removing SVs for which AF=0 in both cases and controls.\n",
    "LBD3 = LBD2[~((LBD2[\"controls_ALT_FREQS\"] == 0) & (LBD2[\"LBD_ALT_FREQS\"] == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58664f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Also remove \"<>\" from ALT naming\n",
    "LBD3[\"ALT\"] = LBD3[\"ALT\"].str.replace(\"[<>]\",\"\", regex=True)\n",
    "LBD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662ef73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Make results directory\n",
    "mkdir -p LBD_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to text file\n",
    "LBD3.to_csv(\"LBD_results/LBD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer.txt\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa73779-3c99-4b7c-8e24-69e2d7791742",
   "metadata": {},
   "source": [
    "## Frontotemporal dementia/amyotrophic lateral sclerosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9222022-e238-4204-b038-2ccfc1d38c18",
   "metadata": {},
   "source": [
    "### Import vcfs into pandas as the main data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54cdbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#For each vcf (one per gene), print only columns of interest with gene name added as one of the columns.\n",
    "#All columns are separated by tab, sample names with alt allele are separated with single space and their genotype with \":\"\n",
    "\n",
    "cd $PATH1/NIH_FALL_2021_SVs_1percFDR\n",
    "mkdir SV_text_files_FTD\n",
    "\n",
    "module load bcftools\n",
    "\n",
    "for gene in $(ls -1 $PATH1/NIH_FALL_2021_SVs/NIH_files/CLEAN.knownGenes.plink/Gene_Locs/ | awk -F\".\" '{print $1}'); do\n",
    "    bcftools query -f \"%CHROM\\t%POS\\t%END\\t%ID\\t%REF\\t%ALT\\t%QUAL\\t${gene}\\t%FILTER\\t%SVLEN\\t%ALGORITHMS\\t%EVIDENCE\\t[%SAMPLE:%GT ]\\n\" vcfs_FTD/SV.FTD.keepRelated.subsetKnownGenes.flank1Mb.${gene}.vcf.gz > SV_text_files_FTD/FTD_${gene}_to_pandas.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of files to be concatenated\n",
    "csv_file_list = glob.glob(\"$PATH1/NIH_FALL_2021_SVs_1percFDR/SV_text_files_FTD/*to_pandas.txt\")\n",
    "\n",
    "#Make a list of data frames\n",
    "list_of_dataframes = []\n",
    "\n",
    "for filename in csv_file_list:\n",
    "    list_of_dataframes.append(pd.read_csv(filename, sep=\"\\t\", header=None))\n",
    "  \n",
    "\n",
    "#Merge individual data frames into one\n",
    "NDD_all_FTD = pd.concat(list_of_dataframes, axis=0, join=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ab765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add column names, columns are in the same order as vcf was queried with bcftools\n",
    "NDD_all_FTD.columns = [\"CHROM\",\"POS\",\"END\",\"ID\",\"REF\",\"ALT\",\"QUAL\", \"GENE\", \"FILTER\",\"SVLEN\",\"ALGORITHMS\",\"EVIDENCE\",\"SAMPLES\"]\n",
    "NDD_all_FTD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f455018a-f488-49ca-8a1b-4defe2057483",
   "metadata": {},
   "source": [
    "### Import case-control allele frequencies and add them to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import case and control allele frequencies, rename columns and select only relevant columns. Drop duplicates before merging\n",
    "\n",
    "FTD_freqs = pd.read_csv(\"$PATH1/NIH_FALL_2021_SVs_1percFDR/freqs_FTD/freqs_FTD_cases.afreq\", sep=\"\\s+\")\n",
    "FTD_freqs.rename(columns={'ALT_FREQS': 'FTD_ALT_FREQS'}, inplace=True)\n",
    "FTD_freqs = FTD_freqs.iloc[:,[1,4]]\n",
    "FTD_freqs.drop_duplicates(inplace=True)\n",
    "\n",
    "FTD_controls_freqs = pd.read_csv(\"$PATH1/NIH_FALL_2021_SVs_1percFDR/freqs_FTD/freqs_FTD_controls.afreq\", sep=\"\\s+\")\n",
    "FTD_controls_freqs.rename(columns={'ALT_FREQS': 'controls_ALT_FREQS'}, inplace=True)\n",
    "FTD_controls_freqs = FTD_controls_freqs.iloc[:,[1,4]]\n",
    "FTD_controls_freqs.drop_duplicates(inplace=True)\n",
    "\n",
    "FTD_freqs = FTD_freqs.merge(FTD_controls_freqs, on = \"ID\", how=\"outer\")\n",
    "FTD_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a687152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add case-control frequencies to data frame (some SVs are >1 times because they overlap >1 genes of interest)\n",
    "NDD_all_FTD = NDD_all_FTD.merge(FTD_freqs, on=\"ID\")\n",
    "NDD_all_FTD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c271d57-7008-405e-80b6-bfcf12bc57ce",
   "metadata": {},
   "source": [
    "### List only sample IDs that have minor (mostly alternative) allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c09550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split sample id strings (separated by single space) into a list. List items are strings of format ID:Genotype\n",
    "#If frequncy in controls < 0.5, alt allele is minor allele and keep only sample names that contain /1 (0/1 or 1/1)\n",
    "#If frequncy in controls > 0.5, ref allele is minor allele and keep only sample names that contain 0/ (0/0 or 0/1)\n",
    "\n",
    "geno_df = pd.DataFrame()\n",
    "for i in range(0, len(NDD_all_FTD)):\n",
    "    if NDD_all_FTD[\"controls_ALT_FREQS\"][i] < 0.5:\n",
    "        sample_list = NDD_all_FTD[\"SAMPLES\"][i].split(\" \")\n",
    "        minor_allele_samples = [x for x in sample_list if '/1' in x]\n",
    "        b = pd.DataFrame({\"ID\":NDD_all_FTD.iloc[i,3], \"minor_allele_samples\":[minor_allele_samples]})\n",
    "        geno_df = pd.concat([geno_df,b])\n",
    "    else:\n",
    "        sample_list = NDD_all_FTD[\"SAMPLES\"][i].split(\" \")\n",
    "        minor_allele_samples = [x for x in sample_list if '0/' in x]\n",
    "        b = pd.DataFrame({\"ID\":NDD_all_FTD.iloc[i,3], \"minor_allele_samples\":[minor_allele_samples]})\n",
    "        geno_df = pd.concat([geno_df,b])\n",
    "\n",
    "\n",
    "#Drop duplicate values\n",
    "geno_df.drop_duplicates(inplace=True, subset=[\"ID\"])\n",
    "geno_df\n",
    "\n",
    "\n",
    "\n",
    "# Add non-ref sample IDs to main data frame and reset indeces\n",
    "\n",
    "NDD_all_FTD = NDD_all_FTD.merge(geno_df, on=\"ID\")\n",
    "NDD_all_FTD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_FTD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f2f2d-dc1b-4e47-83ee-6d52231a59bd",
   "metadata": {},
   "source": [
    "### Gene region, promoter, exon, non-coding, GeneHancer and CADD-SV overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf98121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import information on starting files section\n",
    "#N.B! biomart doesn't recognize PARK2 but PRKN, that name was substituted manually to biomart and from biomart back to PARK2\n",
    "\n",
    "chr_strand = pd.read_csv(\"$PATH1/NIH_FALL_2021_SVs/NDD_ensembl_104_canonical_gene_regions.txt\", sep=\"\\s+\")\n",
    "chr_strand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9ab30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To include promoter regions, substract 1000bp (gnomAD SV pipeline uses this value) from transcription start site if gene is \n",
    "#on plus strand or add 1000bp to transcrip end if gene is on minus strand.\n",
    "\n",
    "chr_strand.loc[chr_strand['Strand'] == \"+\", 'start'] = chr_strand[\"txStart\"] - 1000\n",
    "chr_strand.loc[chr_strand['Strand'] == \"+\", 'stop'] = chr_strand[\"txEnd\"]\n",
    "\n",
    "chr_strand.loc[chr_strand['Strand'] == \"-\", 'start'] = chr_strand[\"txStart\"]\n",
    "chr_strand.loc[chr_strand['Strand'] == \"-\", 'stop'] = chr_strand[\"txEnd\"] + 1000\n",
    "\n",
    "chr_strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc7a12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add start and stop sites to main data frame and reset indeces\n",
    "\n",
    "NDD_all_FTD = NDD_all_FTD.merge(chr_strand, left_on=\"GENE\", right_on=\"Gene\")\n",
    "NDD_all_FTD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_FTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec3a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import exon range information\n",
    "#N.B.biomart doens't recognize PARK2 but PRKN, that name was substituted manually\n",
    "\n",
    "exons = pd.read_csv(\"$PATH1/NIH_FALL_2021_SVs/NDD_ensembl_104_canonical_exon_ranges.txt\", sep=\"\\s+\")\n",
    "\n",
    "# Make exonStarts and Stops into lists\n",
    "\n",
    "exons[\"exonStarts\"] = exons[\"exonStarts\"].str.split(\",\")\n",
    "exons[\"exonEnds\"] = exons[\"exonEnds\"].str.split(\",\")\n",
    "\n",
    "# Remove empty value at the end of each list introduced by splitting\n",
    "\n",
    "for i in range (0, len(exons)):\n",
    "    exons[\"exonStarts\"][i] = [x for x in exons[\"exonStarts\"][i] if x !='']\n",
    "    exons[\"exonEnds\"][i] = [x for x in exons[\"exonEnds\"][i] if x !='']\n",
    "    \n",
    "#Convert list of strings into list of numbers so they can be used as interval ranges\n",
    "\n",
    "for i in range (0, len(exons)):\n",
    "    exons[\"exonStarts\"][i] = [int(val) for val in exons[\"exonStarts\"][i]]\n",
    "    exons[\"exonEnds\"][i] = [int(val) for val in exons[\"exonEnds\"][i]]\n",
    "\n",
    "# Make exon interval arrays\n",
    "exons[\"exon_intervals\"] = \"\"\n",
    "for i in range(0, len(exons)):\n",
    "     exons[\"exon_intervals\"][i] =  pd.IntervalIndex.from_arrays(exons[\"exonStarts\"][i], exons[\"exonEnds\"][i], closed='both')\n",
    "\n",
    "exons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ddc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge exon range information per gene ID\n",
    "\n",
    "NDD_all_FTD = NDD_all_FTD.merge(exons, right_on=\"Gene\", left_on=\"GENE\")\n",
    "NDD_all_FTD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list from information on exon overlap. Exon start and stop positions are given for every row (otherwise would be need to check exon overlap chromsome-wise)\n",
    "#pandas intervals need to be start < stop so if loop to test if SV POS < END: interval = pos-end, if not: interval=end-pos\n",
    "\n",
    "exon_overlaps = []\n",
    "for i in range(0, len(NDD_all_FTD)):\n",
    "        if NDD_all_FTD[\"POS\"][i] < NDD_all_FTD[\"END\"][i]:\n",
    "            overlap_truefalse = NDD_all_FTD[\"exon_intervals\"][i].overlaps(pd.Interval(NDD_all_FTD[\"POS\"][i], NDD_all_FTD[\"END\"][i]))\n",
    "            if True in overlap_truefalse:\n",
    "                exon_overlaps.append(\"Exonic\")\n",
    "            else:\n",
    "                exon_overlaps.append(\"Not_exonic\")\n",
    "        else:\n",
    "            overlap_truefalse = NDD_all_FTD[\"exon_intervals\"][i].overlaps(pd.Interval(NDD_all_FTD[\"END\"][i], NDD_all_FTD[\"POS\"][i]))\n",
    "            if True in overlap_truefalse:\n",
    "                exon_overlaps.append(\"Exonic\")\n",
    "            else:\n",
    "                exon_overlaps.append(\"Not_exonic\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787ef4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add exon overlap information to data frame and reset indeces\n",
    "print(len(exon_overlaps) == len(NDD_all_FTD))\n",
    "\n",
    "NDD_all_FTD = NDD_all_FTD.assign(candidate_gene_exon_overlap = exon_overlaps)\n",
    "NDD_all_FTD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_FTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1313564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list from information on gene overlap, i.e. if variant pos-end interval overlaps with start-stop interval\n",
    "# take into account that END can be smaller than POS like above\n",
    "\n",
    "gene_overlap_FTD = []\n",
    "for i in range (0,len(NDD_all_FTD)):\n",
    "    if NDD_all_FTD[\"POS\"][i] <= NDD_all_FTD[\"END\"][i]:\n",
    "        i1 = pd.Interval(NDD_all_FTD[\"POS\"][i], NDD_all_FTD[\"END\"][i], closed=\"both\")\n",
    "        i2 = pd.Interval(NDD_all_FTD[\"start\"][i], NDD_all_FTD[\"stop\"][i], closed=\"both\")\n",
    "        if i1.overlaps(i2):\n",
    "            gene_overlap_FTD.append(\"Candidate_gene_overlap\")\n",
    "        else:\n",
    "            gene_overlap_FTD.append(\"No_candidate_gene_overlap\")\n",
    "    else:\n",
    "        i1 = pd.Interval(NDD_all_FTD[\"END\"][i], NDD_all_FTD[\"POS\"][i], closed=\"both\")\n",
    "        i2 = pd.Interval(NDD_all_FTD[\"start\"][i], NDD_all_FTD[\"stop\"][i], closed=\"both\")\n",
    "        if i1.overlaps(i2):\n",
    "            gene_overlap_FTD.append(\"Candidate_gene_overlap\")\n",
    "        else:\n",
    "            gene_overlap_FTD.append(\"No_candidate_gene_overlap\") \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2574978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add overlap gene information on main data frame and reset indeces\n",
    "NDD_all_FTD = NDD_all_FTD.assign(Candidate_gene_overlap = gene_overlap_FTD)\n",
    "NDD_all_FTD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_FTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list from information on promoter overlap, i.e. if gene on +: start-transcription start site ; gene on -: transcription end-stop\n",
    "# Also need take into account that END can be smaller than POS.\n",
    "# Therefore two main loops: one tests if POS < END other one tests if Strand is + or -\n",
    "\n",
    "promoter_overlap_FTD = []\n",
    "for i in range (0,len(NDD_all_FTD)):\n",
    "    if NDD_all_FTD[\"Strand\"][i] == \"+\":\n",
    "        if NDD_all_FTD[\"POS\"][i] <= NDD_all_FTD[\"END\"][i]:\n",
    "            i1 = pd.Interval(NDD_all_FTD[\"POS\"][i], NDD_all_FTD[\"END\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(NDD_all_FTD[\"start\"][i], NDD_all_FTD[\"txStart\"][i], closed=\"both\")\n",
    "            if i1.overlaps(i2):\n",
    "                promoter_overlap_FTD.append(\"Promoter_overlap\")\n",
    "            else:\n",
    "                promoter_overlap_FTD.append(\"No_promoter_overlap\")\n",
    "        else:\n",
    "            i1 = pd.Interval(NDD_all_FTD[\"END\"][i], NDD_all_FTD[\"POS\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(NDD_all_FTD[\"start\"][i], NDD_all_FTD[\"txStart\"][i], closed=\"both\")\n",
    "            if i1.overlaps(i2):\n",
    "                promoter_overlap_FTD.append(\"Promoter_overlap\")\n",
    "            else:\n",
    "                promoter_overlap_FTD.append(\"No_promoter_overlap\") \n",
    "    else:\n",
    "        if NDD_all_FTD[\"POS\"][i] <= NDD_all_FTD[\"END\"][i]:\n",
    "            i1 = pd.Interval(NDD_all_FTD[\"POS\"][i], NDD_all_FTD[\"END\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(NDD_all_FTD[\"txEnd\"][i], NDD_all_FTD[\"stop\"][i], closed=\"both\")\n",
    "            if i1.overlaps(i2):\n",
    "                promoter_overlap_FTD.append(\"Promoter_overlap\")\n",
    "            else:\n",
    "                promoter_overlap_FTD.append(\"No_promoter_overlap\")\n",
    "        else:\n",
    "            i1 = pd.Interval(NDD_all_FTD[\"END\"][i], NDD_all_FTD[\"POS\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(NDD_all_FTD[\"txEnd\"][i], NDD_all_FTD[\"stop\"][i], closed=\"both\")\n",
    "            if i1.overlaps(i2):\n",
    "                promoter_overlap_FTD.append(\"Promoter_overlap\")\n",
    "            else:\n",
    "                promoter_overlap_FTD.append(\"No_promoter_overlap\") \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e92eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add promoter overlap information on main data frame and reset indeces\n",
    "NDD_all_FTD = NDD_all_FTD.assign(Candidate_gene_promoter_overlap = promoter_overlap_FTD)\n",
    "NDD_all_FTD.reset_index(drop=True, inplace=True)\n",
    "NDD_all_FTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1855d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add information on non-coding variants. Variant overlaps non-coding regions of candidate-gene if it overlaps the gene but is not exonic.\n",
    "NDD_all_FTD['Candidate_gene_non_coding_overlap'] = 'No_non_coding_overlap'\n",
    "NDD_all_FTD2 = NDD_all_FTD\n",
    "NDD_all_FTD2.loc[(NDD_all_FTD['candidate_gene_exon_overlap'] == 'Not_exonic') & (NDD_all_FTD['Candidate_gene_overlap'] == \"Candidate_gene_overlap\" ), ['Candidate_gene_non_coding_overlap']] = \"Non-coding_overlap\"\n",
    "NDD_all_FTD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2eb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query GeneHancer overlaps based on gene information and create data frame out of overlaps\n",
    "FTD = NDD_all_FTD2\n",
    "genehancer_overlap_FTD = pd.DataFrame({\"ID\":[],\"geneHancerIdentifier\":[]})\n",
    "\n",
    "for i in FTD.index:\n",
    "    for j in genehancer.index:\n",
    "        if FTD[\"POS\"][i] <= FTD[\"END\"][i]:\n",
    "            i1 = pd.Interval(FTD[\"POS\"][i], FTD[\"END\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(genehancer[\"geneHancerStart\"][j], genehancer[\"geneHancerEnd\"][j], closed=\"both\")\n",
    "            if ((i1.overlaps(i2)) and (FTD[\"GENE\"][i] == genehancer[\"geneName\"][j])):\n",
    "                df = pd.DataFrame({\"ID\":FTD[\"ID\"][i], \"geneHancerIdentifier\":genehancer[\"geneHancerIdentifier\"][j]}, index=[0])\n",
    "                genehancer_overlap_FTD = genehancer_overlap_FTD.append(df)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            i1 = pd.Interval(FTD[\"END\"][i], FTD[\"POS\"][i], closed=\"both\")\n",
    "            i2 = pd.Interval(genehancer[\"geneHancerStart\"][j], genehancer[\"geneHancerEnd\"][j], closed=\"both\")\n",
    "            if ((i1.overlaps(i2)) and (FTD[\"GENE\"][i] == genehancer[\"geneName\"][j])):\n",
    "                df = pd.DataFrame({\"ID\":FTD[\"ID\"][i], \"geneHancerIdentifier\":genehancer[\"geneHancerIdentifier\"][j]}, index=[0])\n",
    "                genehancer_overlap_FTD = genehancer_overlap_FTD.append(df)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check overlap df and save it\n",
    "genehancer_overlap_FTD\n",
    "genehancer_overlap_FTD.to_csv(\"genehancer_overlap_FTD_1percFDR.txt\", sep=\"\\t\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714e6d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Format GeneHancer df for merging\n",
    "#genehancer_overlap_FTD = pd.read_csv(\"genehancer_overlap_FTD.txt\", sep=\"\\t\")\n",
    "df = genehancer_overlap_FTD.groupby(\"ID\")[\"geneHancerIdentifier\"].apply(list).reset_index(name=\"genehancer\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge genehancer info to main data frame\n",
    "FTD = FTD.merge(df, on=\"ID\", how = \"left\")\n",
    "\n",
    "#Add info of no GeneHancer overlap for SVs that did not overlap\n",
    "FTD[\"genehancer\"].fillna(\"No_genehancer_overlap\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import unique CADD-SV scores\n",
    "##CADD-SV output has mixed separators of tabs and spaces, so first create a tsv with wanted columns tab separated and unique SVs only (128 shared SVs between overlapping 1Mb gene regions)\n",
    "!awk 'OFS=\"\\t\" {print $1,$2,$3,$4,$5,$6,$7,$8}' $PATH1/CADD-SV-1.1/output/FTD_1percFDR_NDD_all_vcfs_sorted_score.bed > $PATH1/CADD-SV-1.1/output/FTD_1percFDR_NDD_all_vcfs_sorted_score.txt\n",
    "!head -n1 $PATH1/CADD-SV-1.1/output/FTD_1percFDR_NDD_all_vcfs_sorted_score.txt > $PATH1/CADD-SV-1.1/output/FTD_1percFDR_NDD_all_vcfs_sorted_unique_score.txt\n",
    "!sort $PATH1/CADD-SV-1.1/output/FTD_1percFDR_NDD_all_vcfs_sorted_score.txt | uniq >> $PATH1/CADD-SV-1.1/output/FTD_1percFDR_NDD_all_vcfs_sorted_unique_score.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad581952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Import CADD-SV scores\n",
    "caddsv_FTD = pd.read_csv(\"$PATH1/CADD-SV-1.1/output/FTD_1percFDR_NDD_all_vcfs_sorted_unique_score.txt\", sep='\\t')\n",
    "caddsv_FTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48df441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge CADD-SV info to main FTD data frame\n",
    "FTD2 = FTD.merge(caddsv_FTD.iloc[:,[4,5,6,7]], left_on=\"ID\", right_on=\"name\", how=\"left\")\n",
    "FTD2.reset_index(drop=True, inplace=True)                                  \n",
    "FTD2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a25603-32c3-4425-8b30-d22b262924e1",
   "metadata": {},
   "source": [
    "### Tidy main data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ddea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tidy data frame by excluding redundant name column and minor allele sample column as last (array ends are noninclusive so +1 to range end).\n",
    "for i in range (0, len(FTD2.columns)):\n",
    "    print(i, FTD2.columns[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ead93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FTD2 = FTD2.iloc[:, np.r_[0:12,13:15,26:31,32:35,15]]\n",
    "FTD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tidy by removing SVs for which AF=0 in both cases and controls.\n",
    "FTD3 = FTD2[~((FTD2[\"controls_ALT_FREQS\"] == 0) & (FTD2[\"FTD_ALT_FREQS\"] == 0))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05060940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Also remove \"<>\" from ALT naming\n",
    "FTD3[\"ALT\"] = FTD3[\"ALT\"].str.replace(\"[<>]\",\"\", regex=True)\n",
    "FTD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Make results directory\n",
    "mkdir -p FTD_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef01795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Export to text file\n",
    "FTD3.to_csv(\"FTD_results/FTD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer.txt\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9365c7-b46c-4fd6-9886-b9b4846a3b77",
   "metadata": {},
   "source": [
    "# Shiny app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7668d8f-4b19-4c05-8918-772edf6a573b",
   "metadata": {},
   "source": [
    "## 50 Neurodegenerative disease gene images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731bd13-4939-4d74-b5ef-01394cc8971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Image preparation for shiny app \n",
    "\n",
    "#Load libraries\n",
    "library(\"Gviz\")\n",
    "library(\"tidyverse\")\n",
    "library(AnnotationHub)\n",
    "library(biomaRt)\n",
    "\n",
    "#Import files 50NDD files\n",
    "LBD <- read.delim(\"LBD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer.txt\")\n",
    "FTD <- read.delim(\"FTD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer.txt\")\n",
    "genes <- read.csv(\"NDD_ensembl_104_canonical_gene_regions.txt\", sep=\"\", stringsAsFactors=FALSE)\n",
    "\n",
    "#Format files\n",
    "##Add chr prefix\n",
    "LBD$CHROM <- paste0(\"chr\",LBD$CHROM)\n",
    "FTD$CHROM <- paste0(\"chr\", FTD$CHROM)\n",
    "#Change : in SVTYPE to _\n",
    "LBD$ALT <- gsub(\":\",\"_\",LBD$ALT)\n",
    "FTD$ALT <- gsub(\":\",\"_\",FTD$ALT)\n",
    "#Make AFs in percentages column, two decimal places\n",
    "LBD$LBD_ALT_FREQS_perc <- paste0(round(LBD$LBD_ALT_FREQS *100,digits=2), \"%\")\n",
    "LBD$controls_ALT_FREQS_perc <- paste0(round(LBD$controls_ALT_FREQS *100,digits=2), \"%\")\n",
    "FTD$FTD_ALT_FREQS_perc <- paste0(round(FTD$FTD_ALT_FREQS *100,digits=2), \"%\")\n",
    "FTD$controls_ALT_FREQS_perc <- paste0(round(FTD$controls_ALT_FREQS *100,digits=2), \"%\")\n",
    "##Remove SV carrier column\n",
    "LBD <- LBD[,-23]\n",
    "FTD <- FTD[,-23]\n",
    "##Make all END > POS for visualisation (if any)\n",
    "print(\"LBD\")\n",
    "for (i in 1:nrow(LBD)) {\n",
    "  if (LBD$END[i] >= LBD$POS[i]) {\n",
    "    next\n",
    "  } else {\n",
    "    print(paste(\"Initial pos:\", LBD$POS[i], \"and initial end:\", LBD$END[i]))\n",
    "    tmp <- LBD$END[i]\n",
    "    LBD$END[i] <- LBD$POS[i]\n",
    "    LBD$POS[i] <- tmp\n",
    "    print(paste(\"Updated pos:\", LBD$POS[i], \"and updated end:\", LBD$END[i]))\n",
    "  }\n",
    "}\n",
    "\n",
    "print(\"FTD\")\n",
    "for (i in 1:nrow(FTD)) {\n",
    "  if (FTD$END[i] >= FTD$POS[i]) {\n",
    "    next\n",
    "  } else {\n",
    "    print(paste(\"Initial pos:\", FTD$POS[i], \"and initial end:\", FTD$END[i]))\n",
    "    tmp <- FTD$END[i]\n",
    "    FTD$END[i] <- FTD$POS[i]\n",
    "    FTD$POS[i] <- tmp\n",
    "    print(paste(\"Updated pos:\", FTD$POS[i], \"and updated end:\", FTD$END[i]))\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#Plot\n",
    "##Initialize biomart track\n",
    "bm <- useEnsembl(biomart = \"genes\")\n",
    "bm <- useDataset(dataset = \"hsapiens_gene_ensembl\", mart = bm)\n",
    "\n",
    "##Make a df of canonical protein coding genes\n",
    "gene_info <- as.data.frame(getBM(attributes = c(\"chromosome_name\",\"start_position\",\"end_position\",\"gene_biotype\",\"external_gene_name\"), filters = \"transcript_is_canonical\", values = TRUE, mart = bm))\n",
    "###Include only autosomal and X variants and genes with gene name \n",
    "gene_info <- gene_info %>%\n",
    "  filter(gene_biotype == \"protein_coding\") %>%\n",
    "  filter(chromosome_name %in% c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,\"X\")) %>%\n",
    "  filter(external_gene_name != \"\")\n",
    "###Remove gene biotype column to save space\n",
    "gene_info <- gene_info[,c(1,2,3,5)]\n",
    "###Add chr prefix to chr codes\n",
    "gene_info$chromosome_name <- paste0(\"chr\",gene_info$chromosome_name)\n",
    "###Save df\n",
    "write.table(gene_info, file = \"gene_start_stop_name.txt\", quote=FALSE, row.names = FALSE)\n",
    "  \n",
    "##LBD gene region (including promoter) overlaps\n",
    "for (i in 1:nrow(genes)) {\n",
    "  gene = genes$Gene[i]\n",
    "  start = genes$txStart[i] -1000\n",
    "  stop = genes$txEnd[i] + 1000\n",
    "  \n",
    "  LBD_cases <- LBD %>%\n",
    "    filter(GENE == gene) %>%\n",
    "    filter(LBD_ALT_FREQS > 0) %>%\n",
    "    filter((Candidate_gene_overlap == \"Candidate_gene_overlap\") | (Candidate_gene_promoter_overlap == \"Promoter_overlap\"))\n",
    "  \n",
    "  LBD_controls <- LBD %>%\n",
    "    filter(GENE == gene) %>%\n",
    "    filter(controls_ALT_FREQS > 0) %>%\n",
    "    filter((Candidate_gene_overlap == \"Candidate_gene_overlap\") | (Candidate_gene_promoter_overlap == \"Promoter_overlap\"))\n",
    "  \n",
    "  LBD_cases$POS[LBD_cases$POS < start] <- start - (0.2*(stop-start))\n",
    "  LBD_cases$END[LBD_cases$END > stop] <- stop + (0.2*(stop-start))\n",
    "  LBD_controls$POS[LBD_controls$POS < start] <- start - (0.2*(stop-start))\n",
    "  LBD_controls$END[LBD_controls$END > stop] <- stop + (0.2*(stop-start))\n",
    "  \n",
    "  png(paste0(\"NIH_LBD_FTD_SV_shinyapp/NIH_SV_images/LBD/\",gene,\"_LBD_candidate_gene_overlap.png\"), height = 1180, width = 1180, units = \"px\", res=100)\n",
    "  \n",
    "  if ((nrow(LBD_cases) > 0) & (nrow(LBD_controls) > 0)) {\n",
    "    gtrack <- GenomeAxisTrack()\n",
    "    itrack <- IdeogramTrack(genome = \"hg38\", chromosome = LBD_cases$CHROM[1])\n",
    "    biomTrack <- BiomartGeneRegionTrack(transcriptAnnotation = \"symbol\", genome = \"hg38\",chromosome = LBD_cases$CHROM[1], start = start, end = stop, name = gene, filter = list(transcript_is_canonical = TRUE), biomart = bm, protein_coding=\"gray\", utr3=\"gray\", utr5=\"gray\", fill=\"gray\")\n",
    "    atrack_LBD <- AnnotationTrack(start=LBD_cases$POS, end=LBD_cases$END, chromosome = LBD_cases$CHROM[1], genome=\"hg38\", name=\"LBD\", feature = LBD_cases$ALT, id=LBD_cases$LBD_ALT_FREQS_perc, showFeatureId = TRUE, fontcolor.item=\"black\", min.width=2)\n",
    "    atrack_controls <- AnnotationTrack(start=LBD_controls$POS, end=LBD_controls$END, chromosome = LBD_controls$CHROM[1], genome=\"hg38\", name=\"Controls\", feature = LBD_controls$ALT, id=LBD_controls$controls_ALT_FREQS_perc, showFeatureId = TRUE, fontcolor.item=\"black\", min.width=2)\n",
    "    plotTracks(list(itrack,gtrack, atrack_LBD, atrack_controls, biomTrack), from = start, to = stop, fontcolor.title=\"#808080\", extend.right = 0.2, extend.left = 0.2, fontsize.group=14, fontsize.title=14, BND=\"#377246\", CPX=\"#86E496\", DEL=\"#D6402D\", DUP=\"#5282AF\", INS=\"#D579E1\", INS_ME=\"#F6AAFF\", INS_ME_ALU=\"#F6AAFF\", INS_ME_LINE1=\"#F6AAFF\", INS_ME_SVA=\"#F6AAFF\", INV=\"#F69A57\")\n",
    "  } else if ((nrow(LBD_cases) > 0) & (nrow(LBD_controls) == 0)) {\n",
    "    gtrack <- GenomeAxisTrack()\n",
    "    itrack <- IdeogramTrack(genome = \"hg38\", chromosome = LBD_cases$CHROM[1])\n",
    "    biomTrack <- BiomartGeneRegionTrack(genome = \"hg38\",chromosome = LBD_cases$CHROM[1], start = start, end = stop, name = \"ENSEMBL\", filter = list(transcript_is_canonical = TRUE), biomart = bm, protein_coding=\"gray\", utr3=\"gray\", utr5=\"gray\", fill=\"gray\")\n",
    "    atrack_LBD <- AnnotationTrack(start=LBD_cases$POS, end=LBD_cases$END, chromosome = LBD_cases$CHROM, genome=\"hg38\", name=\"LBD\", feature = LBD_cases$ALT, id=LBD_cases$LBD_ALT_FREQS_perc, showFeatureId = TRUE, fontcolor.item=\"black\", col.line=\"white\", min.width=2)\n",
    "    plotTracks(list(itrack,gtrack, atrack_LBD, biomTrack), from = start, to = stop, fontcolor.title=\"#808080\", extend.right = 0.2, extend.left = 0.2, fontsize.group=14, fontsize.title=14, BND=\"#377246\", CPX=\"#86E496\", DEL=\"#D6402D\", DUP=\"#5282AF\", INS=\"#D579E1\", INS_ME=\"#F6AAFF\", INS_ME_ALU=\"#F6AAFF\", INS_ME_LINE1=\"#F6AAFF\", INS_ME_SVA=\"#F6AAFF\", INV=\"#F69A57\")\n",
    "  } else if ((nrow(LBD_cases) == 0) & (nrow(LBD_controls) == 0)) {\n",
    "    gtrack <- GenomeAxisTrack(showTitle=TRUE, name=\"No SVs\", fontcolor.title=\"#808080\", rotation.title=0)\n",
    "    plotTracks(gtrack, from = 100, to = 110, title.width = 5)\n",
    "  } else {\n",
    "    gtrack <- GenomeAxisTrack()\n",
    "    itrack <- IdeogramTrack(genome = \"hg38\", chromosome = LBD_controls$CHROM[1])\n",
    "    biomTrack <- BiomartGeneRegionTrack(transcriptAnnotation = \"symbol\", genome = \"hg38\",chromosome = LBD_controls$CHROM[1], start = start, end = stop, name = gene, filter = list(transcript_is_canonical = TRUE), biomart = bm, protein_coding=\"gray\", utr3=\"gray\", utr5=\"gray\", fill=\"gray\")\n",
    "    atrack_controls <- AnnotationTrack(start=LBD_controls$POS, end=LBD_controls$END, chromosome = LBD_controls$CHROM, genome=\"hg38\", name=\"Controls\", feature = LBD_controls$ALT, id=LBD_controls$controls_ALT_FREQS_perc, showFeatureId = TRUE, fontcolor.item=\"black\", min.width=2)\n",
    "    plotTracks(list(itrack,gtrack, atrack_controls, biomTrack), from = start, to = stop, fontcolor.title=\"#808080\", extend.right = 0.2, extend.left = 0.2, fontsize.group=14, fontsize.title=14, BND=\"#377246\", CPX=\"#86E496\", DEL=\"#D6402D\", DUP=\"#5282AF\", INS=\"#D579E1\", INS_ME=\"#F6AAFF\", INS_ME_ALU=\"#F6AAFF\", INS_ME_LINE1=\"#F6AAFF\", INS_ME_SVA=\"#F6AAFF\", INV=\"#F69A57\")\n",
    "  }\n",
    "  dev.off()\n",
    "}\n",
    "\n",
    "##FTD gene region (including promoter) overlaps\n",
    "for (i in 1:nrow(genes)) {\n",
    "  gene = genes$Gene[i]\n",
    "  start = genes$txStart[i] -1000\n",
    "  stop = genes$txEnd[i] + 1000\n",
    "  \n",
    "  FTD_cases <- FTD %>%\n",
    "    filter(GENE == gene) %>%\n",
    "    filter(FTD_ALT_FREQS > 0) %>%\n",
    "    filter((Candidate_gene_overlap == \"Candidate_gene_overlap\") | (Candidate_gene_promoter_overlap == \"Promoter_overlap\"))\n",
    "  \n",
    "  FTD_controls <- FTD %>%\n",
    "    filter(GENE == gene) %>%\n",
    "    filter(controls_ALT_FREQS > 0) %>%\n",
    "    filter((Candidate_gene_overlap == \"Candidate_gene_overlap\") | (Candidate_gene_promoter_overlap == \"Promoter_overlap\"))\n",
    "  \n",
    "  FTD_cases$POS[FTD_cases$POS < start] <- start - (0.2*(stop-start))\n",
    "  FTD_cases$END[FTD_cases$END > stop] <- stop + (0.2*(stop-start))\n",
    "  FTD_controls$POS[FTD_controls$POS < start] <- start - (0.2*(stop-start))\n",
    "  FTD_controls$END[FTD_controls$END > stop] <- stop + (0.2*(stop-start))\n",
    "  \n",
    "  png(paste0(\"NIH_LBD_FTD_SV_shinyapp/NIH_SV_images/FTD/\",gene,\"_FTD_candidate_gene_overlap.png\"), height = 1180, width = 1180, units = \"px\", res=100)\n",
    "  \n",
    "  if ((nrow(FTD_cases) > 0) & (nrow(FTD_controls) > 0)) {\n",
    "    gtrack <- GenomeAxisTrack()\n",
    "    itrack <- IdeogramTrack(genome = \"hg38\", chromosome = FTD_cases$CHROM[1])\n",
    "    biomTrack <- BiomartGeneRegionTrack(transcriptAnnotation = \"symbol\", genome = \"hg38\",chromosome = FTD_cases$CHROM[1], start = start, end = stop, name = gene, filter = list(transcript_is_canonical = TRUE), biomart = bm, protein_coding=\"gray\", utr3=\"gray\", utr5=\"gray\", fill=\"gray\")\n",
    "    atrack_FTD <- AnnotationTrack(start=FTD_cases$POS, end=FTD_cases$END, chromosome = FTD_cases$CHROM[1], genome=\"hg38\", name=\"FTD\", feature = FTD_cases$ALT, id=FTD_cases$FTD_ALT_FREQS_perc, showFeatureId = TRUE, fontcolor.item=\"black\", min.width=2)\n",
    "    atrack_controls <- AnnotationTrack(start=FTD_controls$POS, end=FTD_controls$END, chromosome = FTD_controls$CHROM[1], genome=\"hg38\", name=\"Controls\", feature = FTD_controls$ALT, id=FTD_controls$controls_ALT_FREQS_perc, showFeatureId = TRUE, fontcolor.item=\"black\", col.line=\"white\", min.width=2)\n",
    "    plotTracks(list(itrack,gtrack, atrack_FTD, atrack_controls, biomTrack), from = start, to = stop, fontcolor.title=\"#808080\", extend.right = 0.2, extend.left = 0.2, fontsize.group=14, fontsize.title=14, BND=\"#377246\", CPX=\"#86E496\", DEL=\"#D6402D\", DUP=\"#5282AF\", INS=\"#D579E1\", INS_ME=\"#F6AAFF\", INS_ME_ALU=\"#F6AAFF\", INS_ME_LINE1=\"#F6AAFF\", INS_ME_SVA=\"#F6AAFF\", INV=\"#F69A57\")\n",
    "  } else if ((nrow(FTD_cases) > 0) & (nrow(FTD_controls) == 0)) {\n",
    "    gtrack <- GenomeAxisTrack()\n",
    "    itrack <- IdeogramTrack(genome = \"hg38\", chromosome = FTD_cases$CHROM[1])\n",
    "    biomTrack <- BiomartGeneRegionTrack(genome = \"hg38\",chromosome = FTD_cases$CHROM[1], start = start, end = stop, name = \"ENSEMBL\", filter = list(transcript_is_canonical = TRUE), biomart = bm, protein_coding=\"gray\", utr3=\"gray\", utr5=\"gray\", fill=\"gray\")\n",
    "    atrack_FTD <- AnnotationTrack(start=FTD_cases$POS, end=FTD_cases$END, chromosome = FTD_cases$CHROM, genome=\"hg38\", name=\"FTD\", feature = FTD_cases$ALT, id=FTD_cases$FTD_ALT_FREQS_perc, showFeatureId = TRUE, fontcolor.item=\"black\", min.width=2)\n",
    "    plotTracks(list(itrack,gtrack, atrack_FTD, biomTrack), from = start, to = stop, fontcolor.title=\"#808080\", extend.right = 0.2, extend.left = 0.2, fontsize.group=14, fontsize.title=14, BND=\"#377246\", CPX=\"#86E496\", DEL=\"#D6402D\", DUP=\"#5282AF\", INS=\"#D579E1\", INS_ME=\"#F6AAFF\", INS_ME_ALU=\"#F6AAFF\", INS_ME_LINE1=\"#F6AAFF\", INS_ME_SVA=\"#F6AAFF\", INV=\"#F69A57\")\n",
    "  } else if ((nrow(FTD_cases) == 0) & (nrow(FTD_controls) == 0)) {\n",
    "    gtrack <- GenomeAxisTrack(showTitle=TRUE, name=\"No SVs\", fontcolor.title=\"#808080\", rotation.title=0)\n",
    "    plotTracks(gtrack, from = 100, to = 110, title.width = 5)\n",
    "  } else {\n",
    "    gtrack <- GenomeAxisTrack()\n",
    "    itrack <- IdeogramTrack(genome = \"hg38\", chromosome = FTD_controls$CHROM[1])\n",
    "    biomTrack <- BiomartGeneRegionTrack(transcriptAnnotation = \"symbol\", genome = \"hg38\",chromosome = FTD_controls$CHROM[1], start = start, end = stop, name = gene, filter = list(transcript_is_canonical = TRUE), biomart = bm, protein_coding=\"gray\", utr3=\"gray\", utr5=\"gray\", fill=\"gray\")\n",
    "    atrack_controls <- AnnotationTrack(start=FTD_controls$POS, end=FTD_controls$END, chromosome = FTD_controls$CHROM, genome=\"hg38\", name=\"Controls\", feature = FTD_controls$ALT, id=FTD_controls$controls_ALT_FREQS_perc, showFeatureId = TRUE, fontcolor.item=\"black\", min.width=2)\n",
    "    plotTracks(list(itrack,gtrack, atrack_controls, biomTrack), from = start, to = stop, fontcolor.title=\"#808080\", extend.right = 0.2, extend.left = 0.2, fontsize.group=14, fontsize.title=14, BND=\"#377246\", CPX=\"#86E496\", DEL=\"#D6402D\", DUP=\"#5282AF\", INS=\"#D579E1\", INS_ME=\"#F6AAFF\", INS_ME_ALU=\"#F6AAFF\", INS_ME_LINE1=\"#F6AAFF\", INS_ME_SVA=\"#F6AAFF\", INV=\"#F69A57\")\n",
    "  }\n",
    "  dev.off()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f131604-a94a-4f63-8f84-15af8a08a285",
   "metadata": {},
   "source": [
    "R version 4.1.3 (2022-03-10)\n",
    "Platform: x86_64-apple-darwin17.0 (64-bit)\n",
    "Running under: macOS Catalina 10.15.7\n",
    "\n",
    "Matrix products: default\n",
    "BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\n",
    "LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n",
    "\n",
    "locale:\n",
    "[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n",
    "\n",
    "attached base packages:\n",
    "[1] grid      stats4    stats     graphics  grDevices utils     datasets  methods   base     \n",
    "\n",
    "other attached packages:\n",
    " [1] biomaRt_2.50.3       AnnotationHub_3.2.2  BiocFileCache_2.2.1  dbplyr_2.2.1         forcats_0.5.2        stringr_1.4.1       \n",
    " [7] dplyr_1.0.10         purrr_0.3.5          readr_2.1.3          tidyr_1.2.1          tibble_3.1.8         ggplot2_3.4.0       \n",
    "[13] tidyverse_1.3.2      Gviz_1.38.4          GenomicRanges_1.46.1 GenomeInfoDb_1.30.1  IRanges_2.32.0       S4Vectors_0.36.0    \n",
    "[19] BiocGenerics_0.40.0 \n",
    "\n",
    "loaded via a namespace (and not attached):\n",
    "  [1] readxl_1.4.1                  backports_1.4.1               Hmisc_4.7-1                   lazyeval_0.2.2               \n",
    "  [5] splines_4.1.3                 BiocParallel_1.28.3           digest_0.6.30                 ensembldb_2.18.4             \n",
    "  [9] htmltools_0.5.3               fansi_1.0.3                   magrittr_2.0.3                checkmate_2.1.0              \n",
    " [13] memoise_2.0.1                 BSgenome_1.62.0               googlesheets4_1.0.1           cluster_2.1.2                \n",
    " [17] tzdb_0.3.0                    Biostrings_2.62.0             modelr_0.1.10                 matrixStats_0.62.0           \n",
    " [21] timechange_0.1.1              prettyunits_1.1.1             jpeg_0.1-9                    colorspace_2.0-3             \n",
    " [25] blob_1.2.3                    rvest_1.0.3                   rappdirs_0.3.3                haven_2.5.1                  \n",
    " [29] xfun_0.34                     crayon_1.5.2                  RCurl_1.98-1.9                jsonlite_1.8.3               \n",
    " [33] survival_3.2-13               VariantAnnotation_1.40.0      glue_1.6.2                    gtable_0.3.1                 \n",
    " [37] gargle_1.2.1                  zlibbioc_1.40.0               XVector_0.34.0                DelayedArray_0.20.0          \n",
    " [41] scales_1.2.1                  DBI_1.1.3                     Rcpp_1.0.9                    xtable_1.8-4                 \n",
    " [45] progress_1.2.2                htmlTable_2.4.1               foreign_0.8-82                bit_4.0.4                    \n",
    " [49] Formula_1.2-4                 DT_0.26                       htmlwidgets_1.5.4             httr_1.4.4                   \n",
    " [53] RColorBrewer_1.1-3            ellipsis_0.3.2                pkgconfig_2.0.3               XML_3.99-0.12                \n",
    " [57] nnet_7.3-17                   deldir_1.0-6                  utf8_1.2.2                    tidyselect_1.2.0             \n",
    " [61] rlang_1.0.6                   later_1.3.0                   AnnotationDbi_1.56.2          munsell_0.5.0                \n",
    " [65] BiocVersion_3.14.0            cellranger_1.1.0              tools_4.1.3                   cachem_1.0.6                 \n",
    " [69] cli_3.4.1                     generics_0.1.3                RSQLite_2.2.18                broom_1.0.1                  \n",
    " [73] fastmap_1.1.0                 yaml_2.3.6                    knitr_1.40                    bit64_4.0.5                  \n",
    " [77] fs_1.5.2                      KEGGREST_1.34.0               AnnotationFilter_1.18.0       mime_0.12                    \n",
    " [81] xml2_1.3.3                    compiler_4.1.3                rstudioapi_0.14               filelock_1.0.2               \n",
    " [85] curl_4.3.3                    png_0.1-7                     interactiveDisplayBase_1.32.0 reprex_2.0.2                 \n",
    " [89] stringi_1.7.8                 GenomicFeatures_1.46.5        lattice_0.20-45               ProtGenerics_1.26.0          \n",
    " [93] Matrix_1.4-0                  vctrs_0.5.0                   pillar_1.8.1                  lifecycle_1.0.3              \n",
    " [97] BiocManager_1.30.19           data.table_1.14.4             bitops_1.0-7                  httpuv_1.6.6                 \n",
    "[101] rtracklayer_1.54.0            R6_2.5.1                      BiocIO_1.4.0                  latticeExtra_0.6-30          \n",
    "[105] promises_1.2.0.1              gridExtra_2.3                 dichromat_2.0-0.1             assertthat_0.2.1             \n",
    "[109] SummarizedExperiment_1.24.0   rjson_0.2.21                  withr_2.5.0                   GenomicAlignments_1.30.0     \n",
    "[113] Rsamtools_2.10.0              GenomeInfoDbData_1.2.7        parallel_4.1.3                hms_1.1.2                    \n",
    "[117] rpart_4.1.16                  MatrixGenerics_1.6.0          googledrive_2.0.0             biovizBase_1.42.0            \n",
    "[121] Biobase_2.54.0                shiny_1.7.3                   lubridate_1.9.0               base64enc_0.1-3     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e6eec-c8b6-4de7-b770-6f32e34e060c",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00f9e1-1b35-45bf-9f4d-b4cdc10c4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#Data preparation for shiny app (run locally)\n",
    "\n",
    "#Load libraries\n",
    "library(\"Gviz\")\n",
    "library(AnnotationHub)\n",
    "library(\"tidyverse\")\n",
    "library(biomaRt)\n",
    "library(tidyverse)\n",
    "\n",
    "#Import files\n",
    "LBD <- read.delim(\"LBD_high_quality_subset_clean_GQ300missing_all_chr.txt\")\n",
    "FTD <- read.delim(\"FTD_high_quality_subset_clean_GQ300missing_all_chr.txt\")\n",
    "\n",
    "#Split into case and control dfs\n",
    "LBD_cases <- LBD %>%\n",
    "  filter(AF_cases > 0)\n",
    "LBD_controls <- LBD %>%\n",
    "  filter(AF_controls > 0)\n",
    "\n",
    "FTD_cases <- FTD %>%\n",
    "  filter(AF_cases > 0)\n",
    "FTD_controls <- FTD %>%\n",
    "  filter(AF_controls > 0)\n",
    "\n",
    "#Change AFs to percentages, two decimal places\n",
    "LBD_cases$AF_cases <- paste0(round(LBD_cases$AF_cases*100,digits=2), \"%\")\n",
    "LBD_controls$AF_controls <- paste0(round(LBD_controls$AF_controls*100,digits=2), \"%\")\n",
    "\n",
    "FTD_cases$AF_cases <- paste0(round(FTD_cases$AF_cases*100,digits=2), \"%\")\n",
    "FTD_controls$AF_controls <- paste0(round(FTD_controls$AF_controls*100,digits=2), \"%\")\n",
    "\n",
    "#Save dfs\n",
    "write.table(LBD_cases, file=\"LBD_cases_shinyapp.txt\", sep=\"\\t\", row.names = FALSE, quote = FALSE)\n",
    "write.table(LBD_controls, file=\"LBD_controls_shinyapp.txt\", sep=\"\\t\", row.names = FALSE, quote = FALSE)\n",
    "\n",
    "write.table(FTD_cases, file=\"FTD_cases_shinyapp.txt\", sep=\"\\t\", row.names = FALSE, quote = FALSE)\n",
    "write.table(FTD_controls, file=\"FTD_controls_shinyapp.txt\", sep=\"\\t\", row.names = FALSE, quote = FALSE)\n",
    "\n",
    "#Import candidate gene files\n",
    "LBD <- read.delim(\"LBD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer.txt\", stringsAsFactors = FALSE)\n",
    "FTD <- read.delim(\"FTD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer.txt\", stringsAsFactors = FALSE)\n",
    "#Remove SV carrier ID column\n",
    "LBD <- LBD[,-23]\n",
    "FTD <- FTD[,-23]\n",
    "#Save dfs\n",
    "write.table(LBD,file=\"LBD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer_shinyapp.txt\", sep=\"\\t\", row.names = FALSE, quote = FALSE)\n",
    "write.table(FTD,file=\"FTD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer_shinyapp.txt\", sep=\"\\t\", row.names = FALSE, quote = FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff63c5e3-5e81-4115-a453-8732865bb388",
   "metadata": {},
   "source": [
    "## Shiny app code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c906444-c966-4474-bf3b-9e24d30e8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Shiny app to visualize SVs\n",
    "\n",
    "#Set working directory where files are/put files to your working directory\n",
    "#Load libraries\n",
    "library(tidyverse)\n",
    "library(Gviz)\n",
    "library(shiny)\n",
    "library(shinyWidgets)\n",
    "library(datamods)\n",
    "library(biomaRt)\n",
    "library(shinythemes)\n",
    "library(shinysky)\n",
    "\n",
    "\n",
    "#Import files\n",
    "##50 NDD genes\n",
    "LBD <- read.delim(\"LBD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer_shinyapp.txt\", stringsAsFactors = FALSE)\n",
    "FTD <- read.delim(\"FTD_1percFDR_all_info_unfiltered_with_CADDSV_genehancer_shinyapp.txt\", stringsAsFactors = FALSE)\n",
    "\n",
    "##Make chr ordered factor, the sort dfs by factor order\n",
    "LBD$CHROM <- factor(LBD$CHROM, ordered = TRUE, levels = c(seq(1,22),\"X\"))\n",
    "FTD$CHROM <- factor(FTD$CHROM, ordered = TRUE, levels = c(seq(1,22),\"X\"))\n",
    "\n",
    "LBD <- arrange(LBD, CHROM)\n",
    "FTD <- arrange(FTD, CHROM)\n",
    "##High-quality SVs whole genome\n",
    "LBD_gw <- read.delim(\"LBD_high_quality_subset_clean_GQ300missing_all_chr.txt\")\n",
    "FTD_gw <- read.delim(\"FTD_high_quality_subset_clean_GQ300missing_all_chr.txt\")\n",
    "\n",
    "LBD_cases <- read.csv(\"LBD_cases_shinyapp.txt\", sep=\"\")\n",
    "LBD_controls <- read.csv(\"LBD_controls_shinyapp.txt\", sep=\"\")\n",
    "FTD_cases <- read.csv(\"FTD_cases_shinyapp.txt\", sep=\"\")\n",
    "FTD_controls <- read.csv(\"FTD_controls_shinyapp.txt\", sep=\"\")\n",
    "##Make chrom ordered facror and sort by it so chr are ordered in shiny app\n",
    "LBD_gw$CHROM <- factor(LBD_gw$CHROM, ordered = TRUE, levels = c(paste0(rep(\"chr\",22),seq(1,22)),\"chrX\"))\n",
    "FTD_gw$CHROM <- factor(FTD_gw$CHROM, ordered = TRUE, levels = c(paste0(rep(\"chr\",22),seq(1,22)),\"chrX\"))\n",
    "\n",
    "LBD_gw <- arrange(LBD_gw, CHROM)\n",
    "FTD_gw <- arrange(FTD_gw, CHROM)\n",
    "\n",
    "\n",
    "##Gene info file\n",
    "gene_info <- read.csv(\"gene_start_stop_name.txt\", sep=\"\")\n",
    "\n",
    "#Initialize biomart track\n",
    "bm <- useEnsembl(biomart = \"genes\")\n",
    "bm <- useDataset(dataset = \"hsapiens_gene_ensembl\", mart = bm)\n",
    "\n",
    "#Define user interface\n",
    "ui <- navbarPage(\"LBD and FTD/ALS structural variants\", theme = shinytheme(\"lumen\"),\n",
    "                 tabPanel(\"Neurodegenerative gene region visualisation\", icon = icon(name = \"image\", lib = \"font-awesome\"),\n",
    "                          sidebarLayout(\n",
    "                            sidebarPanel(\n",
    "                              width = 3,\n",
    "                              radioButtons(inputId = \"pheno2\", label = \"Phenotype\", choiceValues = c(\"LBD\", \"FTD\"), choiceNames = c(\"LBD\", \"FTD/ALS\"), inline = TRUE),\n",
    "                              pickerInput(inputId = \"gene2\", label = \"Gene\", choices = unique(sort(LBD$GENE)), multiple = FALSE),\n",
    "                              textOutput(outputId = \"SV_info2\"),\n",
    "                              imageOutput(outputId = \"color_legend\", width = \"100%\")\n",
    "                            ),\n",
    "                            mainPanel(\n",
    "                              imageOutput(outputId =  \"img2\")\n",
    "                            )\n",
    "                          )\n",
    "                 ),\n",
    "                 tabPanel(\"Neurodegenerative gene data frame\", icon = icon(name = \"table\", lib = \"font-awesome\"),\n",
    "                          sidebarLayout(\n",
    "                            sidebarPanel(\n",
    "                              width = 3,\n",
    "                              shiny::tags$a(href=\"https://github.com/kkaivola/LBD_FTD_Structural_variants\", \n",
    "                                     \"Download the data frames from here\"),\n",
    "                              radioButtons(inputId = \"dataset\", label = \"Phenotype\", choiceValues = c(\"LBD\", \"FTD\"), choiceNames = c(\"LBD\", \"FTD/ALS\")),\n",
    "                              filter_data_ui(\"filtering\"),\n",
    "                            ),\n",
    "                            mainPanel(\n",
    "                              DT::dataTableOutput(outputId = \"table\")\n",
    "                            )\n",
    "                          )\n",
    "                 ),\n",
    "                 tabPanel(\"Genome-wide visualisation\", icon = icon(name = \"images\", lib = \"font-awesome\"),\n",
    "                          sidebarLayout(\n",
    "                            sidebarPanel(\n",
    "                              width=3,\n",
    "                              shiny::tags$a(href=\"https://github.com/kkaivola/LBD_FTD_Structural_variants\", \n",
    "                                     \"Want to visualize structural variants with regulatory regions, gnomAD variants and more? Get BigBed files for Ensembl/UCSC genome browser from here!\"),\n",
    "                              shiny::tags$p(\" \"),\n",
    "                              shiny::tags$p(\"Number displayed on structural variants is the allele frequency\"),\n",
    "                              shiny::tags$p(\"Click plot to visualize changes after updating genomic coordinates, using zoom, gene search or changing phenotype\"),\n",
    "                              shiny::tags$br(style=\"line-height: 10px\"),\n",
    "                              radioButtons(inputId = \"pheno\", label = \"Phenotype\", choiceValues = c(\"LBD\", \"FTD\"), choiceNames = c(\"LBD\", \"FTD/ALS\"), inline = TRUE),\n",
    "                              shiny::tags$p(\"Gene search\", style = \"font-size:14px;\"),\n",
    "                              shiny::tags$p(\" \"),\n",
    "                              textInput.typeahead(id=\"gene_search\", placeholder = \"Gene name, e.g. GBA\", local=data.frame(name=c(gene_info$external_gene_name)), valueKey = \"name\", tokens =  c(1:length(gene_info$external_gene_name)), template = HTML(\"<p style='font-size:12px;'class='repo-name'>{{name}}</p>\")),\n",
    "                              pickerInput(inputId = \"chrom\", label = \"Chromosome\", choices = c(\"chr1\",\"chr2\",\"chr3\",\"chr4\",\"chr5\",\"chr6\",\"chr7\",\"chr8\",\"chr9\",\"chr10\",\"chr11\",\"chr12\",\"chr13\",\"chr14\",\"chr15\",\"chr16\",\"chr17\",\"chr18\",\"chr19\",\"chr20\",\"chr21\",\"chr22\",\"chrX\"), multiple = FALSE),\n",
    "                              numericRangeInput(inputId = \"genomic_range\", label = \"Genomic range in bp (hg38)\", value = c(155234452,155244699)),\n",
    "                              shiny::actionButton(inputId = \"zoom_out_3\", label = \"Zoom out x3\"),\n",
    "                              shiny::actionButton(inputId = \"zoom_in_3\", label = \"Zoom in x3\"),\n",
    "                              shiny::tags$br(),\n",
    "                              shiny::tags$p(\" \"),\n",
    "                              shiny::actionButton(inputId = \"plot\", label = \"Plot\", icon = icon(name = \"play\", lib = \"font-awesome\"), style='font-size:20px'),\n",
    "                              shiny::tags$br(),\n",
    "                              imageOutput(outputId = \"color_legend2\", width = \"100%\")\n",
    "                            ),\n",
    "                            mainPanel(\n",
    "                              imageOutput(outputId = \"img3\")\n",
    "                            )\n",
    "                          )\n",
    "                          \n",
    "                 ),\n",
    "                 tabPanel(\"Genome-wide data frame\", icon = icon(name = \"table-list\", lib = \"font-awesome\"),\n",
    "                          sidebarLayout(\n",
    "                            sidebarPanel(\n",
    "                              width = 3,\n",
    "                              shiny::tags$a(href=\"https://github.com/kkaivola/LBD_FTD_Structural_variants\", \n",
    "                                     \"Download the data frames from here\"),\n",
    "                              radioButtons(inputId = \"pheno_gw\", label = \"Phenotype\", choiceValues =  c(\"LBD_gw\", \"FTD_gw\"), choiceNames = c(\"LBD\", \"FTD/ALS\")),\n",
    "                              filter_data_ui(\"filtering_gw\")\n",
    "                            ),\n",
    "                            mainPanel(\n",
    "                              DT::dataTableOutput(outputId = \"table_gw\"),\n",
    "                            )\n",
    "                          )\n",
    "                 ),\n",
    "                 tabPanel(\"Info\", icon = icon(\"info\"),\n",
    "                        mainPanel(\n",
    "                          shiny::tags$h1(\"Structural variants in non-Alzheimer's dementias app\"),\n",
    "                          shiny::tags$h2(\"Background\"),\n",
    "                          shiny::tags$p(\"Structural variants cause most variation in genomes but they have been rarely studied due to technical difficulties. This app presents data from Lewy body dementia (LBD) and frontotemporal dementia-amyotrophic lateral sclerosis (FTD/ALS) patients and neurologically healthy controls.\"),\n",
    "                          shiny::tags$p(\"For more details please see our manuscript.\"),\n",
    "                          shiny::tags$h2(\"Structural variant calling and filtering\"),\n",
    "                          shiny::tags$p(\"Structural variant calling was performed with GATK-SV, which uses five structural variant detection algorithms and machine learning to produce consensus variant calls and genotype filtering. The data presented in this app is a high-quality subset of structural variants that was created by further filtering the GATK-SV output with the following criteria:\"),\n",
    "                          shiny::tags$p(\"1. 1 % FDR\"),\n",
    "                          shiny::tags$p(\"2. Variant filter type PASS, MULTIALLELIC, UNRESOLVED\"),\n",
    "                          shiny::tags$p(\"3. GQ < 300 set to missing\"),\n",
    "                          shiny::tags$p(\"4. Genotyping rate > 95 %\"),\n",
    "                          shiny::tags$p(\"5. HWE mid-p adjusted p-value > 0.000001\"),\n",
    "                          shiny::tags$p(\"The final LBD dataset consisted of 2,355 LBD vs. 3,700 controls with 150,752 structural variants\"),\n",
    "                          shiny::tags$p(\"The final FTD/ALS dataset consisted of 2,307 LBD vs. 3,677 controls with 158,991 structural variants\"),\n",
    "                          shiny::tags$h2(\"Contact information\"),\n",
    "                          shiny::tags$h4(\"Karri Kaivola (Application questions)\"),\n",
    "                          shiny::tags$p(\"karri.kaivola@nih.gov / karri.kaivola@helsinki.fi\"),\n",
    "                          shiny::tags$p(\"Neurodegenerative Diseases Research Unit\"),\n",
    "                          shiny::tags$p(\"National Institute of Neurological Disorders and Stroke\"),\n",
    "                          shiny::tags$p(\"National Institutes of Health\"),\n",
    "                          shiny::tags$p(\"Bethesda, Maryland 20892\"),\n",
    "                          shiny::tags$p(\"United States\"),\n",
    "                          shiny::tags$h4(\"Sonja W. Scholz (PI, LBD)\"),\n",
    "                          shiny::tags$p(\"sonja.scholz@nih.gov\"),\n",
    "                          shiny::tags$p(\"Neurodegenerative Diseases Research Unit\"),\n",
    "                          shiny::tags$p(\"National Institute of Neurological Disorders and Stroke\"),\n",
    "                          shiny::tags$p(\"National Institutes of Health\"),\n",
    "                          shiny::tags$p(\"Bethesda, Maryland 20892\"),\n",
    "                          shiny::tags$p(\"United States\"),\n",
    "                          shiny::tags$h4(\"Bryan J. Traynor (PI, FTD/ALS)\"),\n",
    "                          shiny::tags$p(\"bryan.traynor@nih.gov\"),\n",
    "                          shiny::tags$p(\"Neuromuscular Diseases Research Section\"),\n",
    "                          shiny::tags$p(\"Laboratory of Neurogenetics\"),\n",
    "                          shiny::tags$p(\"National Institute on Aging\"),\n",
    "                          shiny::tags$p(\"National Institutes of Health\"),\n",
    "                          shiny::tags$p(\"Bethesda, Maryland 20892\"),\n",
    "                          shiny::tags$p(\"United States\")\n",
    "                        )  \n",
    "                          )\n",
    ")\n",
    "\n",
    "\n",
    "#Define server\n",
    "server <- function(input, output, session) {\n",
    "  \n",
    "  ##Test\n",
    "  data_gw <- reactive({\n",
    "    get(input$pheno_gw)\n",
    "  })\n",
    "  \n",
    "  vars_gw <- reactive({\n",
    "    if (identical(input$pheno_gw, \"LBD_gw\")) {\n",
    "      colnames(LBD_gw)[2:12]\n",
    "    } else {\n",
    "      colnames(FTD_gw)[2:12]\n",
    "    }\n",
    "  })\n",
    "  \n",
    "  res_filter_gw <- filter_data_server(\n",
    "    id = \"filtering_gw\",\n",
    "    data = data_gw,\n",
    "    name = reactive(input$pheno_gw),\n",
    "    widget_num = \"range\",\n",
    "    widget_date = \"slider\",\n",
    "    widget_char = \"picker\",\n",
    "    label_na = \"Missing\",\n",
    "    drop_ids = FALSE,\n",
    "    vars = vars_gw\n",
    "  )\n",
    "  \n",
    "  output$table_gw <- DT::renderDT({\n",
    "    res_filter_gw$filtered()\n",
    "  }, options = list(pageLength = 50))\n",
    "\n",
    "  ##Outputs of SV color legends for SV plots    \n",
    "  output$color_legend <- renderImage({\n",
    "    list(src=file.path(\"color_code_legend.png\"))\n",
    "  }, deleteFile = FALSE)\n",
    "  \n",
    "  output$color_legend2 <- renderImage({\n",
    "    list(src=file.path(\"color_code_legend.png\"))\n",
    "  }, deleteFile = FALSE)\n",
    "  \n",
    "  ##Output NDD gene pre-rendered plots\n",
    "  output$img2 <- renderImage({\n",
    "    list(\n",
    "      src = file.path(\"NIH_SV_images/\",input$pheno2,paste0(input$gene2,\"_\",input$pheno2,\"_candidate_gene_overlap.png\")))\n",
    "  }, deleteFile=FALSE)\n",
    "  \n",
    "  ##Output info text\n",
    "  output$SV_info2 <- renderText({\n",
    "    \"Allele frequency presented on structural variants \\n\"\n",
    "  })\n",
    "  \n",
    "  ##NDD gene data frame filtering and output\n",
    "  data <- reactive({\n",
    "    get(input$dataset)\n",
    "  })\n",
    "  \n",
    "  \n",
    "  vars <- reactive({\n",
    "    if (identical(input$dataset, \"LBD\")) {\n",
    "      colnames(LBD)[c(1:3,6:22)]\n",
    "    } else {\n",
    "      colnames(FTD)[c(1:3,6:22)]\n",
    "    }\n",
    "  })\n",
    "  \n",
    "  res_filter <- filter_data_server(\n",
    "    id = \"filtering\",\n",
    "    data = data,\n",
    "    name = reactive(input$dataset),\n",
    "    widget_num = \"range\",\n",
    "    widget_date = \"slider\",\n",
    "    widget_char = \"picker\",\n",
    "    label_na = \"Missing\",\n",
    "    drop_ids = FALSE,\n",
    "    vars = vars\n",
    "  )\n",
    "  \n",
    "  output$table <- DT::renderDT({\n",
    "    res_filter$filtered()\n",
    "  }, options = list(pageLength = 50))\n",
    "  \n",
    "  ##Genome-wide plotting\n",
    "  ###Input from gene search box updates chromosome and genomic coordinates\n",
    "  observe({\n",
    "    gene_name <- input$gene_search\n",
    "    updatePickerInput(\n",
    "      session = session,\n",
    "      inputId = \"chrom\",\n",
    "      selected = gene_info$chromosome_name[gene_info$external_gene_name == gene_name]\n",
    "    )\n",
    "    updateNumericRangeInput(\n",
    "      session = session,\n",
    "      inputId = \"genomic_range\",\n",
    "      value = c(gene_info$start_position[gene_info$external_gene_name == gene_name], gene_info$end_position[gene_info$external_gene_name == gene_name]),\n",
    "    )\n",
    "  }) %>% bindEvent(input$gene_search, ignoreInit = TRUE)\n",
    "  \n",
    "  ###Input from zoom buttons updates genomic coordinates\n",
    "  observe({\n",
    "    updateNumericRangeInput(\n",
    "      session = session,\n",
    "      inputId = \"genomic_range\",\n",
    "      value = c(round(input$genomic_range[1]-((input$genomic_range[2]-input$genomic_range[1])*1.5)), round(input$genomic_range[2]+((input$genomic_range[2]-input$genomic_range[1])*1.5)))\n",
    "    )\n",
    "  }) %>% bindEvent(input$zoom_out_3, ignoreInit = TRUE)\n",
    "  \n",
    "  observe({\n",
    "    updateNumericRangeInput(\n",
    "      session = session,\n",
    "      inputId = \"genomic_range\",\n",
    "      value = c(round(input$genomic_range[1]+((input$genomic_range[2]-input$genomic_range[1])/1.5)), round(input$genomic_range[2]-((input$genomic_range[2]-input$genomic_range[1])/1.5)))\n",
    "    )\n",
    "  }) %>% bindEvent(input$zoom_in_3, ignoreInit = TRUE)\n",
    "  \n",
    "  ###Plot user-defined genomic region\n",
    "  output$img3 <- renderPlot(width = \"auto\", height = \"auto\", {\n",
    "    #Set variables based on genomic range input\n",
    "    chr <- input$chrom\n",
    "    start <- input$genomic_range[1]\n",
    "    stop <- input$genomic_range[2]\n",
    "    #Select df to plot\n",
    "    if(input$pheno == \"LBD\") {\n",
    "      df_cases <- LBD_cases\n",
    "      df_controls <- LBD_controls\n",
    "    } else {\n",
    "      df_cases <- FTD_cases\n",
    "      df_controls <- FTD_controls\n",
    "    }\n",
    "    ##Find overlaps (3 different criteria) with input region and dfs and extract IDs for filtering\n",
    "    tmp_cases1 <- df_cases %>%\n",
    "      filter(CHROM == chr) %>%\n",
    "      filter(END >= start & END <= stop)\n",
    "    tmp_cases2 <- df_cases %>%\n",
    "      filter(CHROM == chr) %>%\n",
    "      filter(POS >= start & POS <= stop)\n",
    "    tmp_cases3 <- df_cases %>%\n",
    "      filter(CHROM == chr) %>%\n",
    "      filter(POS <= start & END >=stop)\n",
    "    tmp_IDs_cases <- unique(c(tmp_cases1$ID, tmp_cases2$ID, tmp_cases3$ID))\n",
    "    tmp_cases <- df_cases %>%\n",
    "      filter(ID %in% tmp_IDs_cases)\n",
    "    \n",
    "    tmp_controls1 <- df_controls %>%\n",
    "      filter(CHROM == chr) %>%\n",
    "      filter(END >= start & END <= stop)\n",
    "    tmp_controls2 <- df_controls %>%\n",
    "      filter(CHROM == chr) %>%\n",
    "      filter(POS >= start & POS <= stop)\n",
    "    tmp_controls3 <- df_controls %>%\n",
    "      filter(CHROM == chr) %>%\n",
    "      filter(POS <= start & END >=stop)\n",
    "    tmp_IDs_controls <- unique(c(tmp_controls1$ID, tmp_controls2$ID, tmp_controls3$ID))\n",
    "    tmp_controls <- df_controls %>%\n",
    "      filter(ID %in% tmp_IDs_controls)\n",
    "    \n",
    "    ##So that text is shown in plot: if SV POS < start, make POS = start.\n",
    "    tmp_cases$POS[tmp_cases$POS < start] <- start\n",
    "    tmp_controls$POS[tmp_controls$POS < start] <- start\n",
    "    ##So that text is shown in plot: if SV END > stop, make END = stop.\n",
    "    tmp_cases$END[tmp_cases$END >  stop] <- stop\n",
    "    tmp_controls$END[tmp_controls$END > stop] <- stop\n",
    "    ##Make tracks and plot\n",
    "    if ((nrow(tmp_cases) > 0) & (nrow(tmp_controls) > 0)) {\n",
    "      gtrack <- GenomeAxisTrack(fontsize=12)\n",
    "      itrack <- IdeogramTrack(genome = \"hg38\", chromosome = chr, fontsize=14)\n",
    "      biomTrack <- BiomartGeneRegionTrack(transcriptAnnotation = \"symbol\", genome = \"hg38\",chromosome = chr, start = start, end = stop, name = \"Gene\", filter = list(transcript_is_canonical = TRUE), biomart = bm, just.group=\"below\", protein_coding=\"gray\", utr3=\"gray\", utr5=\"gray\", fill=\"gray\")\n",
    "      atrack_cases <- AnnotationTrack(start=tmp_cases$POS, end=tmp_cases$END, chromosome = chr, genome=\"hg38\", name=\"Cases\", feature = tmp_cases$SVTYPE, id=tmp_cases$AF_cases, showFeatureId = TRUE, fontcolor.item=\"black\", col.line=\"white\", min.width=2)\n",
    "      atrack_controls <- AnnotationTrack(start=tmp_controls$POS, end=tmp_controls$END, chromosome = chr, genome=\"hg38\", name=\"Controls\", feature = tmp_controls$SVTYPE, id=tmp_controls$AF_controls, showFeatureId = TRUE, fontcolor.item=\"black\", min.width=2)\n",
    "      plotTracks(list(itrack,gtrack, atrack_cases, atrack_controls, biomTrack), from = start, to = stop, fontcolor.title=\"#808080\", fontsize.group=20, fontsize.title=20, BND=\"#377246\", CPX=\"#86E496\", DEL=\"#D6402D\", DUP=\"#5282AF\", INS=\"#D579E1\", INS_ME=\"#F6AAFF\", INS_ME_ALU=\"#F6AAFF\", INS_ME_LINE1=\"#F6AAFF\", INS_ME_SVA=\"#F6AAFF\", INV=\"#F69A57\")\n",
    "    } else if ((nrow(tmp_cases) > 0) & (nrow(tmp_controls) == 0)) {\n",
    "      gtrack <- GenomeAxisTrack(fontsize=12)\n",
    "      itrack <- IdeogramTrack(genome = \"hg38\", chromosome = chr, fontsize=14)\n",
    "      biomTrack <- BiomartGeneRegionTrack(transcriptAnnotation = \"symbol\", genome = \"hg38\",chromosome = chr, start = start, end = stop, name = \"Gene\", filter = list(transcript_is_canonical = TRUE), biomart = bm, just.group=\"below\", protein_coding=\"gray\", utr3=\"gray\", utr5=\"gray\", fill=\"gray\")\n",
    "      atrack_cases <- AnnotationTrack(start=tmp_cases$POS, end=tmp_cases$END, chromosome = chr, genome=\"hg38\", name=\"Cases\", feature = tmp_cases$SVTYPE, id=tmp_cases$AF_cases, showFeatureId = TRUE, fontcolor.item=\"black\", min.width=2)\n",
    "      plotTracks(list(itrack,gtrack, atrack_cases, biomTrack), from = start, to = stop, fontcolor.title=\"#808080\", fontsize.group=20, fontsize.title=20, BND=\"#377246\", CPX=\"#86E496\", DEL=\"#D6402D\", DUP=\"#5282AF\", INS=\"#D579E1\", INS_ME=\"#F6AAFF\", INS_ME_ALU=\"#F6AAFF\", INS_ME_LINE1=\"#F6AAFF\", INS_ME_SVA=\"#F6AAFF\", INV=\"#F69A57\")\n",
    "    } else if ((nrow(tmp_cases) == 0) & (nrow(tmp_controls) == 0)) {\n",
    "      gtrack <- GenomeAxisTrack(showTitle=TRUE, name=\"No SVs\", fontcolor.title=\"#808080\", rotation.title=0)\n",
    "      plotTracks(gtrack, from = 100, to = 110, title.width = 5)\n",
    "    } else {\n",
    "      gtrack <- GenomeAxisTrack(fontsize=12)\n",
    "      itrack <- IdeogramTrack(genome = \"hg38\", chromosome = chr, fontsize=14)\n",
    "      biomTrack <- BiomartGeneRegionTrack(transcriptAnnotation = \"symbol\", genome = \"hg38\",chromosome = chr, start = start, end = stop, name = \"Gene\", filter = list(transcript_is_canonical = TRUE), biomart = bm, just.group=\"below\", protein_coding=\"gray\", utr3=\"gray\", utr5=\"gray\", fill=\"gray\")\n",
    "      atrack_controls <- AnnotationTrack(start=tmp_controls$POS, end=tmp_controls$END, chromosome = chr, genome=\"hg38\", name=\"Controls\", feature = tmp_controls$SVTYPE, id=tmp_controls$AF_controls, showFeatureId = TRUE, fontcolor.item=\"black\", min.width=2)\n",
    "      plotTracks(list(itrack,gtrack, atrack_controls, biomTrack), from = start, to = stop, fontcolor.title=\"#808080\", fontsize.group=20, fontsize.title=20, BND=\"#377246\", CPX=\"#86E496\", DEL=\"#D6402D\", DUP=\"#5282AF\", INS=\"#D579E1\", INS_ME=\"#F6AAFF\", INS_ME_ALU=\"#F6AAFF\", INS_ME_LINE1=\"#F6AAFF\", INS_ME_SVA=\"#F6AAFF\", INV=\"#F69A57\")\n",
    "    }\n",
    "  }) %>% bindEvent(input$plot, ignoreInit = FALSE, ignoreNULL = FALSE)\n",
    "}\n",
    "\n",
    "#Launch shiny app\n",
    "shinyApp(ui, server)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3495222-832e-4fb1-b4bb-25ab2035afb5",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6234b3-639e-482a-93f2-5280dadeb93f",
   "metadata": {},
   "source": [
    "## Manhattan plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d18612",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Check number of SVs in GWAS result files to determine Bonferroni correction threshold\n",
    "\n",
    "echo \"Number of SVs in LBD analysis:\"\n",
    "grep -v 'CHROM' $PATH5/Analysis.GLM.hg38_minGQ300/LBD/LBD.controls.UNRELATED.SNVindels.SV-1perc-fdr-minGQ300.hg38.hwe1e-6.maf001cases.exclTelomereFlank100kb.exclCentromereFlank2.5Mb.exclVDJ.QUAL500.autosomesOnly.withVarFilterInfo.PASS.UNRESOLVED.QUAL500.TIDY.txt | wc -l\n",
    "echo \"Number of SVs in FTD analysis:\"\n",
    "grep -v 'CHROM' $PATH5/Analysis.GLM.hg38_minGQ300/FTD/FTD.controls.UNRELATED.SNVindels.SV-1perc-fdr-minGQ300.hg38.hwe1e-6.maf001cases.exclTelomereFlank100kb.exclCentromereFlank2.5Mb.exclVDJ.QUAL500.autosomesOnly.withVarFilterInfo.PASS.UNRESOLVED.QUAL500.TIDY.txt | wc -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonferroni corrected thresholds are:\n",
    "print(\"LBD:\", 0.05/4889)\n",
    "print(\"FTD:\", 0.05/4699)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd6830-6d19-481c-8482-7bac9ed7c6e7",
   "metadata": {},
   "source": [
    "### Lewy body dementias plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ac5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5012d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "subset(gwas_data, ID %in% c(\"LBD_DUP_chr4_3651\", \"LBD_DEL_chr1_11039\", \"LBD_DUP_chr21_888\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274ab4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#Code modified from https://danielroelfs.com/blog/how-i-create-manhattan-plots-using-ggplot/ \n",
    "\n",
    "#Plot LBD manhattan plot\n",
    "\n",
    "##Load libraries\n",
    "library(tidyverse)\n",
    "library(ggtext)\n",
    "library(data.table)\n",
    "library(ggrepel)\n",
    "\n",
    "##Import data\n",
    "LBD <- fread(\"$PATH5/Analysis.GLM.hg38_minGQ300/LBD/LBD.controls.UNRELATED.SNVindels.SV-1perc-fdr-minGQ300.hg38.hwe1e-6.maf001cases.exclTelomereFlank100kb.exclCentromereFlank2.5Mb.exclVDJ.QUAL500.autosomesOnly.withVarFilterInfo.PASS.UNRESOLVED.QUAL500.TIDY.txt\")\n",
    "\n",
    "##Set significance threshold\n",
    "sig <- 0.05/4889\n",
    "\n",
    "##Rename data to suit downstream code\n",
    "gwas_data <- LBD\n",
    "colnames(gwas_data)[c(1,2,12)] <- c(\"chr\", \"bp\", \"p\")\n",
    "\n",
    "##Downstream code\n",
    "data_cum <- gwas_data %>% \n",
    "  group_by(chr) %>% \n",
    "  summarise(max_bp = max(bp)) %>% \n",
    "  mutate(bp_add = lag(cumsum(as.numeric(max_bp)), default = 0)) %>% \n",
    "  select(chr, bp_add)\n",
    "\n",
    "\n",
    "gwas_data <- gwas_data %>% \n",
    "  inner_join(data_cum, by = \"chr\") %>% \n",
    "  mutate(bp_cum = bp + bp_add)\n",
    "\n",
    "\n",
    "axis_set <- gwas_data %>% \n",
    "  group_by(chr) %>% \n",
    "  summarize(center = mean(bp_cum))\n",
    "\n",
    "ylim <- gwas_data %>% \n",
    "  filter(p == min(p)) %>% \n",
    "  mutate(ylim = abs(floor(log10(p))) + 2) %>% \n",
    "  pull(ylim)\n",
    "\n",
    "highlight_df <- gwas_data %>% \n",
    "             filter(p<=0.000012)\n",
    "\n",
    "\n",
    "manhplot <- ggplot(gwas_data, aes(x = bp_cum, y = -log10(p), \n",
    "                                  color = as_factor(chr))) +\n",
    "  geom_hline(yintercept = -log10(sig), color = \"grey40\", linetype = \"dashed\") + \n",
    "  geom_point(alpha = 0.75) +\n",
    "  geom_point(data=highlight_df, aes(x=bp_cum,y=-log10(p)), color=c('gray','red')) +\n",
    "  geom_text(aes(label=ifelse(p<sig,as.character(ID),'')), color=\"black\",hjust=0,vjust=-2) +\n",
    "  scale_x_continuous(label = axis_set$chr, breaks = axis_set$center, expand = c(0.01,0.01)) +\n",
    "  scale_y_continuous(expand = c(0,0), limits = c(0, ylim)) +\n",
    "  scale_color_manual(values = rep(c(\"#276FBF\", \"#183059\"), unique(length(axis_set$chr)))) +\n",
    "  scale_size_continuous(range = c(0.5,3)) +\n",
    "  labs(x = NULL, \n",
    "       y = \"-log<sub>10</sub>(p)\") + \n",
    "  theme_minimal() +\n",
    "  theme( \n",
    "    legend.position = \"none\",\n",
    "    panel.grid.major.x = element_blank(),\n",
    "    panel.grid.minor.x = element_blank(),\n",
    "    axis.title.y = element_markdown(),\n",
    "    axis.line = element_line(colour = \"black\", linetype=1)\n",
    "  )\n",
    "\n",
    "\n",
    "manhplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff615a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "ggsave(plot = manhplot, width = 10, height = 5, dpi = 300, filename = \"LBD_1percfdr_GQ300_TIDY_manhattan.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa71317a-5bd9-40f7-9d7c-f25a358f4b92",
   "metadata": {},
   "source": [
    "### Frontotemporal dementia/amyotrophic lateral sclerosis plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ee0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#Code modified from https://danielroelfs.com/blog/how-i-create-manhattan-plots-using-ggplot/ \n",
    "options(repr.plot.width=6)\n",
    "#Plot LBD manhattan plot\n",
    "\n",
    "library(tidyverse)\n",
    "library(ggtext)\n",
    "library(data.table)\n",
    "LBD <- fread(\"$PATH5/Analysis.GLM.hg38_minGQ300/FTD/FTD.controls.UNRELATED.SNVindels.SV-1perc-fdr-minGQ300.hg38.hwe1e-6.maf001cases.exclTelomereFlank100kb.exclCentromereFlank2.5Mb.exclVDJ.QUAL500.autosomesOnly.withVarFilterInfo.PASS.UNRESOLVED.QUAL500.TIDY.txt\")\n",
    "\n",
    "sig <- 0.05/4699\n",
    "\n",
    "gwas_data <- LBD\n",
    "colnames(gwas_data)[c(1,2,12)] <- c(\"chr\", \"bp\", \"p\")\n",
    "\n",
    "\n",
    "data_cum <- gwas_data %>% \n",
    "  group_by(chr) %>% \n",
    "  summarise(max_bp = max(bp)) %>% \n",
    "  mutate(bp_add = lag(cumsum(as.numeric(max_bp)), default = 0)) %>% \n",
    "  select(chr, bp_add)\n",
    "\n",
    "\n",
    "gwas_data <- gwas_data %>% \n",
    "  inner_join(data_cum, by = \"chr\") %>% \n",
    "  mutate(bp_cum = bp + bp_add)\n",
    "\n",
    "\n",
    "axis_set <- gwas_data %>% \n",
    "  group_by(chr) %>% \n",
    "  summarize(center = mean(bp_cum))\n",
    "\n",
    "ylim <- gwas_data %>% \n",
    "  filter(p == min(p)) %>% \n",
    "  mutate(ylim = abs(floor(log10(p))) + 2) %>% \n",
    "  pull(ylim)\n",
    "\n",
    "\n",
    "\n",
    "highlight_df <- gwas_data %>% \n",
    "             filter(p<=0.000012)\n",
    "\n",
    "\n",
    "manhplot <- ggplot(gwas_data, aes(x = bp_cum, y = -log10(p), \n",
    "                                  color = as_factor(chr))) +\n",
    "  geom_hline(yintercept = -log10(sig), color = \"grey40\", linetype = \"dashed\") + \n",
    "  geom_point(alpha = 0.75) +\n",
    "  geom_point(data=highlight_df, aes(x=bp_cum,y=-log10(p)), color=c('red','red','gray')) +\n",
    "  geom_text(aes(label=ifelse(p<sig,as.character(ID),'')), color=\"black\",hjust=0.8,vjust=-2) +\n",
    "  scale_x_continuous(label = axis_set$chr, breaks = axis_set$center, expand = c(0.01,0.01)) +\n",
    "  scale_y_continuous(expand = c(0,0), limits = c(0, ylim)) +\n",
    "  scale_color_manual(values = rep(c(\"#276FBF\", \"#183059\"), unique(length(axis_set$chr)))) +\n",
    "  scale_size_continuous(range = c(0.5,3)) +\n",
    "  labs(x = NULL, \n",
    "       y = \"-log<sub>10</sub>(p)\") + \n",
    "  theme_minimal() +\n",
    "  theme( \n",
    "    legend.position = \"none\",\n",
    "    panel.grid.major.x = element_blank(),\n",
    "    panel.grid.minor.x = element_blank(),\n",
    "    axis.title.y = element_markdown(),\n",
    "    axis.line = element_line(colour = \"black\", linetype=1)\n",
    "  )\n",
    "\n",
    "\n",
    "manhplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "ggsave(plot = manhplot, width = 10, height = 5, dpi = 300, filename = \"FTD_1percfdr_GQ300_TIDY_manhattan.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296ba3a-026b-4643-a3ce-52e5b59421c5",
   "metadata": {},
   "source": [
    "## 95 % condifence intervals for genome-wide association study hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355d184-c600-4ee6-8be9-8fcc158477ad",
   "metadata": {},
   "source": [
    "95% CIs were not included in PLINK output, but they can be calculated with:  \n",
    "lower = BETA - 1.96*SE  \n",
    "upper = BETA + 1.96*SE  \n",
    "  \n",
    "Since we want CIs for OR, we do e^lower and e^upper.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c700395-1942-49dc-806c-8db6cba48930",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Extract SV ID, Beta and SE from GWAS top variants (also P and OR value to ease reporting) and calculate CIs\n",
    "\n",
    "awk '{print $3, $14, $15, $16, $17,2.7182818^($15-1.96*$16),2.7182818^($15+1.96*$16)}'  $PATH5/Analysis.GLM.hg38_minGQ300/FTD/FTD.controls.UNRELATED.SNVindels.SV-1perc-fdr-minGQ300.hg38.hwe1e-6.maf001cases.exclTelomereFlank100kb.exclCentromereFlank2.5Mb.exclVDJ.QUAL500.autosomesOnly.withVarFilterInfo.PASS.UNRESOLVED.QUAL500.FINAL.TIDY.txt > $PATH1/NIH_FALL_2021_SVs_1percFDR/FTD_GWAS_hit_95CIs.txt\n",
    "awk '{print $3, $14, $15, $16, $17,2.7182818^($15-1.96*$16),2.7182818^($15+1.96*$16)}'  $PATH5/Analysis.GLM.hg38_minGQ300/LBD/LBD.controls.UNRELATED.SNVindels.SV-1perc-fdr-minGQ300.hg38.hwe1e-6.maf001cases.exclTelomereFlank100kb.exclCentromereFlank2.5Mb.exclVDJ.QUAL500.autosomesOnly.withVarFilterInfo.PASS.UNRESOLVED.QUAL500.FINAL.TIDY.txt > $PATH1/NIH_FALL_2021_SVs_1percFDR/LBD_all_GWAS_hit_95CIs.txt\n",
    "awk '{print $3, $14, $15, $16, $17,2.7182818^($15-1.96*$16),2.7182818^($15+1.96*$16)}'  $PATH5/Analysis.GLM.hg38_minGQ300/LBD.path.controls1/LBDpath.controls.UNRELATED.SNVindels.SV-1perc-fdr-minGQ300.hg38.hwe1e-6.maf001cases.exclTelomereFlank100kb.exclCentromereFlank2.5Mb.exclVDJ.QUAL500.autosomesOnly.withVarFilterInfo.PASS.UNRESOLVED.QUAL500.FINAL.TIDY.txt > $PATH1/NIH_FALL_2021_SVs_1percFDR/LBD_path_GWAS_hit_95CIs.txt\n",
    "awk '{print $3, $14, $15, $16, $17,2.7182818^($15-1.96*$16),2.7182818^($15+1.96*$16)}'  $PATH5/Analysis.GLM.hg38_minGQ300/LBD.clin.controls2/LBDclin.controls.UNRELATED.SNVindels.SV-1perc-fdr-minGQ300.hg38.hwe1e-6.maf001cases.exclTelomereFlank100kb.exclCentromereFlank2.5Mb.exclVDJ.QUAL500.autosomesOnly.withVarFilterInfo.PASS.UNRESOLVED.QUAL500.FINAL.TIDY.txt > $PATH1/NIH_FALL_2021_SVs_1percFDR/LBD_clin_GWAS_hit_95CIs.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f2f35-022b-4bd7-b61d-6a790b2ec9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Grep top hits from the right file\n",
    "echo \"LBD path\"\n",
    "echo \"ID OR BETA SE P 95%CI_lower 95%CI_upper\"\n",
    "grep -we 'LBD_DUP_chr7_2098' -we 'LBD_DEL_chr18_4975' $PATH1/NIH_FALL_2021_SVs_1percFDR/LBD_path_GWAS_hit_95CIs.txt\n",
    "\n",
    "echo -e \"\\n LBD clin\"\n",
    "echo \"ID OR BETA SE P 95%CI_lower 95%CI_upper\"\n",
    "grep -we 'LBD_DEL_chr21_374' -we 'LBD_DEL_chr8_2722' $PATH1/NIH_FALL_2021_SVs_1percFDR/LBD_clin_GWAS_hit_95CIs.txt\n",
    "\n",
    "echo -e \"\\n LBD all\"\n",
    "echo \"ID OR BETA SE P 95%CI_lower 95%CI_upper\"\n",
    "grep -we 'LBD_DUP_chr7_2098' -we 'LBD_DEL_chr12_9172' -e 'LBD_DEL_chr18_4975' -e 'LBD_DEL_chr21_374' -e 'LBD_DEL_chr8_2722' $PATH1/NIH_FALL_2021_SVs_1percFDR/LBD_all_GWAS_hit_95CIs.txt\n",
    "\n",
    "echo -e \"\\n FTD all\"\n",
    "echo \"ID OR BETA SE P 95%CI_lower 95%CI_upper\"\n",
    "grep -we 'FTD_BND_chr9_581' -we 'FTD_DEL_chr21_304' -we 'FTD_CPX_chr17_77' $PATH1/NIH_FALL_2021_SVs_1percFDR/FTD_GWAS_hit_95CIs.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca6389-d07d-4f55-b82c-f8867b4ee659",
   "metadata": {},
   "source": [
    "## TPCN1 plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa58c58f-7625-4d57-9696-363a817db9e6",
   "metadata": {},
   "source": [
    "### Locus zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH3/\n",
    "mkdir TPCN1_locuszoom_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce6409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Locuszoom takes LD file only in a specific format. Variant ID is chr:pos_ref/alt Data wrangle to that format\n",
    "cd $PATH3/TPCN1_locuszoom_prep\n",
    "module load plink/2.3-alpha\n",
    "\n",
    "##Extract variants from region of interest from clean(ish) files\n",
    "plink2 \\\n",
    "--bfile $PATH5/LBD_minGQ300/SNVindels.SV.LBD.UNRELATED.merged.chr12 \\\n",
    "--keep-allele-order \\\n",
    "--chr 12 \\\n",
    "--from-bp 113045316 \\\n",
    "--to-bp 113445316 \\\n",
    "--make-bed \\\n",
    "--out tmp_TPCN1_locus\n",
    "\n",
    "##Make file with new IDs\n",
    "awk '{print $1\":\"$4\"_\"$6\"/\"$5,$2}' tmp_TPCN1_locus.bim > tmp_TPCN1_locus_SV_newnames.txt\n",
    "\n",
    "##Update IDs\n",
    "plink2 --bfile tmp_TPCN1_locus --update-name tmp_TPCN1_locus_SV_newnames.txt 1 2 --make-bed --out tmp_TPCN1_locus_newnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee53288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Calculate LD and format according to locuszooms instructions: R2\n",
    "cd $PATH3/TPCN1_locuszoom_prep\n",
    "module load plink/1.9\n",
    "\n",
    "plink \\\n",
    "--r2 \\\n",
    "--bfile tmp_TPCN1_locus_newnames \\\n",
    "--ld-window 499999 \\\n",
    "--ld-window-kb 500 \\\n",
    "--ld-window-r2 0.0 \\\n",
    "--ld-snp \"12:113245316_N/<DEL>\"\n",
    "\n",
    "cat plink.ld | tail -n+2 | sed 's/^[[:space:]]*//g' | sed 's/[[:space:]]*$//g' | tr -s ' ' '\\t' | sort -k4,4 -k5,5n | bgzip > plink.ld.tab.gz && tabix -s4 -b5 -e5 plink.ld.tab.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Calculate LD and format according to locuszooms instructions: D'\n",
    "cd $PATH3/TPCN1_locuszoom_prep\n",
    "module load plink/1.9\n",
    "module load samtools\n",
    "\n",
    "plink \\\n",
    "--r2 dprime \\\n",
    "--bfile tmp_TPCN1_locus_newnames \\\n",
    "--ld-window 499999 \\\n",
    "--ld-window-kb 500 \\\n",
    "--ld-window-r2 0.0 \\\n",
    "--ld-snp \"12:113245316_N/<DEL>\" \\\n",
    "--out dprime_ld\n",
    "\n",
    "##Format to make locuszoom compatible, add step to cut R2 column\n",
    "\n",
    "cat dprime_ld.ld | tail -n+2 | sed 's/^[[:space:]]*//g' | sed 's/[[:space:]]*$//g' | tr -s ' ' '\\t' | sort -k4,4 -k5,5n | cut -f1,2,3,4,5,6,8 | bgzip > dprime_ld.ld.tab.gz && tabix -s4 -b5 -e5 dprime_ld.ld.tab.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77518f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "##Run glm again for this region only to get result file\n",
    "cd $PATH3/TPCN1_locuszoom_prep\n",
    "module load plink/2.3-alpha\n",
    "\n",
    "plink2 \\\n",
    "--bfile tmp_TPCN1_locus_newnames \\\n",
    "--covar $PATH5/COVARIATES.SNVindels.SV.freeze9.LBD.controls.UNRELATED_minGQ300.txt \\\n",
    "--covar-name GENDER,CONSENSUS_AGE,PC1,PC3,PC4,PC7,PC8 \\\n",
    "--covar-variance-standardize \\\n",
    "--glm hide-covar firth-fallback cols=+a1freq,+a1freqcc,+a1count,+totallele,+a1countcc,+totallelecc,+err \\\n",
    "--out tmp_TPCN1_region_glmrerun \\\n",
    "--pheno $PATH5/COVARIATES.SNVindels.SV.freeze9.LBD.controls.UNRELATED_minGQ300.txt \\\n",
    "--pheno-name AFFECTION_STATUS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d8915-a4da-4957-a136-82689eb63f54",
   "metadata": {},
   "source": [
    "## Beta-beta plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f8fc5-b0c5-42db-9dc9-379375409593",
   "metadata": {},
   "source": [
    "### Beta-beta plot of Belenguez Alzheimer's disease TPCN1 and our TPCN1 loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599407ae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/beta_beta_plots\n",
    "\n",
    "##Download Belenguez harmonized summary statistics\n",
    "wget http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90027001-GCST90028000/GCST90027158/harmonised/35379992-GCST90027158-MONDO_0004975.h.tsv.gz\n",
    "gunzip  35379992-GCST90027158-MONDO_0004975.h.tsv.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9fa95d-2546-4ec5-8a93-7039736a66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/beta_beta_plots\n",
    "\n",
    "#Download Chia et al harmonized summary statistics\n",
    "wget http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90001001-GCST90002000/GCST90001390/harmonised/33589841-GCST90001390-EFO_0006792.h.tsv.gz\n",
    "gunzip 33589841-GCST90001390-EFO_0006792.h.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c651e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Extract analyzed SNPS/indels from the TPCN1 LD block (region from locuszoom plot) from LBD summary stats\n",
    "cd $PATH2/beta_beta_plots\n",
    "\n",
    "##Extract TPCN1 haplotype region\n",
    "awk '($3==\"hm_chrom\" || ($3==12 && $4>113150000 && $4<113350000))' 33589841-GCST90001390-EFO_0006792.h.tsv > TPCN1_analyzed_snps_indels_glm.txt\n",
    "\n",
    "##Get IDs\n",
    "awk '(NR>1) {print $1}' TPCN1_analyzed_snps_indels_glm.txt > TPCN1_analyzed_snps_indels.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Grep TPCN1 haplotype SNPs from harmonized Belenguez summary stats\n",
    "cd $PATH2/beta_beta_plots\n",
    "\n",
    "head -n1 35379992-GCST90027158-MONDO_0004975.h.tsv > 35379992-GCST90027158-MONDO_0004975.h._TPCN1_SNPs.tsv\n",
    "grep -Ff TPCN1_analyzed_snps_indels.txt 35379992-GCST90027158-MONDO_0004975.h.tsv >> 35379992-GCST90027158-MONDO_0004975.h._TPCN1_SNPs.tsv\n",
    "\n",
    "##Check how many were found\n",
    "echo \"number of searched SNPs:\"\n",
    "wc -l TPCN1_analyzed_snps_indels.txt\n",
    "echo \"Number of found SNPs\"\n",
    "wc -l 35379992-GCST90027158-MONDO_0004975.h._TPCN1_SNPs.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce55590",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a574d790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#####beta-beta plot TPCN1 us vs belenguez\n",
    "##Set wd\n",
    "setwd(\"$PATH2/beta_beta_plots\")\n",
    "\n",
    "##Load libraries\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(scales)\n",
    "\n",
    "##Import data\n",
    "our <- read.delim(\"TPCN1_analyzed_snps_indels_glm.txt\")\n",
    "belenguez <- read.delim(\"35379992-GCST90027158-MONDO_0004975.h._TPCN1_SNPs.tsv\")\n",
    "\n",
    "##Merge dfs by SNP ID\n",
    "df <- merge(our, belenguez, by=\"hm_variant_id\", how=\"union\", suffixes = c(\"_LBD\", \"_AD\"))\n",
    "\n",
    "print(head(df))\n",
    "##Harmonize allele for which effect was tested tested between our and Belenguez data, if all effect alleles are not the same\n",
    "print(table(df$hm_effect_allele_LBD == df$hm_effect_allele_AD))\n",
    "\n",
    "##Create variable that shows only suggestive p value variants\n",
    "df$suggestive <- ifelse((df$p_value_LBD < 0.00001 | df$p_value_AD < 0.00001), TRUE, FALSE)\n",
    "\n",
    "##Subset only variants that show suggestive association to either trait\n",
    "df2 <- df %>%\n",
    "  filter(p_value_LBD < 0.005 | p_value_AD < 0.005)\n",
    "\n",
    "df3 <- df %>%\n",
    "  filter(p_value_LBD < 0.00001 | p_value_AD <0.00001)\n",
    "\n",
    "##Correlation tests\n",
    "cor1 <- cor.test(df$hm_beta_LBD, df$hm_beta_AD, \n",
    "         method = \"pearson\")\n",
    "print(cor1)\n",
    "print(cor1$p.value)\n",
    "\n",
    "cor2 <- cor.test(df2$hm_beta_LBD, df2$hm_beta_AD, \n",
    "         method = \"pearson\")\n",
    "print(cor2)\n",
    "\n",
    "cor3 <- cor.test(df3$hm_beta_LBD, df3$hm_beta_AD, \n",
    "         method = \"pearson\")\n",
    "print(cor3)\n",
    "\n",
    "##Fancier plot (modifier Cornelis's code)\n",
    "###Plot unfiltered\n",
    "print(ggplot(df, aes(x=hm_beta_AD, y=hm_beta_LBD)) +\n",
    "  geom_point(aes(color=suggestive)) + \n",
    "  scale_color_manual(values = c('black', 'red')) +\n",
    "  theme_bw() + \n",
    "  theme(legend.position=\"none\") +\n",
    "  geom_smooth(se = T, method = lm) + \n",
    "  geom_vline(xintercept = 0, linetype = 2) + \n",
    "  geom_hline(yintercept = 0, linetype = 2) +\n",
    "  xlab(\"TPCN1 locus beta in AD\") +\n",
    "  ylab(\"TPCN1 locus beta in LBD\") +\n",
    "  ylim(-0.4,0.4))\n",
    "      \n",
    "#if want to add annotation annotate(\"text\", size = 3, x=-0.1, y=0.35, label= paste(\"cor =\", round(cor1$estimate, 2), \"\\n\", \"p = \", scientific(cor1$p.value, 2))))\n",
    "\n",
    "ggsave(filename = \"beta_beta_plot_TPCN1_LD_region.pdf\", plot = last_plot(), device = \"pdf\", dpi = 300, width = 3, height=4.4, units = \"in\" )\n",
    "\n",
    "\n",
    "###Plot p value filtered\n",
    "print(ggplot(df2, aes(x=hm_beta_AD, y=hm_beta_LBD)) +\n",
    "  geom_point(aes(color=suggestive)) + \n",
    "  scale_color_manual(values = c('black', 'red')) +\n",
    "  theme_bw() + \n",
    "  theme(legend.position=\"none\") + \n",
    "  geom_smooth(se = T, method = lm) + \n",
    "  geom_vline(xintercept = 0, linetype = 2) + \n",
    "  geom_hline(yintercept = 0, linetype = 2) +\n",
    "  xlab(\"beta in Belenguez et. al. GWAS\") +\n",
    "  ylab(\"beta in this study\") +\n",
    "  annotate(\"text\", size = 8, x=-0.1, y=0.3, label= paste(\"cor =\", round(cor2$estimate, 2), \",\", \"p = \", scientific(cor2$p.value, 2))))\n",
    "\n",
    "###Plot p value filtered2\n",
    "ggplot(df3, aes(x=hm_beta_AD, y=beta_LBD)) +\n",
    "  geom_point(aes(color=suggestive)) + \n",
    "  scale_color_manual(values = c('black', 'red')) +\n",
    "  theme_bw() + \n",
    "  theme(legend.position=\"none\") + \n",
    "  geom_smooth(se = T, method = lm) + \n",
    "  geom_vline(xintercept = 0, linetype = 2) + \n",
    "  geom_hline(yintercept = 0, linetype = 2) +\n",
    "  xlab(\"beta in Belenguez et. al. GWAS\") +\n",
    "  ylab(\"beta in this study\") +\n",
    "  annotate(\"text\", x=-0.05, y=0.5, label= paste(\"cor =\", round(cor3$estimate, 2), \",\", \"p = \", scientific(cor3$p.value, 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930df83e-a59d-489c-92af-1a5739c70544",
   "metadata": {},
   "source": [
    "### Beta-beta plot of Lewy body dementias and Parkinsons' disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d872360",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Copy Nalls et al PD symmary stats (without 23andme) from Ruth\n",
    "cd /$PATH2/beta_beta_plots\n",
    "cp $PATH9/GWAS_LBD.v2/FIGURES_PUBLICATION/AdditionalInfo/LBDoverlap.AD.PD.GWAS/nallsEtAl2019_excluding23andMe_allVariants.TIDY.hg38.txt .\n",
    "\n",
    "#Extract only TPCN1 LD block\n",
    "awk '(NR==1 || ($1 == 12 && $10 > 113150000 && $10 < 113350000))' nallsEtAl2019_excluding23andMe_allVariants.TIDY.hg38.txt > nallsEtAl2019_excluding23andMe_TPCN1_LD_block.TIDY.hg38.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af01a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#####beta-beta plot TPCN1 us vs nalls\n",
    "#####Talked with Raph, he suggested either defining the locus or using +-1Mb of the top variant. He also said he often includes only variants that are suggestive in either data set\n",
    "#####We have defined the region with locuszoom, so use that region. \n",
    "##Set wd\n",
    "setwd(\"$PATH2/beta_beta_plots\")\n",
    "\n",
    "##Load libraries\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(scales)\n",
    "\n",
    "#Import files\n",
    "LBD <- read.delim(\"TPCN1_analyzed_snps_indels_glm.txt\")\n",
    "PD <- read.delim(\"nallsEtAl2019_excluding23andMe_TPCN1_LD_block.TIDY.hg38.txt\")\n",
    "\n",
    "#Merge\n",
    "df <- merge(LBD, PD, by.x = \"hm_pos\", by.y=\"POS_hg38\", how = union)\n",
    "\n",
    "#check effect allele matching\n",
    "\n",
    "print(table(df$hm_effect_allele == df$EffectAllele))\n",
    "\n",
    "#Exclude those with different effect allele since only 6 of them\n",
    "match <- df$hm_effect_allele == df$EffectAllele\n",
    "df <- df[match,]\n",
    "\n",
    "#check effect allele matching v2\n",
    "print(table(df$hm_effect_allele == df$EffectAllele))\n",
    "\n",
    "#calculate correlation\n",
    "\n",
    "cor1 <- cor.test(df$hm_beta, df$PD.beta, method = \"pearson\")\n",
    "print(cor1)\n",
    "\n",
    "#Plot\n",
    "print(ggplot(df, aes(x=PD.beta, y=hm_beta)) +\n",
    "        geom_point() +\n",
    "        scale_color_manual(values = c('black', 'red')) +\n",
    "        theme_bw() + \n",
    "        theme(legend.position=\"none\") +\n",
    "        geom_smooth(se = T, method = lm) + \n",
    "        geom_vline(xintercept = 0, linetype = 2) + \n",
    "        geom_hline(yintercept = 0, linetype = 2) +\n",
    "        xlab(\"TPCN1 locus beta in PD\") +\n",
    "        ylab(\"TPCN1 locus beta in LBD\") +\n",
    "        ylim(-0.4,0.4))\n",
    "\n",
    "ggsave(filename = \"beta_beta_plot_TPCN1_LD_region_PD.pdf\", plot = last_plot(), device = \"pdf\", dpi = 300, width = 3, height=4.4, units = \"in\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24dd37-6ca0-4d38-af4a-424ba9c2c21e",
   "metadata": {},
   "source": [
    "## Cohort demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc6317-c5d8-43be-a80c-91488041e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b50fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "###LBD GATK-SV cohort\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(gmodels)\n",
    "\n",
    "#Import files\n",
    "LBD_analyzed_samples <- fread(\"$PATH2/clean_high_quality_vcfs/tmp_LBD_analyzed_samples.txt\", header = FALSE)\n",
    "LBD_covars <- fread(\"$PATH5/COVARIATES.SNVindels.SV.freeze9.LBD.controls.UNRELATED_minGQ300.txt\", header = TRUE)\n",
    "\n",
    "#Subset covar file to include only analyzed samples\n",
    "LBD_covars <- LBD_covars %>%\n",
    "    filter(IID %in% LBD_analyzed_samples$V1)\n",
    "\n",
    "#Get sex proportions per case-control group\n",
    "print(CrossTable(LBD_covars$AFFECTION_STATUS,LBD_covars$SEX, prop.r=TRUE, prop.c=F, prop.t=F, prop.chisq=F))\n",
    "\n",
    "#Get age summaries per phenotype\n",
    "print(summary(subset(LBD_covars, AFFECTION_STATUS == 1, CONSENSUS_AGE)))\n",
    "print(summary(subset(LBD_covars, AFFECTION_STATUS == 2, CONSENSUS_AGE)))\n",
    "\n",
    "#Get clin vs path dg summaries\n",
    "print(table(LBD_covars$AFFECTION_STATUS, LBD_covars$DIAGNOSIS_TYPE, useNA=\"ifany\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9624834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "###FTD GATK-SV cohort\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(gmodels)\n",
    "\n",
    "#Import files\n",
    "FTD_analyzed_samples <- fread(\"$PATH2/clean_high_quality_vcfs/tmp_FTD_analyzed_samples.txt\", header = FALSE)\n",
    "FTD_covars <- fread(\"$PATH5/COVARIATES.SNVindels.SV.freeze9.FTD.controls.UNRELATED_minGQ300.txt\", header = TRUE)\n",
    "\n",
    "#Subset covar file to include only analyzed samples\n",
    "FTD_covars <- FTD_covars %>%\n",
    "    filter(IID %in% FTD_analyzed_samples$V1)\n",
    "\n",
    "#Get sex proportions per case-control group\n",
    "print(CrossTable(FTD_covars$AFFECTION_STATUS,FTD_covars$SEX, prop.r=TRUE, prop.c=F, prop.t=F, prop.chisq=F))\n",
    "\n",
    "#Get age summaries per phenotype\n",
    "print(summary(subset(FTD_covars, AFFECTION_STATUS == 1, CONSENSUS_AGE)))\n",
    "print(summary(subset(FTD_covars, AFFECTION_STATUS == 2, CONSENSUS_AGE)))\n",
    "\n",
    "#Get clin vs path dg summaries\n",
    "print(table(FTD_covars$AFFECTION_STATUS, FTD_covars$DIAGNOSIS_TYPE, useNA=\"ifany\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de580a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "###LBD replication (BBSeq and Demseq2) cohort\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(gmodels)\n",
    "\n",
    "#Import files\n",
    "LBD_analyzed_samples <- fread(\"$PATH3/replication_TPCN1_BBSeq_Demseq2/tmp_analyzed_samples.txt\", header = FALSE)\n",
    "LBD_age_sex <- fread(\"$PATH3/replication_TPCN1_BBSeq_Demseq2/BBSeq_Demseq2_covariates.txt\", header = TRUE)\n",
    "LBD_pheno <- fread(\"pheno_LBD_cases.txt\")\n",
    "\n",
    "#Subset covar file to include only analyzed samples\n",
    "LBD_pheno <- LBD_pheno %>%\n",
    "    filter(IID %in% LBD_analyzed_samples$V1)\n",
    "print(dim(LBD_pheno))\n",
    "LBD_age_sex <- LBD_age_sex %>%\n",
    "    filter(IID %in% LBD_analyzed_samples$V1)\n",
    "print(dim(LBD_age_sex))\n",
    "\n",
    "#Merge LBD_pheno and LBD covar since ~23 samples have wrong phenotype in covar file\n",
    "df <- merge(LBD_pheno, LBD_age_sex, by = c(\"IID\",\"FID\"))\n",
    "\n",
    "#Get sex proportions per case-control group\n",
    "print(CrossTable(df$LBD,df$SEX, prop.r=TRUE, prop.c=F, prop.t=F, prop.chisq=F))\n",
    "\n",
    "#Get age summaries per phenotype\n",
    "print(summary(subset(df, LBD == 1, Age)))\n",
    "print(summary(subset(df, LBD == 2, Age)))\n",
    "\n",
    "#Get clin vs path dg summaries\n",
    "#print(table(df$LBD, df$DIAGNOSIS_TYPE, useNA=\"ifany\"))\n",
    "\n",
    "head(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e999d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Get numbers of path vs clin cases in LBD replication cohort\n",
    "cd $PATH3/replication_TPCN1_BBSeq_Demseq2\n",
    "grep -wFf tmp_analyzed_samples.txt pheno_LBD_cases.txt | awk '($3==2 && $1 ~/BBS/) {print $1}' | wc -l\n",
    "grep -wFf tmp_analyzed_samples.txt pheno_LBD_cases.txt | awk '($3==2 && $1 ~/RES/) {print $1}' > tmp_analyzed_demseq_cases.txt\n",
    "\n",
    "grep -wFf tmp_analyzed_demseq_cases.txt $PATH10/LBD.FTD/Phenotype.BBS_DementiaSeq_v2_harmonized.txt | grep -i 'Pathological' | wc -l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc99d66-cc2b-4161-816e-8726d3c46711",
   "metadata": {},
   "source": [
    "All BBSeq samples are neuropathological, so the pathological samples are 58+352/555 = 73.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7c62f-caf6-42a1-84e3-3804104d9f8d",
   "metadata": {},
   "source": [
    "## Bigbed files for UCSC/Ensembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c7f59-414e-4b6e-beff-f99633da5ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Make bigbed files for LBD cases, LBD controls, FTD cases, FTD controls\n",
    "cd $PATH3/ucsc_bigbed_track\n",
    "module load bcftools\n",
    "module load ucsc\n",
    "\n",
    "##Fetch chrom sizes (UCSC binary)\n",
    "fetchChromSizes hg38 > hg38.chrom.sizes\n",
    "\n",
    "##Autosql file is same for all bigbeds, file template from UCSC\n",
    "cat fieldnames.as\n",
    "\n",
    "##Create bigbeds\n",
    "for PHENO in LBD FTD; do\n",
    "  for STATUS in cases controls; do\n",
    "        bcftools query -f '%CHROM\\t%POS\\t%END\\t\"INFO\"\\t%QUAL\\t\".\"\\t%POS\\t%END\\t\"RGB\"\\t%AF\\t%SVLEN\\t%SVTYPE\\t%ID\\n' $PATH2/clean_high_quality_vcfs/${PHENO}_${STATUS}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz > tmp_${PHENO}_${STATUS}_analyzed.bed #Extract info per variant\n",
    "        sed -i 's/\"//g' tmp_${PHENO}_${STATUS}_analyzed.bed #Remove quote marks\n",
    "        awk '($10 > 0)' tmp_${PHENO}_${STATUS}_analyzed.bed > tmp.txt #Filter out variants with AF = 0\n",
    "        awk '{if($12==\"INS\") {$3=$2 ; $8=$2; print} else{print $0}}' tmp.txt > tmp2.txt #If SVTYPE is INS, make END=POS\n",
    "        awk '{if($12==\"INS\") {$11=1; print} else{print $0}}' tmp2.txt > tmp3.txt #For INS, set SVLEN = 1\n",
    "        awk '{if($11<0) {$11=1; print} else{print $0}}' tmp3.txt > tmp4.txt #For those SVs (BNDs, CTX) where SVLEN is under -1 (undetermined), set SVLEN to 1\n",
    "        awk '{if($12 == \"DUP\") {$9=\"0,0,255\"; print} else{print $0}}' tmp4.txt > tmp5.txt #Add color code\n",
    "        awk '{if($12 == \"DEL\") {$9=\"255,0,0\"; print} else{print $0}}' tmp5.txt > tmp6.txt #Add color code\n",
    "        awk '{if($12 == \"INS\") {$9=\"255,153,51\"; print} else{print $0}}' tmp6.txt > tmp7.txt #Add color code\n",
    "        awk '{if($12 == \"INV\") {$9=\"102,0,204\"; print} else{print $0}}' tmp7.txt > tmp8.txt #Add color code\n",
    "        awk '{if($12 == \"INV\") {$9=\"102,0,204\"; print} else{print $0}}' tmp8.txt > tmp9.txt #Add color code\n",
    "        awk '{if($9 == \"RGB\") {$9=\"128,128,128\"; print} else{print $0}}' tmp9.txt > tmp10.txt #Add color code\n",
    "        awk '{printf \"%.2f%\\n\",$10*100}' tmp10.txt > tmp11.txt #Make INFO field as \"SVTYPE_AF(rounded % two decimals)_QUAL\"\n",
    "        paste tmp10.txt tmp11.txt > tmp12.txt\n",
    "        awk '$4=$12\"_AF=\"$14\"_QUAL=\"$5' tmp12.txt > tmp13.txt\n",
    "        awk '$2=$2-1' tmp13.txt > tmp14.txt #Make 0-based bed by substracting 1 from POS\n",
    "        cut -d \" \" -f1-13 tmp14.txt > ${PHENO}_${STATUS}_analyzed.bed\n",
    "        sort -k1,1 -k2,2n ${PHENO}_${STATUS}_analyzed.bed -o ${PHENO}_${STATUS}_analyzed.bed #Sort bed file\n",
    "        bedToBigBed  -as=fieldnames.as -type=bed9+4 ${PHENO}_${STATUS}_analyzed.bed hg38.chrom.sizes ${PHENO}_${STATUS}_analyzed.bb #Make bed into bigbed file\n",
    "    done\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e543a38-77ce-43db-9999-00c8240a301a",
   "metadata": {},
   "source": [
    "## Number of tested filtered clean minor allele frequecy <1% and >=1% structural variants tested against Nanopore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f941ed-8d2b-46bb-9da7-ec4069645665",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Make a list of all SR SVs tested against nanopore\n",
    "cd $PATH2/nanopore_validation/SR_vcfs/split_SR_vcfs/truvari_bench\n",
    "module load bcftools\n",
    "\n",
    "SAMPLES=\"RES01827 RES01897 RES02284 UMARY-5077 RES08227 UMARY-1571 UMARY-634 RES01859 RES01877 UMARY-1544 RES00032 RES00064 RES00275 UMARY-4542 RES00071 RES00048 RES05717 RES05720 RES05722 RES05724\"\n",
    "\n",
    "##Over MAF 1%\n",
    "for SAMPLE in $SAMPLES; do\n",
    "    for SVTYPE in DEL DUP INS INV; do\n",
    "        bcftools query -f '%ID\\n' truvari_bench_${SAMPLE}_${SVTYPE}_over_0.01/tp-call.vcf >> tmp_IDs_over0.01.txt\n",
    "        bcftools query -f '%ID\\n' truvari_bench_${SAMPLE}_${SVTYPE}_over_0.01/fp.vcf >> tmp_IDs_over0.01.txt\n",
    "    done\n",
    "done\n",
    "\n",
    "echo \"Unique SVs over MAF 1%\"\n",
    "sort tmp_IDs_over0.01.txt | uniq | wc -l\n",
    "\n",
    "\n",
    "##under MAF 1%\n",
    "for SAMPLE in $SAMPLES; do\n",
    "    for SVTYPE in DEL DUP INS INV; do\n",
    "        bcftools query -f '%ID\\n' truvari_bench_${SAMPLE}_${SVTYPE}_under_0.01/tp-call.vcf >> tmp_IDs_under0.01.txt\n",
    "        bcftools query -f '%ID\\n' truvari_bench_${SAMPLE}_${SVTYPE}_under_0.01/fp.vcf >> tmp_IDs_under0.01.txt\n",
    "    done\n",
    "done\n",
    "\n",
    "echo -e \"\\n\"\n",
    "echo \"Unique SVs under MAF 1%\"\n",
    "sort tmp_IDs_under0.01.txt | uniq | wc -l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4984502e-b67f-4e6f-aef9-2421ff96fc3a",
   "metadata": {},
   "source": [
    "## Generate spreadsheets for high-quality structural variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e7918-e6d4-43a1-bdc8-b72361711f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $PATH2/clean_high_quality_vcfs\n",
    "module load bcftools\n",
    "\n",
    "#Make header line and extract information from cleaned vcfs\n",
    "for PHENO in LBD FTD; do\n",
    "    echo \"ID CHROM POS END SVTYPE SVLEN QUAL AF ALGORITHMS EVIDENCE\" > tmp_${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.txt\n",
    "    bcftools query -f '%ID %CHROM %POS %END %SVTYPE %SVLEN %QUAL %AF %ALGORITHMS %EVIDENCE\\n' ${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz >> tmp_${PHENO}_high_quality_subset_clean_GQ300missing_all_chr.txt\n",
    "done\n",
    "\n",
    "#Extract case-control allele frequencies from case-control vcfs. If variant does not exit in that file, its AF in that cohort was 0\n",
    "for PHENO in LBD FTD;do\n",
    "    for STATUS in cases controls; do\n",
    "        echo \"ID AF\" > tmp_${PHENO}_${STATUS}_AFs.txt\n",
    "        bcftools query -f \"%ID %AF\\n\" ${PHENO}_${STATUS}_high_quality_subset_clean_GQ300missing_all_chr.vcf.gz >> tmp_${PHENO}_${STATUS}_AFs.txt\n",
    "    done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a417bce-b008-4157-b190-1b34a964c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb0fdef-8341-4584-ba89-1e7549be7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "####LBD\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "\n",
    "#Import files\n",
    "LBD <- fread(\"$PATH2/clean_high_quality_vcfs/tmp_LBD_high_quality_subset_clean_GQ300missing_all_chr.txt\")\n",
    "head(LBD)\n",
    "LBD_cases_AF <- fread(\"$PATH2/clean_high_quality_vcfs/tmp_LBD_cases_AFs.txt\")\n",
    "LBD_controls_AF <- fread(\"$PATH2/clean_high_quality_vcfs/tmp_LBD_controls_AFs.txt\")\n",
    "\n",
    "#Check df dimensions\n",
    "print(dim(LBD))\n",
    "print(dim(LBD_cases_AF))\n",
    "print(dim(LBD_controls_AF))\n",
    "\n",
    "#Merge case-control allele frequencies: include all SVs from both dfs\n",
    "LBD_AFs <- merge(LBD_cases_AF,LBD_controls_AF, by = \"ID\", all = TRUE, suffixes = c(\"_cases\", \"_controls\"))\n",
    "print(dim(LBD_AFs))\n",
    "\n",
    "#Change NA AF values to 0\n",
    "LBD_AFs$AF_cases[is.na(LBD_AFs$AF_cases)] <- 0\n",
    "LBD_AFs$AF_controls[is.na(LBD_AFs$AF_controls)] <- 0\n",
    "\n",
    "#Merge AF data with other data\n",
    "LBD <- merge(LBD, LBD_AFs, by=\"ID\")\n",
    "\n",
    "#Reorganize column order, check file output and dimensions\n",
    "LBD <- LBD[,c(1,2,3,4,5,6,7,8,11,12,9,10)]\n",
    "print(head(LBD))\n",
    "dim(LBD)\n",
    "\n",
    "#Save as an excel file\n",
    "write.table(LBD, \"LBD_high_quality_subset_clean_GQ300missing_all_chr.txt\", row.names = FALSE, sep=\"\\t\", quote = FALSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a52a16-6c35-4f25-acde-f3f3c8e81759",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "####FTD\n",
    "#Load libraries\n",
    "library(data.table)\n",
    "library(\"xlsx\")\n",
    "\n",
    "#Import files\n",
    "FTD <- fread(\"$PATH2/clean_high_quality_vcfs/tmp_FTD_high_quality_subset_clean_GQ300missing_all_chr.txt\")\n",
    "head(FTD)\n",
    "FTD_cases_AF <- fread(\"$PATH2/clean_high_quality_vcfs/tmp_FTD_cases_AFs.txt\")\n",
    "FTD_controls_AF <- fread(\"$PATH2/clean_high_quality_vcfs/tmp_FTD_controls_AFs.txt\")\n",
    "\n",
    "#Check df dimensions\n",
    "print(dim(FTD))\n",
    "print(dim(FTD_cases_AF))\n",
    "print(dim(FTD_controls_AF))\n",
    "\n",
    "#Merge case-control allele frequencies: include all SVs from both dfs\n",
    "FTD_AFs <- merge(FTD_cases_AF,FTD_controls_AF, by = \"ID\", all = TRUE, suffixes = c(\"_cases\", \"_controls\"))\n",
    "print(dim(FTD_AFs))\n",
    "\n",
    "#Change NA AF values to 0\n",
    "FTD_AFs$AF_cases[is.na(FTD_AFs$AF_cases)] <- 0\n",
    "FTD_AFs$AF_controls[is.na(FTD_AFs$AF_controls)] <- 0\n",
    "\n",
    "#Merge AF data with other data\n",
    "FTD <- merge(FTD, FTD_AFs, by=\"ID\")\n",
    "\n",
    "#Reorganize column order, check file output and dimensions\n",
    "FTD <- FTD[,c(1,2,3,4,5,6,7,8,11,12,9,10)]\n",
    "print(head(FTD))\n",
    "dim(FTD)\n",
    "\n",
    "#Save as an excel file\n",
    "write.table(FTD, \"FTD_high_quality_subset_clean_GQ300missing_all_chr.txt\", row.names = FALSE, sep=\"\\t\", quote = FALSE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
